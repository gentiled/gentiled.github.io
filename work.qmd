---
title: "Projects"
#listing:
  #id: sample-listings
  #contents: portfolio
  #sort: "date desc"
  #type: default
  #image-align: left 
  #fields: [title, description]
  #max-description-length: 250
#toc: true
#page-layout: full
---

::: {#sample-listings}
:::

###### **\[2025\]** [Human Performance in Operation of Small Modular Reactors](blog1.qmd)

*Team Lead, University of Toronto*

Directed research informing the Canadian Nuclear Safety Commission's regulations on small modular reactors. Developed approaches to measure human performance, integrate automation, manage multi-unit operations, and assess community impacts.

------------------------------------------------------------------------

###### [User Experiments in Machine Learning Explainability](blog1.qmd)

*PhD Research, University of Toronto, 2024*

Led user studies testing how different explanations affect the ability to detect ML errors. Results showed that combining multiple explanation types improves user performance while revealing potential risks. Findings contribute to human-centered AI design.

------------------------------------------------------------------------

###### [Trust in Human-Machine Learning Interaction](blog1.qmd)

*Working Group Member, Schwartz Reisman Institute, 2024*

Developed a new charting tool to help engineers compare ML models and interpret results via explanation methods LIME, SHAP, and ELI5. User testing showed the chart helped identify key variables and review model outputs.

------------------------------------------------------------------------

###### [[Machine Learning Interface Design for Reliability Engineers]{.underline}](blog1.qmd)

*MITACS Intern, Ericsson, 2023*

Developed a new charting tool to help engineers compare ML models and interpret results via explanation methods LIME, SHAP, and ELI5. User testing showed the chart helped identify key variables and review model outputs.

------------------------------------------------------------------------

###### [Machine Learning [Evaluation for Insurance Risk]{.underline}](blog1.qmd)

*Consultant, Armilla AI and University of Toronto*

Developed a new charting tool to help engineers compare ML models and interpret results via explanation methods LIME, SHAP, and ELI5. User testing showed the chart helped identify key variables and review model outputs.

------------------------------------------------------------------------

<!-- ## Teaching -->

<!-- *Dept. of Mechanical and Industrial Engineering, University of Toronto, 2020-2024* -->

<!-- Taught statistics, human-centered system design, and human factors case studies. Mentored 400+ students in research methods, R programming, and inclusive design practices. Advised student projects for industry partners including Metro, VoilÃ , and Kritik. -->

<!-- ## Research Highlights -->

<!-- -   Led a team of six on human--automation interaction studies for small modular reactors -->

<!-- -   Developed multi-year research funding proposals -->

<!-- -   Designed ML interfaces and evaluated user performance in human-in-the-loop experiments -->

<!-- -   Consulted on ML risk evaluation and conducted ML analyses for insurance risk modeling -->

<!-- ### Selected Publications -->

<!-- For the full list, visit Research Gate or Google Scholar. -->

<!-- #### Peer-Reviewed -->

<!-- -   Gentile D., Donmez, B., & Jamieson, G. A. (2025). [Human performance effects of combining counterfactual explanations with normative and contrastive explanations in supervised machine learning for automated decision assistance.](https://www.sciencedirect.com/science/article/pii/S1071581924002179) *International Journal of Human-Computer Studies*, 196, 103434.\ -->

<!-- -   Gentile D., Donmez, B., & Jamieson, G. A. (2023). [Human performance consequences of normative and contrastive explanations: an experiment in machine learning for reliability maintenance](https://www.sciencedirect.com/science/article/pii/S0004370223000917). *Artificial Intelligence*, 103945.\ -->

<!-- -   Nguyen, T., Gentile D., Jamieson, G. A., Gosine, R., & Purmhedi, H. (2023). [Designing a glyph-based polar chart to interpret the results of machine learning models.](https://journals.sagepub.com/doi/abs/10.1177/10648046231166047) In *Ergonomics in Design: The Quarterly of Human Factors Applications*. -->

<!-- #### Articles -->

<!-- -   Gentile, D. (2023) [Exploring user interaction challenges with large language models](https://srinstitute.utoronto.ca/news/exploring-user-interaction-challenges-with-large-language-models). Schwartz Reisman Insitute for Technology and Society. -->
