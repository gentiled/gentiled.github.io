{
  "hash": "cd0ab23de4e1466a69142f611eaa0b75",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Human performance in operation of small modular reactors\"\nauthor: \"Davide Gentile\"\ndate: \"2024-09-16\"\ncategories: [research]\nimage: \"image.jpg\"\n---\n\n\nThis is the project of my dissertation\n\nðŸ“„ [Report](resume.pdf)\n\nðŸ“Š [Slides](resume.pdf)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 + 1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n:::\n\n\n### 17.26\n\n### Sign test\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data.frame (add  = c(34.7, 28.3, 19.6, 25.1, 15.7, 24.5, 28.7, 23.5,\n                              27.7, 32.1, 29.6, 22.4, 25.7, 28.1, 24.3),\n                  w_add = c(31.4, 27.2, 20.4, 24.6, 14.9, 22.3, 26.8, 24.1, \n                            26.2, 31.4, 28.8, 23.1, 24.0, 27.3, 22.9))\n```\n:::\n\n\nA sign test is performed, with 3 negative signs and 12 positive signs. The p-value is calculated from a binomial distribution, where the 'smaller' sign (negative) has 3 occurrences.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(3, size=15, prob=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0138855\n```\n\n\n:::\n:::\n\n\nAccording to the sign test, the difference in mileage per gallon due to the additive is significant at the .05 significance level, but not at the .01 significance level.\n\n### Wilcoxon test\n\nThe appropriate Wilcoxon test is the Wilcoxon signed rank test, because the two data samples come from repeated observations of the same automobiles.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata$diff = data$add - data$w_add\ndata$abs = abs(data$add - data$w_add)\ndata$rank = rank(data$abs, ties.method = c(\"average\"))\ndata$rank[c(3, 5, 11, 14)] = 6.5\n```\n:::\n\n\nThe null hypothesis is that the mileage per gallon in the two samples are identical populations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(data$add, data$w_add, paired=TRUE) \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in wilcox.test.default(data$add, data$w_add, paired = TRUE): cannot\ncompute exact p-value with ties\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  data$add and data$w_add\nV = 109.5, p-value = 0.005367\nalternative hypothesis: true location shift is not equal to 0\n```\n\n\n:::\n:::\n\n\nAt both .05 and .01 significance levels, we conclude that the mileage per gallon of with and without the additive are nonidentical populations. At the .05 significance level, both the sign test and the Wilcoxon signed rank test indicate a difference due to the additive. However, at the .01 significance level, only the Wilcoxon signed rank test indicate a difference due to the additive.\n\n## 17.34, Wilcoxon rank sum\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n```\n\n\n:::\n:::\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors' grades.\n\n### 17.51\n\n### Kruskall Wallis\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6.54\n```\n\n\n:::\n:::\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\n\nIf all five students were the same for each method, the samples would be dependent, where 'student' becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.8\n```\n\n\n:::\n:::\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\n\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis 'student' is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n### 17.69\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tSpearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n```\n\n\n:::\n:::\n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 64.000000 32.000000 90.666667  3.360672\n```\n\n\n:::\n:::\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(secondj)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n```\n\n\n:::\n\n```{.r .cell-code}\ncor.test(firstj, secondj, method=c(\"pearson\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n```\n\n\n:::\n:::\n\n\nThe results from part a and c agree.\n\n### 12.39\n\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.577795\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nDOF = (2-1)*(2-1)\nDOF\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1939535\n```\n\n\n:::\n:::\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n### Supplementary problem\n\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\n\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar's test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}