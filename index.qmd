---
title: "Davide Gentile"
subtitle: "AI Safety and Usability Advisor for Critical Infrastructure"
about:
  template: solana
  #image: images/profile2.jpg
  #image-width: 7em
  #image-shape: round
  #links:
    #- text: projects
      #href: services.qmd
      #icon: boxes
---

```{=html}
<!-- ## Davide Gentile

**Hi, welcome to my website**

I'm a researcher and analyst specializing in human-automation interaction in safety-critical environments, most recently in the context of small modular reactors. I hold a phd in human-in-the-loop explainability, a field that studies how to design AI systems that are transparent and usable for the people who use them.

My past work spans AI risk, human-machine learning interaction, and system usability across energy, insurance, telecom, and academia. You can find my academic publications [here](publications.qmd).

As of June 2025, I am a member of z-inspection, an international initiative dedicated to evaluating AI systems.

I offer consulting services in user evaluations and AI risk assessment.

Projects \| Publications \| Services \| Contact -->
```
<a id="top"></a> I help organizations develop effective AI systems grounded in human-centered research.

[Contact](#contact) \| [About](#about) \| [Projects](#projects) \| [Services](#services)

------------------------------------------------------------------------

## About {#about}

I work at the intersection of AI, human performance, and risk evaluation. My job is to make sure automation helps people do their jobs in safety-critical environments like nuclear control rooms, telecom operations, and other regulated industries.

I specialize in designing and evaluating how people interact with AI. My background is in industrial engineering (PhD), with a focus on decision support tools in process control environments. I’ve worked across sectors (nuclear, telecom, insurance, and academia) and projects in AI usability, system reliability, and automation risk. View my academic publications [here](publications.qmd).

Since June 2025, I’ve been part of Z-inspection, an international initiative that evaluates the responsible use of AI systems.

------------------------------------------------------------------------

## Projects {#projects}

These are selected engagements where I applied human factors principles to AI and automation systems:

**Human Performance in the Operation of Small Modular Reactors**\
*University of Toronto, Team Lead, 2025*\
Led research to support regulatory oversight of Small Modular Reactors (SMRs). The work focused on two areas: how engineering design factors (e.g., operational phase, load type) affect human performance when managing multiple units, and how AI-based decision aids influence operator effectiveness and system controllability.

**Assessing Risk in Language Models for Global Telecom Company**\
*Armilla AI, Risk Consultant, 2024*\
Evaluated a retrieval-augmented generation (RAG) customer service system with 16M+ users. The project focused on quantifying safety, bias, performance, and regulatory compliance. Key challenge: defining and implementing meaningful metrics for these abstract risks.

**Helping Data Scientists Understand Their Models**\
*Ericsson, Global AI Accelerator Intern, 2023*\
Contributed to the design and evaluation of a visualization tool (“glyph-based polar” chart) to help data scientists compare outputs from multiple machine learning models and explainability methods (e.g., SHAP, LIME). Conducted global user testing to assess clarity, usability, and value. 



------------------------------------------------------------------------

## Services {#services}

I work directly with AI teams, product leads, and compliance officers to make sure AI systems serve people and not the other way around.

-   **Usability Testing for AI Tools** - See how real users interact with your systems before deployment. Identify confusion, friction, and failure modes early.

<!-- Assess how users interact with automated systems to improve trust and performance. -->

-   **AI Risk Assessment** - Get structured, measurable evaluations tied to actual performance and regulatory needs.

<!-- Identify and mitigate safety, bias, and reliability risks. -->

-   **Training and Strategy Workshops** - Customized sessions that bring teams up to speed on human-AI interaction, explainability, and responsible AI design.
<!-- Equip people with practical skills in AI safety and human-centered design. -->

------------------------------------------------------------------------

## Contact {#contact}

gentiledv \[at\] gmail \[dot\] com

[Back to Top](#top){.btn .btn-outline-primary} 
