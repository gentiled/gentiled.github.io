[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Davide Gentile",
    "section": "",
    "text": "Leading human factors research in nuclear operations at the university of toronto cognitive engineering lab\nPreviously consulted on ai risk at armilla ai, researched human–ml interaction at the schwartz reisman institute, and interned at ericsson’s global ai accelerator. Member of z-inspection since june 2025\nIndustries: nuclear, healthcare, transportation, industrial products, consumer products, software, web, mobile\nprojects\npublications\nwriting\nservices\ncontact"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a human factors analyst specializing in human-AI interaction and experimental methods. I currently lead human factors research in nuclear operations at the University of Toronto’s Cognitive Engineering Lab. \nI recently completed a PhD in human factors and explainable AI, focusing on how machine learning explanations affect maintenance operators’ ability to detect errors in automated recommendations.\nPrior to my current role, I consulted on AI risk at Armilla AI, researched human–ML interaction at the Schwartz Reisman Institute for Technology and Society, and interned at Ericsson’s Global AI Accelerator. As of June 2025, I am a member of Z-inspection, an initiative for evaluation of AI systems.\nIndustries served: nuclear, healthcare, automotive, aerospace & aviation, industrial products, consumer products & services, software, web, and mobile applications."
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses",
    "section": "",
    "text": "Causality in Machine Learning\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Causal Inference\n\n\n\n\n\n\n\n\n\n\n\nHuman-centered System Design\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Davide Gentile",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Davide Gentile",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018"
  },
  {
    "objectID": "work.html",
    "href": "work.html",
    "title": "Portfolio",
    "section": "",
    "text": "Human performance in operation of automated nuclear reactors\n\n\n\n\n\nThis research program addresses emerging human factors challenges in the operation of small modular reactors (SMRs). The program focuses on two main objectives: i) improving methodologies for measuring situation awareness and workload in nuclear control rooms, and ii) developing a taxonomy to categorize various SMR designs and their implications for human performance. The first experiment evaluates multiple situation awareness and workload metrics across different levels of automation in computerized nuclear procedures. A parallel project within the program is creating a taxonomy that will guide the development of human factors guidelines across a range of SMR designs. These outcomes will help establish more effective performance metrics and inform the creation of standardized guidelines for SMR operations, contributing to improved safety and efficiency in the nuclear sector. This research is funded by the Natural Sciences and Engineering Council of Canada and the Canadian Nuclear Safety Commission.\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHuman-AI collaboration in industrial process control\n\n\n\n\n\nThis project investigated the impact of model-agnostic explanations on human performance in industrial process control, focusing on improving the detection of system failures in condition-based maintenance. Two controlled experiments tested the effects of different explanation types—normative, contrastive, and counterfactual—on decision-making, workload, and reliance on automated decision aids. Results showed that combining normative and contrastive explanations improved decision time and reduced workload, while adding counterfactuals further enhanced accuracy and reduced false alarms. The findings can inform the design of more effective and efficient explainable AI systems to support human operators in safety-critical work environments.\n\n\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEvaluation of machine learning models for usage-based insurance\n\n\n\n\n\nThis project leveraged fleet telematics data to inform usage-based insurance models for corporate vehicle fleets. We compared machine learning algorithms to predict collision risk in real-time driving behavior data from 3,854 corporate vehicle drivers. The analysis identified key factors that influenced collision involvement, such as driving time, trip frequency, and rapid speed changes. Fleet rental companies can use these insights to adjust insurance rates based on risky driver behaviors. This project contributes to the development of more accurate risk models and improved operational strategies for commercial fleet services.\n\n\n\n\n\nAug 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUX analysis of explainable machine learning tools for Ericsson’s data scientists\n\n\n\n\n\nThis project developed a glyph-based polar chart (GPC) to enhance the interpretability of machine learning models for data scientists. The tool enables comparisons of explanations across different models and computational methods. User experience evaluations with Ericsson data scientists showed that the GPC helped identify key model variables, compare various explanation techniques, and perform logical reviews of model outputs. This project was conducted during my internship at Ericsson’s Global AI Accelerator. \n\n\n\n\n\nJun 12, 2024\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Thoughts",
    "section": "",
    "text": "May 2025\n\nContemporary problems in science and possible paths forward.\n\nMay 2025\n\nWhat is"
  },
  {
    "objectID": "docs/blog/index.html",
    "href": "docs/blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "How to Approach Creating AI Models\n\n\nPutting the Drive into the Train\n\n\n\nApproaching AI\n\n\n\nThere’s more to AI than just creating models.\n\n\n\n\n\nMay 27, 2022\n\n\nSalman Naqvi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html",
    "title": "How to Approach Creating AI Models",
    "section": "",
    "text": "This article was rewritten on Monday, 31 October 2022."
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "title": "How to Approach Creating AI Models",
    "section": "Introduction",
    "text": "Introduction\nHow you approach making models is crucial. The way AI methods are used in today’s landscape is very different. AI methods are created to solve small, atomic problems. And we’ve got most of the methods to handle these small tasks hammered down. Therefore, applied AI is not about creating models; it’s only a small part of it. It’s 80% problem solving and 20% implementing (I would not be surprised if it actually followed the 80-20 rule1).\nThink of AI methods as a tool; think of it as a pencil. You can use pencils to draw, take notes, poke holes, and much more. There are also dozens of pencils out there. But what point is there in using any of those pencils if you don’t even know how to properly use a pencil in the first place? The art of creating pencils has already been perfected too.\nOne highly successful approach is the Drivetrain Approach, created by Jeremy Howard — who’s widely known for his fastai course and library —, Margit Zwemer, and Mike Loukides.\nThe goal of the Drivetrain Approach is to not just use data to generate more data — data that is in the form of predictions. But rather to use data to also generate actionable outcomes.\nThe official blogpost goes into much more depth here.\nIn this post, I’ll be providing a short overview of my understanding of this approach by applying it to the Elements of AI course’s final project (this online course was created by the University of Helsinki and Reaktor)."
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "title": "How to Approach Creating AI Models",
    "section": "Overview of the Drivetrain Approach",
    "text": "Overview of the Drivetrain Approach\nThere are four main steps to this approach:\n\nDefine the objective\nConsider your possible actions\nConsider your data\nCreate the models\n\n\n\n\nImage Source\n\n\n\nDefine the objective\nWrite out what you are really trying to achieve. What is your goal? Writing it out puts it in a tangible manner.\n\n\nConsider your actions\nThink about what actions you can take to achieve your objective.\nAlso think about what would happen if you did those actions.\nWhat would happen if I did x? Would y really be a good idea? What if z worked out too well? Will x lead to y? What would happen if x turned out poorly?\n\n\nConsider your data\nThink about the data you already have and how it could be used.\nThink about any further data that is needed and how it could be collected.\n\n\nCreate the models\nCreate models. But create models that produce actions. Actions that produce the best results for your objective."
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "title": "How to Approach Creating AI Models",
    "section": "Endangered Language Chatbot",
    "text": "Endangered Language Chatbot\nThe final project of the Elements of AI course asked me to come up with my own AI method that would solve a problem, and how it would do so.\nThe problem I tackled was the endangerment of languages. The solution I came up with was to create a chatbot that could converse in these endangered languages. I created an overview of how this could be done.\nThe overview can be read here.\nLet’s tackle this problem through the Drivetrain Approach.\n\nDefine the objective\nThe objective is to preserve languages that are in danger of going extinct. Through preserving languages, histories and cultures can be preserved.\n\n\nConsider your actions\nOne way this could be done is to create a chatbot that could converse in endangered languages. However, this would be a monumental task considering the amount of data needed to achieve this.\nAnother action that could be taken is to create an information retrieval (IR) system of sorts. A corpus of written text of the language could be provided, from which insights about the language’s history, culture, and way of conversing could be gained. In turn the language is preserved.\nThe latter action may be easier to achieve.\n\n\nConsider your data\nThe obvious source of data would be a corpora of text.\nHowever, a major problem arises for those languages which are only spoken. Audio recordings of conversations would have to be made which would take a lot of time and effort. This would be especially difficult for those languages where very few speakers remain.\nEven if a language does have written text, gathering enough text for the language can also be a problem: the language may not have much written text. This may especially be the case for endangered languages. Again, one solution is to manually create texts — using an NLP method to create these texts is not viable.\nIn short, for some languages, there may be no choice other than to manually create the data that would be fed into the system — this manual creation also has the chance to skew the performance of the model.\n\n\n\nKuş dili, a whistled language spoken in Turkey. How would such a language be preserved? Image Source\n\n\n\n\nCreate the model\nEither a chatbot needs to be created that speaks as accurately as a native speaker, or an IR system needs to be created that gives meaningful, correct insights into a language and its associated culture.\nThis step may either be easy or hard, depending on the language. Most NLP or IR systems have been built on a few, select languages. Perhaps this step may be easy for those languages that are similar to languages on which NLP or IR systems have already been built on. It will most likely be harder for those languages which are not."
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "title": "How to Approach Creating AI Models",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes my understanding of the Drivetrain Approach, through an example.\nApproaches are crucial: you can have state-of-the-art tools, but they are useless if not correctly applied. The approach you take can either make it or break it. Putting it into a concrete, organized, tangible manner goes a long way.\nIf you have any comments, questions, suggestions, feedback, criticisms, or corrections, please do post them down in the comment section below!"
  },
  {
    "objectID": "docs/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "href": "docs/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "title": "How to Approach Creating AI Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 80/20 Rule, also known as the Pareto Principle↩︎"
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html",
    "title": "How to Approach Creating AI Models",
    "section": "",
    "text": "This article was rewritten on Monday, 31 October 2022."
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "title": "How to Approach Creating AI Models",
    "section": "Introduction",
    "text": "Introduction\nHow you approach making models is crucial. The way AI methods are used in today’s landscape is very different. AI methods are created to solve small, atomic problems. And we’ve got most of the methods to handle these small tasks hammered down. Therefore, applied AI is not about creating models; it’s only a small part of it. It’s 80% problem solving and 20% implementing (I would not be surprised if it actually followed the 80-20 rule1).\nThink of AI methods as a tool; think of it as a pencil. You can use pencils to draw, take notes, poke holes, and much more. There are also dozens of pencils out there. But what point is there in using any of those pencils if you don’t even know how to properly use a pencil in the first place? The art of creating pencils has already been perfected too.\nOne highly successful approach is the Drivetrain Approach, created by Jeremy Howard — who’s widely known for his fastai course and library —, Margit Zwemer, and Mike Loukides.\nThe goal of the Drivetrain Approach is to not just use data to generate more data — data that is in the form of predictions. But rather to use data to also generate actionable outcomes.\nThe official blogpost goes into much more depth here.\nIn this post, I’ll be providing a short overview of my understanding of this approach by applying it to the Elements of AI course’s final project (this online course was created by the University of Helsinki and Reaktor)."
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "title": "How to Approach Creating AI Models",
    "section": "Overview of the Drivetrain Approach",
    "text": "Overview of the Drivetrain Approach\nThere are four main steps to this approach:\n\nDefine the objective\nConsider your possible actions\nConsider your data\nCreate the models\n\n\n\n\nImage Source\n\n\n\nDefine the objective\nWrite out what you are really trying to achieve. What is your goal? Writing it out puts it in a tangible manner.\n\n\nConsider your actions\nThink about what actions you can take to achieve your objective.\nAlso think about what would happen if you did those actions.\nWhat would happen if I did x? Would y really be a good idea? What if z worked out too well? Will x lead to y? What would happen if x turned out poorly?\n\n\nConsider your data\nThink about the data you already have and how it could be used.\nThink about any further data that is needed and how it could be collected.\n\n\nCreate the models\nCreate models. But create models that produce actions. Actions that produce the best results for your objective."
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "title": "How to Approach Creating AI Models",
    "section": "Endangered Language Chatbot",
    "text": "Endangered Language Chatbot\nThe final project of the Elements of AI course asked me to come up with my own AI method that would solve a problem, and how it would do so.\nThe problem I tackled was the endangerment of languages. The solution I came up with was to create a chatbot that could converse in these endangered languages. I created an overview of how this could be done.\nThe overview can be read here.\nLet’s tackle this problem through the Drivetrain Approach.\n\nDefine the objective\nThe objective is to preserve languages that are in danger of going extinct. Through preserving languages, histories and cultures can be preserved.\n\n\nConsider your actions\nOne way this could be done is to create a chatbot that could converse in endangered languages. However, this would be a monumental task considering the amount of data needed to achieve this.\nAnother action that could be taken is to create an information retrieval (IR) system of sorts. A corpus of written text of the language could be provided, from which insights about the language’s history, culture, and way of conversing could be gained. In turn the language is preserved.\nThe latter action may be easier to achieve.\n\n\nConsider your data\nThe obvious source of data would be a corpora of text.\nHowever, a major problem arises for those languages which are only spoken. Audio recordings of conversations would have to be made which would take a lot of time and effort. This would be especially difficult for those languages where very few speakers remain.\nEven if a language does have written text, gathering enough text for the language can also be a problem: the language may not have much written text. This may especially be the case for endangered languages. Again, one solution is to manually create texts — using an NLP method to create these texts is not viable.\nIn short, for some languages, there may be no choice other than to manually create the data that would be fed into the system — this manual creation also has the chance to skew the performance of the model.\n\n\n\nKuş dili, a whistled language spoken in Turkey. How would such a language be preserved? Image Source\n\n\n\n\nCreate the model\nEither a chatbot needs to be created that speaks as accurately as a native speaker, or an IR system needs to be created that gives meaningful, correct insights into a language and its associated culture.\nThis step may either be easy or hard, depending on the language. Most NLP or IR systems have been built on a few, select languages. Perhaps this step may be easy for those languages that are similar to languages on which NLP or IR systems have already been built on. It will most likely be harder for those languages which are not."
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "title": "How to Approach Creating AI Models",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes my understanding of the Drivetrain Approach, through an example.\nApproaches are crucial: you can have state-of-the-art tools, but they are useless if not correctly applied. The approach you take can either make it or break it. Putting it into a concrete, organized, tangible manner goes a long way.\nIf you have any comments, questions, suggestions, feedback, criticisms, or corrections, please do post them down in the comment section below!"
  },
  {
    "objectID": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "href": "docs/blog/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "title": "How to Approach Creating AI Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 80/20 Rule, also known as the Pareto Principle↩︎"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "How to Approach Creating AI Models\n\n\nPutting the Drive into the Train\n\n\n\nApproaching AI\n\n\n\nThere’s more to AI than just creating models.\n\n\n\n\n\nMay 27, 2022\n\n\nSalman Naqvi\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html",
    "title": "How to Approach Creating AI Models",
    "section": "",
    "text": "This article was rewritten on Monday, 31 October 2022."
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html#introduction",
    "title": "How to Approach Creating AI Models",
    "section": "Introduction",
    "text": "Introduction\nHow you approach making models is crucial. The way AI methods are used in today’s landscape is very different. AI methods are created to solve small, atomic problems. And we’ve got most of the methods to handle these small tasks hammered down. Therefore, applied AI is not about creating models; it’s only a small part of it. It’s 80% problem solving and 20% implementing (I would not be surprised if it actually followed the 80-20 rule1).\nThink of AI methods as a tool; think of it as a pencil. You can use pencils to draw, take notes, poke holes, and much more. There are also dozens of pencils out there. But what point is there in using any of those pencils if you don’t even know how to properly use a pencil in the first place? The art of creating pencils has already been perfected too.\nOne highly successful approach is the Drivetrain Approach, created by Jeremy Howard — who’s widely known for his fastai course and library —, Margit Zwemer, and Mike Loukides.\nThe goal of the Drivetrain Approach is to not just use data to generate more data — data that is in the form of predictions. But rather to use data to also generate actionable outcomes.\nThe official blogpost goes into much more depth here.\nIn this post, I’ll be providing a short overview of my understanding of this approach by applying it to the Elements of AI course’s final project (this online course was created by the University of Helsinki and Reaktor)."
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html#overview-of-the-drivetrain-approach",
    "title": "How to Approach Creating AI Models",
    "section": "Overview of the Drivetrain Approach",
    "text": "Overview of the Drivetrain Approach\nThere are four main steps to this approach:\n\nDefine the objective\nConsider your possible actions\nConsider your data\nCreate the models\n\n\n\n\nImage Source\n\n\n\nDefine the objective\nWrite out what you are really trying to achieve. What is your goal? Writing it out puts it in a tangible manner.\n\n\nConsider your actions\nThink about what actions you can take to achieve your objective.\nAlso think about what would happen if you did those actions.\nWhat would happen if I did x? Would y really be a good idea? What if z worked out too well? Will x lead to y? What would happen if x turned out poorly?\n\n\nConsider your data\nThink about the data you already have and how it could be used.\nThink about any further data that is needed and how it could be collected.\n\n\nCreate the models\nCreate models. But create models that produce actions. Actions that produce the best results for your objective."
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html#endangered-language-chatbot",
    "title": "How to Approach Creating AI Models",
    "section": "Endangered Language Chatbot",
    "text": "Endangered Language Chatbot\nThe final project of the Elements of AI course asked me to come up with my own AI method that would solve a problem, and how it would do so.\nThe problem I tackled was the endangerment of languages. The solution I came up with was to create a chatbot that could converse in these endangered languages. I created an overview of how this could be done.\nThe overview can be read here.\nLet’s tackle this problem through the Drivetrain Approach.\n\nDefine the objective\nThe objective is to preserve languages that are in danger of going extinct. Through preserving languages, histories and cultures can be preserved.\n\n\nConsider your actions\nOne way this could be done is to create a chatbot that could converse in endangered languages. However, this would be a monumental task considering the amount of data needed to achieve this.\nAnother action that could be taken is to create an information retrieval (IR) system of sorts. A corpus of written text of the language could be provided, from which insights about the language’s history, culture, and way of conversing could be gained. In turn the language is preserved.\nThe latter action may be easier to achieve.\n\n\nConsider your data\nThe obvious source of data would be a corpora of text.\nHowever, a major problem arises for those languages which are only spoken. Audio recordings of conversations would have to be made which would take a lot of time and effort. This would be especially difficult for those languages where very few speakers remain.\nEven if a language does have written text, gathering enough text for the language can also be a problem: the language may not have much written text. This may especially be the case for endangered languages. Again, one solution is to manually create texts — using an NLP method to create these texts is not viable.\nIn short, for some languages, there may be no choice other than to manually create the data that would be fed into the system — this manual creation also has the chance to skew the performance of the model.\n\n\n\nKuş dili, a whistled language spoken in Turkey. How would such a language be preserved? Image Source\n\n\n\n\nCreate the model\nEither a chatbot needs to be created that speaks as accurately as a native speaker, or an IR system needs to be created that gives meaningful, correct insights into a language and its associated culture.\nThis step may either be easy or hard, depending on the language. Most NLP or IR systems have been built on a few, select languages. Perhaps this step may be easy for those languages that are similar to languages on which NLP or IR systems have already been built on. It will most likely be harder for those languages which are not."
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html#conclusion",
    "title": "How to Approach Creating AI Models",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes my understanding of the Drivetrain Approach, through an example.\nApproaches are crucial: you can have state-of-the-art tools, but they are useless if not correctly applied. The approach you take can either make it or break it. Putting it into a concrete, organized, tangible manner goes a long way.\nIf you have any comments, questions, suggestions, feedback, criticisms, or corrections, please do post them down in the comment section below!"
  },
  {
    "objectID": "blog/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "href": "blog/posts/1_how_to_approach_creating_ai_models.html#footnotes",
    "title": "How to Approach Creating AI Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe 80/20 Rule, also known as the Pareto Principle↩︎"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/welcome/index.html",
    "href": "blogposts/welcome/index.html",
    "title": "Halden HTO’s AI in Nuclear",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/post-with-code/index.html",
    "href": "blogposts/post-with-code/index.html",
    "title": "Choosing the design for your experiment",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "works/work1.html",
    "href": "works/work1.html",
    "title": "Project 1",
    "section": "",
    "text": "Project 1\nHere is a detailed description of Project 1, including the technologies used, challenges, and outcomes.\n\n\n\nProject Image"
  },
  {
    "objectID": "workposts/welcome/index.html",
    "href": "workposts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "workposts/post-with-code/index.html",
    "href": "workposts/post-with-code/index.html",
    "title": "Evaluating the impact of automated decision aids on human performance",
    "section": "",
    "text": "This is the project of my dissertation\n📄 Report\n📊 Slides\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "work.html#predictive-modeling-for-sales-forecasting",
    "href": "work.html#predictive-modeling-for-sales-forecasting",
    "title": "works",
    "section": "Predictive Modeling for Sales Forecasting",
    "text": "Predictive Modeling for Sales Forecasting\n\nSkills: R, Python, Machine Learning, Time Series Analysis\nCategories: Data Science, Applied Statistics\nDescription: Built a predictive model to forecast sales using time series analysis and machine learning. Improved forecast accuracy by 20%."
  },
  {
    "objectID": "work.html#ai-decision-aid-evaluation",
    "href": "work.html#ai-decision-aid-evaluation",
    "title": "works",
    "section": "AI Decision Aid Evaluation",
    "text": "AI Decision Aid Evaluation\n\nSkills: Data Analysis, Statistical Modeling, Human Factors Engineering\nCategories: AI Evaluation, Decision Support Systems\nDescription: Evaluated explanation interfaces for decision-making in automated systems, focusing on false alarms and overreliance."
  },
  {
    "objectID": "work.html#exploratory-data-analysis-on-toronto-island-data",
    "href": "work.html#exploratory-data-analysis-on-toronto-island-data",
    "title": "works",
    "section": "Exploratory Data Analysis on Toronto Island Data",
    "text": "Exploratory Data Analysis on Toronto Island Data\n\nSkills: R, Data Wrangling, Visualization\nCategories: Data Science, Statistics\nDescription: Merged ticket sales data with weather datasets to understand patterns in tourism. Visualized trends to inform public policy."
  },
  {
    "objectID": "workposts/post-with-code/index.html#wilcoxon-rank-sum",
    "href": "workposts/post-with-code/index.html#wilcoxon-rank-sum",
    "title": "Evaluating the impact of automated decision aids on human performance",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "The impact of post-hoc explanations from automated decision aids on human performance\n\n\n\n\n\n\nresearch\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\nDavide Gentile\n\n\n\n\n\n\n\n\n\n\n\n\nHuman performance in operation of small modular reactors\n\n\n\n\n\n\nresearch\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nDavide Gentile\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "teaching",
    "section": "",
    "text": "Introduction to data science with R\nTime series analysis with R\nStatistical models for empirical research\nDesign of experiments\nData visualization and communication\nProgramming practices in human-subjects research\nHow to publish scientific research"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "WORK\nPostdoc | Team Lead, Experimentation and Analysis 2024 – Present\nHuman Factors Researcher 2020 - 2024\nUniversity of Toronto\nData Science Consultant 2024, Armilla AI, Toronto ON\nResearch Intern 2020 – 2023, Ericsson, Global AI Accelerator, Montreal, QC\nEDUCATION\nPhD, Industrial Engineering, University of Toronto, 2019 – 2024\nMSc, Cognitive Science of Language, McMaster University, 2017 – 2019\nBA, Lettere Moderne, University of Bologna, 2014 – 2017"
  },
  {
    "objectID": "docs/courses.html",
    "href": "docs/courses.html",
    "title": "courses",
    "section": "",
    "text": "Introduction to data science with R\nTime series analysis with R\nStatistical models for empirical research\nDesign of experiments\nData visualization and communication\nProgramming practices in human-subjects research\nHow to publish scientific research"
  },
  {
    "objectID": "research - Copy.html",
    "href": "research - Copy.html",
    "title": "research",
    "section": "",
    "text": "AI Decision Aid Evaluation\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nDavide Gentile\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "sites.html",
    "href": "sites.html",
    "title": "sites",
    "section": "",
    "text": "AI Decision Aid Evaluation\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nSep 16, 2024\n\n\nDavide Gentile\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nSep 12, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "workposts/time-series/index.html",
    "href": "workposts/time-series/index.html",
    "title": "Time series analysis for customer retention",
    "section": "",
    "text": "This is a time series analysis\n📄 Report\n📊 Slides\n# Libraries\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load dataset from github\ndata &lt;- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/3_TwoNumOrdered.csv\", header=T)\ndata$date &lt;- as.Date(data$date)\n\n# Plot\ndata %&gt;%\n  tail(10) %&gt;%\n  ggplot( aes(x=date, y=value)) +\n    geom_line() +\n    geom_point()"
  },
  {
    "objectID": "workposts/time-series/index.html#wilcoxon-rank-sum",
    "href": "workposts/time-series/index.html#wilcoxon-rank-sum",
    "title": "Time series analysis for customer retention",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "researchposts/small-modular-reactors/index.html",
    "href": "researchposts/small-modular-reactors/index.html",
    "title": "Human performance in operation of small modular reactors",
    "section": "",
    "text": "This is the project of my dissertation\n📄 Report\n📊 Slides\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "researchposts/small-modular-reactors/index.html#wilcoxon-rank-sum",
    "href": "researchposts/small-modular-reactors/index.html#wilcoxon-rank-sum",
    "title": "Human performance in operation of small modular reactors",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "researchposts/explanations/index.html",
    "href": "researchposts/explanations/index.html",
    "title": "Explaining automated results in decision support systems",
    "section": "",
    "text": "This is a time series analysis\n📄 Report\n📊 Slides\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "researchposts/explanations/index.html#wilcoxon-rank-sum",
    "href": "researchposts/explanations/index.html#wilcoxon-rank-sum",
    "title": "Explaining automated results in decision support systems",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "researchposts/human-performance/index.html",
    "href": "researchposts/human-performance/index.html",
    "title": "Evaluating the impact of automated decision aids on human performance",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/Conducting a socio-technical evaluation/index.html",
    "href": "blogposts/Conducting a socio-technical evaluation/index.html",
    "title": "Conducting a sociotechnical evaluation",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/welcome - Copy/index.html",
    "href": "blogposts/welcome - Copy/index.html",
    "title": "Halden HTO’s AI in Nuclear",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/welcome - Copy (2)/index.html",
    "href": "blogposts/welcome - Copy (2)/index.html",
    "title": "Halden HTO’s AI in Nuclear",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "blogposts/asking-causal-questions/index.html",
    "href": "blogposts/asking-causal-questions/index.html",
    "title": "Asking better causal questions for statistical inference",
    "section": "",
    "text": "This blog post is currently being prepared."
  },
  {
    "objectID": "researchposts/explanations - Copy/index.html",
    "href": "researchposts/explanations - Copy/index.html",
    "title": "Usability study of XAI displays to support productivity of Ericsson’s data scientists",
    "section": "",
    "text": "This is a time series analysis\n📄 Report\n📊 Slides\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "researchposts/explanations - Copy/index.html#wilcoxon-rank-sum",
    "href": "researchposts/explanations - Copy/index.html#wilcoxon-rank-sum",
    "title": "Usability study of XAI displays to support productivity of Ericsson’s data scientists",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "blogposts/choosing-design-experiment/index.html",
    "href": "blogposts/choosing-design-experiment/index.html",
    "title": "Exploring user interaction challenges with large language models",
    "section": "",
    "text": "Available here."
  },
  {
    "objectID": "blogposts/driving-insurance/index.html",
    "href": "blogposts/driving-insurance/index.html",
    "title": "Usage-based insurance: better to penalize the bad drivers, or reward the good ones?",
    "section": "",
    "text": "This blogpost is currently being prepared.\nAnalysis of confusion matrix for ML models doing binary classification: risky vs. not risky."
  },
  {
    "objectID": "workposts/explanations-human-performance/index.html",
    "href": "workposts/explanations-human-performance/index.html",
    "title": "Designing Machine Feedback that Supports Human Decisions",
    "section": "",
    "text": "This is the project of my dissertation\nimage: https://www.geeksforgeeks.org/explainable-artificial-intelligencexai/\n📄 Report\n📊 Slides\nlibrary(ggrain)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nsdt &lt;- read_csv(\"sdt.csv\")\nsdt$cond = as.factor(sdt$cond)\nsdt$measure = as.factor(sdt$measure)\n\nsensitivity  &lt;-  sdt %&gt;% \n  filter(measure == \"dprime\")\nsensitivity$measure = as.factor(sensitivity$measure)\n\n\ndprimesum &lt;- summarySE(sensitivity, measurevar = \"score\", groupvars=c(\"cond\", \"measure\"))\n\nhead(dprimesum)\n\n  cond measure  N score_mean score_median        sd       sem        ci\n1    0  dprime 25  0.7685624    0.7823470 0.9889596 0.1977919 0.4082225\n2    1  dprime 25  0.9793959    0.6523937 0.8077070 0.1615414 0.3334051\n3    2  dprime 25  1.8532857    2.1213820 0.9431285 0.1886257 0.3893043\n\nggplot(sensitivity, aes(cond, score, fill = measure)) +\n  geom_rain(alpha = .5) +\n  theme_classic() +\n  scale_fill_brewer(palette = 'Dark2') +\n  guides(fill = 'none', color = 'none')"
  },
  {
    "objectID": "workposts/explanations-human-performance/index.html#wilcoxon-rank-sum",
    "href": "workposts/explanations-human-performance/index.html#wilcoxon-rank-sum",
    "title": "Designing Machine Feedback that Supports Human Decisions",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "workposts/driving-data/index.html",
    "href": "workposts/driving-data/index.html",
    "title": "sk-analysis-2024",
    "section": "",
    "text": "In this document I keep track of the analysis plan for the SK Networks dataset. The objective is to write a good paper for publication. The idea of the analysis is the following:\n\nUse ML to identify the factors related to collision involvement (0,1) and to collision severity (3 levels, or cumulative damage cost)\nConduct causal inference analysis to identify the impact of the factors associated with collision involvement\nConduct multinomial or ordered logistic regression to identify the impact of the factors associated with collision severity; this should have adjustments that enable to do causal analysis, but I don’t know which adjustments yet."
  },
  {
    "objectID": "workposts/driving-data/index.html#wilcoxon-rank-sum",
    "href": "workposts/driving-data/index.html#wilcoxon-rank-sum",
    "title": "Driving analytics for risk assessment in usage-based insurance",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "workposts/ericsson-project/index.html",
    "href": "workposts/ericsson-project/index.html",
    "title": "Development of Polar Chart for Model Interpretability",
    "section": "",
    "text": "Here I report the development of a glyph-based polar chart (GPC), designed to support a comprehensive interpretation of the results of ML models by enabling data scientists to compare different explanation methods within the same model and across models.\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "I specialize in three areas:\n\n\n\n\n\n\n\n\n\n\n\n\nHuman Factors Audit\n\n\nEvaluate usability, explainability, and user trust in your AI systems.\n\n\n\n\n\n\n\n\n\n\n\nAI Risk Assessment\n\n\nIdentify and mitigate risks including bias, fairness, and compliance.\n\n\n\n\n\n\n\n\n\n\n\nTraining and Workshops\n\n\nSome courses and workshops to help you discover how AI can augment you\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "serviceposts/audit/index.html",
    "href": "serviceposts/audit/index.html",
    "title": "Model audit",
    "section": "",
    "text": "This is a time series analysis\n📄 Report\n📊 Slides\n# Libraries\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load dataset from github\ndata &lt;- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/3_TwoNumOrdered.csv\", header=T)\ndata$date &lt;- as.Date(data$date)\n\n# Plot\ndata %&gt;%\n  tail(10) %&gt;%\n  ggplot( aes(x=date, y=value)) +\n    geom_line() +\n    geom_point()"
  },
  {
    "objectID": "serviceposts/audit/index.html#wilcoxon-rank-sum",
    "href": "serviceposts/audit/index.html#wilcoxon-rank-sum",
    "title": "Model audit",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "servicesposts/data/index.html",
    "href": "servicesposts/data/index.html",
    "title": "Data strategy",
    "section": "",
    "text": "Develop a data strategy that aligns with your business goals, focusing on data collection, analysis, and experimentation.\n📄 Report\n📊 Slides\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "servicesposts/data/index.html#wilcoxon-rank-sum",
    "href": "servicesposts/data/index.html#wilcoxon-rank-sum",
    "title": "Data strategy",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "servicesposts/audit/index.html",
    "href": "servicesposts/audit/index.html",
    "title": "Model audits",
    "section": "",
    "text": "Assess the performance of your models (predictive, generative), identify biases and ensure robustness to support accurate and reliable outcomes.\n📄 Report\n📊 Slides\n# Libraries\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Load dataset from github\ndata &lt;- read.table(\"https://raw.githubusercontent.com/holtzy/data_to_viz/master/Example_dataset/3_TwoNumOrdered.csv\", header=T)\ndata$date &lt;- as.Date(data$date)\n\n# Plot\ndata %&gt;%\n  tail(10) %&gt;%\n  ggplot( aes(x=date, y=value)) +\n    geom_line() +\n    geom_point()"
  },
  {
    "objectID": "servicesposts/audit/index.html#wilcoxon-rank-sum",
    "href": "servicesposts/audit/index.html#wilcoxon-rank-sum",
    "title": "Model audits",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "servicesposts/inference/index.html",
    "href": "servicesposts/inference/index.html",
    "title": "Causal inference",
    "section": "",
    "text": "Uncover the cause-and-effect relationships in your data using methodologies like randomized controlled trials and regression discontinuity.\n\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html#menu-sidebar",
    "href": "index.html#menu-sidebar",
    "title": "Frameset Example Title",
    "section": "Menu (Sidebar)",
    "text": "Menu (Sidebar)\nYou can create a sidebar with R Markdown using htmltools or simply present the menu in a separate section. If you prefer to embed the menu HTML directly:"
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "Frameset Example Title",
    "section": "Content",
    "text": "Content\nThis is the main content area, which was originally the “content” frame. You can embed the HTML content like so:"
  },
  {
    "objectID": "workposts/hf-nuclear/index.html",
    "href": "workposts/hf-nuclear/index.html",
    "title": "Human performance in operation of automated nuclear reactors",
    "section": "",
    "text": "This research program collects human performance data during simulated operations of Small Modular Reactors (SMRs). SMRs allow for remote monitoring and control of multiple facilities, which introduces a new set of human factors challenges related to the impact of control room design on human performance. Ongoing human-subjects experiments are investigating several aspects of SMR design and their effects on operator behavior, decision-making, and interaction with automated technologies.\n\n\n\nThe basic principle iPWR simulator setup in the Halden Future Lab"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Davide Gentile",
    "section": "",
    "text": "&lt; Back"
  },
  {
    "objectID": "workposts/publications/index.html",
    "href": "workposts/publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "List of academic publications\n\nPeer reviewed journal articles\n\nGoogle Scholar\nGentile D., Donmez, B., & Jamieson, G. A. (Accepted, 2024). Human performance effects of combining counterfactual explanations with normative and contrastive explanations in supervised machine learning for automated decision assistance. In the International Journal of Human-Computer Studies.\nGentile D., Donmez, B., & Jamieson, G. A. (2023). Human Performance Consequences of Normative and Contrastive Explanations: An Experiment in Machine Learning for Reliability Maintenance. Artificial Intelligence, 103945. Link\nNguyen, T., Gentile D., Jamieson, G. A., Gosine, R., & Purmhedi, H. (2023). Designing a Glyph-based Polar Chart to Interpret the Results of Machine Learning Models. In Ergonomics in Design: The Quarterly of Human Factors Applications. Link\n\n\n\n\n\nPeer reviewed conference/workshop proceedings\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating Human Understanding in Explainable AI Systems. In ACM Human Factors in Computing Systems (CHI) Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI2021, Yokohama, Japan. Link\n\n\n\n\nArticles in preparation\nGentile D., & Jamieson, G. A. (2025). Effects of Automation transpareancy on human performance under different workload contrainsts. Human Factors.\nLawson-Jack K., Gentile D., & Jamieson, G. A. (2025). Progress on a Taxonomy of Heterogeneity in Small Modular Reactor Operations. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Liang Y., & Jamieson, G. A. (2025). Assessing Measures of Human Performance in the Nuclear Control Room. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Jamieson, G. A., & Donmez B. (2023). Influence of Individual Differences on the Effectiveness of Post-hoc Explanations in Automation Reliance Behavior. Submitted to the Journal of Cognitive Engineering and Decision-Making.\n\n\n\n\nPresentations\nGentile D., Jamieson G. A., Donmez B. (2024). Supporting human performance with explanation interfaces in automated decision assistance for process control operations. In Disruptive, Innovative and Emerging Technologies (DIET) Conference 2024 of the Canadian Nuclear Society (CNS) (organized in cooperation with the International Atomic Energy Agency).\nGentile D., Donmez, B., & Jamieson, G. A. (2024). Enhancing Human Performance with Post-hoc Explanations in Machine Learning-based Decision Support Systems. Oral presentation at the 7th International Conference on Intelligent Human Systems Integration: Integrating People and Intelligent Systems, Palermo, Italy.\nGentile D. (2023). Designing for human-AI interactions in industrial condition monitoring. Oral presentation at the AI Seminar in GAIA (Global Artificial Intelligence Accelerator), Ericsson Montreal, QC.\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating human understanding in XAI systems. Oral presentation at the ACM CHI Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI Conference on Human Factors in Computing Systems (CHI ’21), Yokohama, Japan (held remotely).\nGentile D. (2020). Human Factors in Explainable AI. Invited panelist at the 2021 Graduate Student Research Showcase. Faculty of Applied Science and Engineering, University of Toronto."
  },
  {
    "objectID": "workposts/1-hf-nuclear/index.html",
    "href": "workposts/1-hf-nuclear/index.html",
    "title": "Human performance in operation of automated nuclear reactors",
    "section": "",
    "text": "This research program collects human performance data during simulated operations of Small Modular Reactors (SMRs). SMRs allow for remote monitoring and control of multiple facilities, which introduces a new set of human factors challenges related to the impact of control room design on human performance. Ongoing human-subjects experiments are investigating several aspects of SMR design and their effects on operator behavior, decision-making, and interaction with automated technologies.\n\n\n\nThe basic principle iPWR simulator setup in the Halden Future Lab"
  },
  {
    "objectID": "workposts/4-publications/index.html",
    "href": "workposts/4-publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "List of academic publications\n\nPeer reviewed journal articles\n\nGoogle Scholar\nGentile D., Donmez, B., & Jamieson, G. A. (Accepted, 2024). Human performance effects of combining counterfactual explanations with normative and contrastive explanations in supervised machine learning for automated decision assistance. In the International Journal of Human-Computer Studies.\nGentile D., Donmez, B., & Jamieson, G. A. (2023). Human Performance Consequences of Normative and Contrastive Explanations: An Experiment in Machine Learning for Reliability Maintenance. Artificial Intelligence, 103945. Link\nNguyen, T., Gentile D., Jamieson, G. A., Gosine, R., & Purmhedi, H. (2023). Designing a Glyph-based Polar Chart to Interpret the Results of Machine Learning Models. In Ergonomics in Design: The Quarterly of Human Factors Applications. Link\n\n\n\n\n\nPeer reviewed conference/workshop proceedings\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating Human Understanding in Explainable AI Systems. In ACM Human Factors in Computing Systems (CHI) Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI2021, Yokohama, Japan. Link\n\n\n\n\nArticles in preparation\nGentile D., & Jamieson, G. A. (2025). Effects of Automation transpareancy on human performance under different workload contrainsts. Human Factors.\nLawson-Jack K., Gentile D., & Jamieson, G. A. (2025). Progress on a Taxonomy of Heterogeneity in Small Modular Reactor Operations. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Liang Y., & Jamieson, G. A. (2025). Assessing Measures of Human Performance in the Nuclear Control Room. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Jamieson, G. A., & Donmez B. (2023). Influence of Individual Differences on the Effectiveness of Post-hoc Explanations in Automation Reliance Behavior. Submitted to the Journal of Cognitive Engineering and Decision-Making.\n\n\n\n\nPresentations\nGentile D., Jamieson G. A., Donmez B. (2024). Supporting human performance with explanation interfaces in automated decision assistance for process control operations. In Disruptive, Innovative and Emerging Technologies (DIET) Conference 2024 of the Canadian Nuclear Society (CNS) (organized in cooperation with the International Atomic Energy Agency).\nGentile D., Donmez, B., & Jamieson, G. A. (2024). Enhancing Human Performance with Post-hoc Explanations in Machine Learning-based Decision Support Systems. Oral presentation at the 7th International Conference on Intelligent Human Systems Integration: Integrating People and Intelligent Systems, Palermo, Italy.\nGentile D. (2023). Designing for human-AI interactions in industrial condition monitoring. Oral presentation at the AI Seminar in GAIA (Global Artificial Intelligence Accelerator), Ericsson Montreal, QC.\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating human understanding in XAI systems. Oral presentation at the ACM CHI Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI Conference on Human Factors in Computing Systems (CHI ’21), Yokohama, Japan (held remotely).\nGentile D. (2020). Human Factors in Explainable AI. Invited panelist at the 2021 Graduate Student Research Showcase. Faculty of Applied Science and Engineering, University of Toronto."
  },
  {
    "objectID": "workposts/2-explanations-human-performance/index.html",
    "href": "workposts/2-explanations-human-performance/index.html",
    "title": "Human-AI collaboration in industrial process control",
    "section": "",
    "text": "This project focuses on developing information content in the HMI* to support human decision-making in complex environments. The goal is to enhance the interpretability and usability of automated advice, ensuring that the information provided in the HMI aligns with human cognitive processes and operational needs.\nHMI = human machine interface."
  },
  {
    "objectID": "workposts/2-explanations-human-performance/index.html#wilcoxon-rank-sum",
    "href": "workposts/2-explanations-human-performance/index.html#wilcoxon-rank-sum",
    "title": "Designing Machine Feedback that Supports Human Decisions",
    "section": "17.34, Wilcoxon rank sum",
    "text": "17.34, Wilcoxon rank sum\n\n# Prepare the data\ndata2 = data.frame(instr = c(\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\"A\",\n                            \"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\"B\",\n                            \"B\",\"B\",\"B\",\"B\"),\n                   grades = c(88, 75, 92, 71, 63, 84, 55, 64, 82, 96, 72, \n                              65, 84, 53, 76, 80, 51, 60, 57, 85, 94, 87, \n                              73, 61))\ndata2$rank = rank(data2$grades, ties.method = c(\"average\"))\n\n\nR1 = sum(data2$rank[data2$instr == \"A\"])\nR2 = sum(data2$rank[data2$instr == \"B\"])\nN1 = 10\nN2= 14\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1]  53.5000000  70.0000000 291.6666667  -0.9661411\n\n\nFrom the z table, we get a critical x value of -1.96, while our calculated z value is approximately -0.966. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two instructors’ grades.\n\n17.51\n\n\nKruskall Wallis\n\n# Prepare the data\ndata3 = data.frame(method = c(\"1\",\"1\",\"1\",\"1\",\"1\",\n                              \"2\",\"2\",\"2\",\"2\",\"2\",\n                              \"3\",\"3\",\"3\",\"3\",\"3\"),\n                   grades = c(78, 62, 71, 58, 73, \n                              76, 85, 77, 90, 87, \n                              74, 79, 60, 75, 80))\ndata3$rank = rank(data3$grades, ties.method = c(\"average\"))\n\n\n# Calculate H\nR1 = sum(data3$rank[data3$method == \"1\"])\nR2 = sum(data3$rank[data3$method == \"2\"])\nR3 = sum(data3$rank[data3$method == \"3\"])\n\nH = ((12/(15*16)) * ((R1^2)/5 + (R2^2)/5 + (R3^2)/5)) - 3*(16)\nH\n\n[1] 6.54\n\n\nThe critical H value for the .05 significance level is 5.991. Thus, at the .05 significance level, we reject the null hypothesis in favor of the alternative hypothesis that there is difference between the three teaching methods. The critical H value for the .01 significance level is 9.21. Thus, at the .01 significance level, we have not enough evidence to reject the null hypothesis that there is no difference between the three teaching methods.\nIf all five students were the same for each method, the samples would be dependent, where ‘student’ becomes the random factor. Thus, the Friedman test is appropriate in this case.\n\n# Prepare the data\ndata4 = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                   met1 = c(78, 62, 71, 58, 73),\n                   met2 = c(76, 85, 77, 90, 87),\n                   met3 = c(74, 79, 60, 75, 80))\n\ndata4rank = data.frame(student = c(\"1\",\"2\",\"3\",\"4\",\"5\"),\n                       met1 = c(1, 3, 2, 3, 3),\n                       met2 = c(2, 1, 1, 1, 1),\n                       met3 = c(3, 2, 3, 2, 2))\n\n\n# Calculate Chi square\nR1 = sum(data4rank$met1)\nR2 = sum(data4rank$met2)\nR3 = sum(data4rank$met3)\n\nXsq = (12/(5*3*(3+1)))*((R1^2)+(R2^2)+(R3^2)) - 15*4\nXsq\n\n[1] 4.8\n\n\nThe critical Chi square value for the .05 significance level is 5.991. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference. The critical Chi square value for the .01 significance level is 9.21. We fail to reject the null hypothesis .# critH for significance level of .01 is 9.21. Thus, we also fail to reject the null hypothesis at the .01 significance level.\nThe first analysis is testing whether different groups of students undertaking three different teaching methods perform equally in their exam. On the other hand, the second analysis is testing whether the same students perform differently on their exam based on different teaching methods. When different groups of students are subject to different teaching methods, there is difference in grades only at the .05 significance level. When the same students are subject to the three different teaching methods, there is no difference in grades. This might be because in the second analysis ‘student’ is a random factor and thus grades depend more on individual variability rather than teaching method.\n\n\n17.69\n\n# Prepare the data\nfirstj = c(5,2,8,1,4,6,3,7)\nsecondj= c(4,5,7,3,2,8,1,6)\n\n\n# a and b\ncor.test(firstj, secondj, method=c(\"spearman\"))\n\n\n    Spearman's rank correlation rho\n\ndata:  firstj and secondj\nS = 28, p-value = 0.08309\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6666667 \n\n\nThe coefficient of rank correlation is 0.6666667, which is a large effect size. However, according to this test, the correlation is not significant: p-value = 0.08309.\n\n# Alternative: Wilcoxon rank sum test  method to calculate significance \nR1 = sum(firstj)\nR2 = sum(secondj)\nN1 = 8\nN2= 8\n\nU = N1*N2 + ((N1*(N1+1))/2) - R1\nmu = (N1*N2)/2\nvar = (N1*N2*(N1+N2+1))/12\nz = (U-mu)/sqrt(var)\nc(U, mu, var, z)\n\n[1] 64.000000 32.000000 90.666667  3.360672\n\n\nThe critical z value at .05 significance is -1.96, while the calculated z value is approximately 3.36. Thus, accroding to the Wilcoxon rank sum test, the rankings from the two judges differ.\n\n# c: Perform the appropriate non-parametric comparison test\nshapiro.test(firstj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  firstj\nW = 0.97486, p-value = 0.9332\n\nshapiro.test(secondj)\n\n\n    Shapiro-Wilk normality test\n\ndata:  secondj\nW = 0.97486, p-value = 0.9332\n\ncor.test(firstj, secondj, method=c(\"pearson\"))\n\n\n    Pearson's product-moment correlation\n\ndata:  firstj and secondj\nt = 2.1909, df = 6, p-value = 0.07099\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07168044  0.93302248\nsample estimates:\n      cor \n0.6666667 \n\n\nThe results from part a and c agree.\n\n\n12.39\nThe null hypothesis is that there is no difference between the sleeping and the sugar pills. The grand total is 170. The expected values are calculated by multiplying the RowSum with the ColSum and dividing that by the grand total: E1 is 39.7, E2 is 14.3, E3 is 85.3 and E4 is 30.7.\n\nXsq = (((44-39.7)^2)/39.7) + (((10-14.3)^2)/14.3) + (((81-85.3)^2)/85.3) + \n  (((35-30.7)^2)/30.7)\nXsq\n\n[1] 2.577795\n\n\n\nDOF = (2-1)*(2-1)\nDOF\n\n[1] 1\n\n\nThe critical value of X square for 1 degree of freedom is 3.84. Thus, at the .05 significance level, we fail to reject the null hypothesis that there is no difference between the two types of pills.\n\nC = sqrt((Xsq^2)/((Xsq^2)+170))\nC\n\n[1] 0.1939535\n\n\nThe coefficient of contingency is 0.1939535. Thus, the variables are independent from each other (i.e., there is no association).\n\n\nSupplementary problem\nThe problem involves a contingency table with dependent samples. The P value answers this question: if there is no association between display type and seeing a collision, what is the probability of observing such a large discrepancy (or larger) between the number of the two kinds of discordant pairs? A small P value is evidence that there is an association between display type and seeing a collision.\nThe two-tailed P value equals 0.1687, which is considered to be not statistically significant. The P value was calculated with McNemar’s test with the continuity correction. Chi squared equals 1.895, with 1 degree of freedom. So we can conclude that there is no difference between displays."
  },
  {
    "objectID": "workposts/3-ericsson-project/index.html",
    "href": "workposts/3-ericsson-project/index.html",
    "title": "UX analysis of explainable machine learning tools for Ericsson’s data scientists",
    "section": "",
    "text": "During my internship at Ericsson, we developed and evaluated a glyph-based polar chart (GPC) designed to support a comprehensive interpretation of the results of ML models. The GPC enabled data scientists to compare different explanation methods within the same model and across models."
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Davide Gentile",
    "section": "",
    "text": "Human Factors in SMR Operations\n\n\n\n\n\n\nSep 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning Machine Feedback to Assist Human Decisions\n\n\n\n\n\n\nSep 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDevelopment of Polar Chart for Model Interpretability\n\n\n\n\n\n\nAug 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPublications\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Portfolio"
    ]
  },
  {
    "objectID": "blogposts/conducting a socio-technical evaluation/index.html",
    "href": "blogposts/conducting a socio-technical evaluation/index.html",
    "title": "How to evaluate joint human-AI performance",
    "section": "",
    "text": "This blogpost is currently being prepared."
  },
  {
    "objectID": "publications.html#peer-reviewed-journal-articles",
    "href": "publications.html#peer-reviewed-journal-articles",
    "title": "Davide Gentile",
    "section": "",
    "text": "Gentile D., Donmez, B., & Jamieson, G. A. (Accepted, 2024). Human performance effects of combining counterfactual explanations with normative and contrastive explanations in supervised machine learning for automated decision assistance. In the International Journal of Human-Computer Studies.\nGentile D., Donmez, B., & Jamieson, G. A. (2023). Human Performance Consequences of Normative and Contrastive Explanations: An Experiment in Machine Learning for Reliability Maintenance. Artificial Intelligence, 103945. Link\nNguyen, T., Gentile D., Jamieson, G. A., Gosine, R., & Purmhedi, H. (2023). Designing a Glyph-based Polar Chart to Interpret the Results of Machine Learning Models. In Ergonomics in Design: The Quarterly of Human Factors Applications. Link\n\n\n\n\n\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating Human Understanding in Explainable AI Systems. In ACM Human Factors in Computing Systems (CHI) Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI2021, Yokohama, Japan. Link",
    "crumbs": [
      "Publications"
    ]
  },
  {
    "objectID": "publications.html#articles-in-preparation",
    "href": "publications.html#articles-in-preparation",
    "title": "Davide Gentile",
    "section": "Articles in preparation",
    "text": "Articles in preparation\nGentile D., & Jamieson, G. A. (2025). Effects of Automation transpareancy on human performance under different workload contrainsts. Human Factors.\nLawson-Jack K., Gentile D., & Jamieson, G. A. (2025). Progress on a Taxonomy of Heterogeneity in Small Modular Reactor Operations. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Liang Y., & Jamieson, G. A. (2025). Assessing Measures of Human Performance in the Nuclear Control Room. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\nGentile D., Jamieson, G. A., & Donmez B. (2023). Influence of Individual Differences on the Effectiveness of Post-hoc Explanations in Automation Reliance Behavior. Submitted to the Journal of Cognitive Engineering and Decision-Making.\n\n\n\nPresentations\nGentile D., Jamieson G. A., Donmez B. (2024). Supporting human performance with explanation interfaces in automated decision assistance for process control operations. In Disruptive, Innovative and Emerging Technologies (DIET) Conference 2024 of the Canadian Nuclear Society (CNS) (organized in cooperation with the International Atomic Energy Agency).\nGentile D., Donmez, B., & Jamieson, G. A. (2024). Enhancing Human Performance with Post-hoc Explanations in Machine Learning-based Decision Support Systems. Oral presentation at the 7th International Conference on Intelligent Human Systems Integration: Integrating People and Intelligent Systems, Palermo, Italy.\nGentile D. (2023). Designing for human-AI interactions in industrial condition monitoring. Oral presentation at the AI Seminar in GAIA (Global Artificial Intelligence Accelerator), Ericsson Montreal, QC.\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating human understanding in XAI systems. Oral presentation at the ACM CHI Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI Conference on Human Factors in Computing Systems (CHI ’21), Yokohama, Japan (held remotely).\nGentile D. (2020). Human Factors in Explainable AI. Invited panelist at the 2021 Graduate Student Research Showcase. Faculty of Applied Science and Engineering, University of Toronto.",
    "crumbs": [
      "Publications"
    ]
  },
  {
    "objectID": "blogposts/user-interaction-llms/index.html",
    "href": "blogposts/user-interaction-llms/index.html",
    "title": "Exploring user interaction challenges with large language models",
    "section": "",
    "text": "As AI assistants such as large language models become increasingly integrated into our daily lives, some human-computer interaction challenges emerge. In this blog post, I discuss both the virtues and pitfalls of user experience, offering insights on how interactions with language models can be made clearer, more trustworthy, and overall more effective for everyone. In particular, I highlight two key issues in user experience and proposes strategies, grounded in human-automation interaction research, to address them and improve this novel interaction paradigm.\nRead the full blog post here."
  },
  {
    "objectID": "about.html#hello",
    "href": "about.html#hello",
    "title": "Davide Gentile",
    "section": "",
    "text": "I am a data science and R&D leader with a background in cognitive science of language and human factors engineering. My experience spans academic research, industrial R&D, and applied data science.\nI have a strong foundation in behavioral science, machine learning, and quantitative UX research, and specialize in developing data solutions that enhance human decision-making and optimize user experiences. I thrive in cross-functional environments, collaborating with engineers, designers, and business leaders to align advanced analytics with real-world applications. My goal is to make data work for people, not the other way around."
  },
  {
    "objectID": "workposts/4-penguins/index.html",
    "href": "workposts/4-penguins/index.html",
    "title": "Penguin",
    "section": "",
    "text": "This analysis takes the best from three analysis on the Penguin data.\nShowing mostly a PCA, and Simpson’s paradox.\n\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(tidyr)\ndata(\"penguins\")\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nhttps://allisonhorst.github.io/palmerpenguins/\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 × 6\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3701. 2008.\n2 Chinstrap           48.8          18.4              196.       3733. 2008.\n3 Gentoo              47.5          15.0              217.       5076. 2008.\n\n\nFor this example:\n\nshorten variable names (remove units) to simplify variable labels,\ncreate factors for character variables (needed for MANOVA), and\nremove NA observations (causes problems with PCA)\n\n\npeng &lt;- penguins %&gt;%\n    dplyr::rename(\n         bill_length = bill_length_mm, \n         bill_depth = bill_depth_mm, \n         flipper_length = flipper_length_mm, \n         body_mass = body_mass_g)\npeng &lt;- peng %&gt;% drop_na()\npeng\n\n# A tibble: 333 × 8\n   species island    bill_length bill_depth flipper_length body_mass sex    year\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;     &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torgersen        39.1       18.7            181      3750 male   2007\n 2 Adelie  Torgersen        39.5       17.4            186      3800 fema…  2007\n 3 Adelie  Torgersen        40.3       18              195      3250 fema…  2007\n 4 Adelie  Torgersen        36.7       19.3            193      3450 fema…  2007\n 5 Adelie  Torgersen        39.3       20.6            190      3650 male   2007\n 6 Adelie  Torgersen        38.9       17.8            181      3625 fema…  2007\n 7 Adelie  Torgersen        39.2       19.6            195      4675 male   2007\n 8 Adelie  Torgersen        41.1       17.6            182      3200 fema…  2007\n 9 Adelie  Torgersen        38.6       21.2            191      3800 male   2007\n10 Adelie  Torgersen        34.6       21.1            198      4400 male   2007\n# ℹ 323 more rows\n\n\n\nlibrary(car)\nlibrary(ggbiplot)\nlibrary(GGally)\n\n\nscatterplotMatrix(~ bill_length + bill_depth + flipper_length + body_mass | species,\n                  data=peng,\n                  ellipse=list(levels=0.68),\n                  col = scales::hue_pal()(3),\n                  legend=list(coords=\"bottomright\"))\n\n\n\n\n\n\n\n\n\nggpairs(peng, mapping = aes(color = species), \n        columns = c(\"bill_length\", \"bill_depth\", \n                    \"flipper_length\", \"body_mass\",\n                    \"island\", \"sex\"))\n\n\n\n\n\n\n\n\n\npeng.pca &lt;- prcomp (~ bill_length + bill_depth + flipper_length + body_mass,\n                    data=peng,\n                    scale. = TRUE)\n\npeng.pca\n\nStandard deviations (1, .., p=4):\n[1] 1.6569115 0.8821095 0.6071594 0.3284579\n\nRotation (n x k) = (4 x 4):\n                      PC1         PC2        PC3        PC4\nbill_length     0.4537532 -0.60019490 -0.6424951  0.1451695\nbill_depth     -0.3990472 -0.79616951  0.4258004 -0.1599044\nflipper_length  0.5768250 -0.00578817  0.2360952 -0.7819837\nbody_mass       0.5496747 -0.07646366  0.5917374  0.5846861\n\n\n\nscreeplot(peng.pca, type = \"line\", lwd=3, cex=3, \n        main=\"Variances of PCA Components\")\n\n\n\n\n\n\n\n\n\nggbiplot(peng.pca, obs.scale = 1, var.scale = 1,\n         groups = peng$species, \n         ellipse = TRUE, circle = TRUE) +\n  scale_color_discrete(name = 'Penguin Species') +\n  theme_minimal() +\n  theme(legend.direction = 'horizontal', legend.position = 'top') \n\n\n\n\n\n\n\n\nFrom this, we can see:\n\nThese two principal components account for 68.6 + 19.5 = 88.1 % of the total variance of these four size variables.\nPC1 is largely determined by flipper length and body mass. We can interpret this as an overall measure of penguin size.\nOn this dimension, Gentoos are the largest, by quite a lot, compared with Adelie and Chinstrap.\nPC2 is mainly determined by variation in the two beak variables: bill length and depth. Chinstrap are lower than the other two species on bill length and depth, but bill length further distinguishes the Gentoos. A penguin biologist could almost certainly provide an explanation, but I’ll call this beak shape."
  },
  {
    "objectID": "workposts/4-ubi/index.html",
    "href": "workposts/4-ubi/index.html",
    "title": "Evaluation of machine learning models for usage-based insurance",
    "section": "",
    "text": "This analysis takes the best from three analysis on the Penguin data.\nShowing mostly a PCA, and Simpson’s paradox.\n\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(tidyr)\ndata(\"penguins\")\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nhttps://allisonhorst.github.io/palmerpenguins/\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 × 6\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3701. 2008.\n2 Chinstrap           48.8          18.4              196.       3733. 2008.\n3 Gentoo              47.5          15.0              217.       5076. 2008.\n\n\nFor this example:\n\nshorten variable names (remove units) to simplify variable labels,\ncreate factors for character variables (needed for MANOVA), and\nremove NA observations (causes problems with PCA)\n\n\npeng &lt;- penguins %&gt;%\n    dplyr::rename(\n         bill_length = bill_length_mm, \n         bill_depth = bill_depth_mm, \n         flipper_length = flipper_length_mm, \n         body_mass = body_mass_g)\npeng &lt;- peng %&gt;% drop_na()\npeng\n\n# A tibble: 333 × 8\n   species island    bill_length bill_depth flipper_length body_mass sex    year\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;     &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torgersen        39.1       18.7            181      3750 male   2007\n 2 Adelie  Torgersen        39.5       17.4            186      3800 fema…  2007\n 3 Adelie  Torgersen        40.3       18              195      3250 fema…  2007\n 4 Adelie  Torgersen        36.7       19.3            193      3450 fema…  2007\n 5 Adelie  Torgersen        39.3       20.6            190      3650 male   2007\n 6 Adelie  Torgersen        38.9       17.8            181      3625 fema…  2007\n 7 Adelie  Torgersen        39.2       19.6            195      4675 male   2007\n 8 Adelie  Torgersen        41.1       17.6            182      3200 fema…  2007\n 9 Adelie  Torgersen        38.6       21.2            191      3800 male   2007\n10 Adelie  Torgersen        34.6       21.1            198      4400 male   2007\n# ℹ 323 more rows\n\n\n\nlibrary(car)\nlibrary(ggbiplot)\nlibrary(GGally)\n\n\nscatterplotMatrix(~ bill_length + bill_depth + flipper_length + body_mass | species,\n                  data=peng,\n                  ellipse=list(levels=0.68),\n                  col = scales::hue_pal()(3),\n                  legend=list(coords=\"bottomright\"))\n\n\n\n\n\n\n\n\n\nggpairs(peng, mapping = aes(color = species), \n        columns = c(\"bill_length\", \"bill_depth\", \n                    \"flipper_length\", \"body_mass\",\n                    \"island\", \"sex\"))\n\n\n\n\n\n\n\n\n\npeng.pca &lt;- prcomp (~ bill_length + bill_depth + flipper_length + body_mass,\n                    data=peng,\n                    scale. = TRUE)\n\npeng.pca\n\nStandard deviations (1, .., p=4):\n[1] 1.6569115 0.8821095 0.6071594 0.3284579\n\nRotation (n x k) = (4 x 4):\n                      PC1         PC2        PC3        PC4\nbill_length     0.4537532 -0.60019490 -0.6424951  0.1451695\nbill_depth     -0.3990472 -0.79616951  0.4258004 -0.1599044\nflipper_length  0.5768250 -0.00578817  0.2360952 -0.7819837\nbody_mass       0.5496747 -0.07646366  0.5917374  0.5846861\n\n\n\nscreeplot(peng.pca, type = \"line\", lwd=3, cex=3, \n        main=\"Variances of PCA Components\")\n\n\n\n\n\n\n\n\n\nggbiplot(peng.pca, obs.scale = 1, var.scale = 1,\n         groups = peng$species, \n         ellipse = TRUE, circle = TRUE) +\n  scale_color_discrete(name = 'Penguin Species') +\n  theme_minimal() +\n  theme(legend.direction = 'horizontal', legend.position = 'top') \n\n\n\n\n\n\n\n\nFrom this, we can see:\n\nThese two principal components account for 68.6 + 19.5 = 88.1 % of the total variance of these four size variables.\nPC1 is largely determined by flipper length and body mass. We can interpret this as an overall measure of penguin size.\nOn this dimension, Gentoos are the largest, by quite a lot, compared with Adelie and Chinstrap.\nPC2 is mainly determined by variation in the two beak variables: bill length and depth. Chinstrap are lower than the other two species on bill length and depth, but bill length further distinguishes the Gentoos. A penguin biologist could almost certainly provide an explanation, but I’ll call this beak shape.\n\n\n# Scatterplot example 2: penguin bill length versus bill depth\nggplot(data = peng, aes(x = bill_length, y = bill_depth)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 2)  +\n  scale_color_manual(values = c(\"darkorange\",\"darkorchid\",\"cyan4\")) +\n  theme_minimal()"
  },
  {
    "objectID": "courses2.html",
    "href": "courses2.html",
    "title": "Courses2",
    "section": "",
    "text": "Introduction to data science with R\nTime series analysis with R\nStatistical models for empirical research\nDesign of experiments\nData visualization and communication\nProgramming practices in human-subjects research\nHow to publish scientific research"
  },
  {
    "objectID": "workposts/ubi/index.html",
    "href": "workposts/ubi/index.html",
    "title": "Evaluation of machine learning models for usage-based insurance",
    "section": "",
    "text": "This analysis takes the best from three analysis on the Penguin data.\nShowing mostly a PCA, and Simpson’s paradox.\n\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(tidyr)\ndata(\"penguins\")\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nhttps://allisonhorst.github.io/palmerpenguins/\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(where(is.numeric), mean, na.rm = TRUE))\n\n# A tibble: 3 × 6\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3701. 2008.\n2 Chinstrap           48.8          18.4              196.       3733. 2008.\n3 Gentoo              47.5          15.0              217.       5076. 2008.\n\n\nFor this example:\n\nshorten variable names (remove units) to simplify variable labels,\ncreate factors for character variables (needed for MANOVA), and\nremove NA observations (causes problems with PCA)\n\n\npeng &lt;- penguins %&gt;%\n    dplyr::rename(\n         bill_length = bill_length_mm, \n         bill_depth = bill_depth_mm, \n         flipper_length = flipper_length_mm, \n         body_mass = body_mass_g)\npeng &lt;- peng %&gt;% drop_na()\npeng\n\n# A tibble: 333 × 8\n   species island    bill_length bill_depth flipper_length body_mass sex    year\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;      &lt;dbl&gt;          &lt;int&gt;     &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n 1 Adelie  Torgersen        39.1       18.7            181      3750 male   2007\n 2 Adelie  Torgersen        39.5       17.4            186      3800 fema…  2007\n 3 Adelie  Torgersen        40.3       18              195      3250 fema…  2007\n 4 Adelie  Torgersen        36.7       19.3            193      3450 fema…  2007\n 5 Adelie  Torgersen        39.3       20.6            190      3650 male   2007\n 6 Adelie  Torgersen        38.9       17.8            181      3625 fema…  2007\n 7 Adelie  Torgersen        39.2       19.6            195      4675 male   2007\n 8 Adelie  Torgersen        41.1       17.6            182      3200 fema…  2007\n 9 Adelie  Torgersen        38.6       21.2            191      3800 male   2007\n10 Adelie  Torgersen        34.6       21.1            198      4400 male   2007\n# ℹ 323 more rows\n\n\n\nlibrary(car)\nlibrary(ggbiplot)\nlibrary(GGally)\n\n\nscatterplotMatrix(~ bill_length + bill_depth + flipper_length + body_mass | species,\n                  data=peng,\n                  ellipse=list(levels=0.68),\n                  col = scales::hue_pal()(3),\n                  legend=list(coords=\"bottomright\"))\n\n\n\n\n\n\n\n\n\nggpairs(peng, mapping = aes(color = species), \n        columns = c(\"bill_length\", \"bill_depth\", \n                    \"flipper_length\", \"body_mass\",\n                    \"island\", \"sex\"))\n\n\n\n\n\n\n\n\n\npeng.pca &lt;- prcomp (~ bill_length + bill_depth + flipper_length + body_mass,\n                    data=peng,\n                    scale. = TRUE)\n\npeng.pca\n\nStandard deviations (1, .., p=4):\n[1] 1.6569115 0.8821095 0.6071594 0.3284579\n\nRotation (n x k) = (4 x 4):\n                      PC1         PC2        PC3        PC4\nbill_length     0.4537532 -0.60019490 -0.6424951  0.1451695\nbill_depth     -0.3990472 -0.79616951  0.4258004 -0.1599044\nflipper_length  0.5768250 -0.00578817  0.2360952 -0.7819837\nbody_mass       0.5496747 -0.07646366  0.5917374  0.5846861\n\n\n\nscreeplot(peng.pca, type = \"line\", lwd=3, cex=3, \n        main=\"Variances of PCA Components\")\n\n\n\n\n\n\n\n\n\nggbiplot(peng.pca, obs.scale = 1, var.scale = 1,\n         groups = peng$species, \n         ellipse = TRUE, circle = TRUE) +\n  scale_color_discrete(name = 'Penguin Species') +\n  theme_minimal() +\n  theme(legend.direction = 'horizontal', legend.position = 'top') \n\n\n\n\n\n\n\n\nFrom this, we can see:\n\nThese two principal components account for 68.6 + 19.5 = 88.1 % of the total variance of these four size variables.\nPC1 is largely determined by flipper length and body mass. We can interpret this as an overall measure of penguin size.\nOn this dimension, Gentoos are the largest, by quite a lot, compared with Adelie and Chinstrap.\nPC2 is mainly determined by variation in the two beak variables: bill length and depth. Chinstrap are lower than the other two species on bill length and depth, but bill length further distinguishes the Gentoos. A penguin biologist could almost certainly provide an explanation, but I’ll call this beak shape.\n\n\n# Scatterplot example 2: penguin bill length versus bill depth\nggplot(data = peng, aes(x = bill_length, y = bill_depth)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 2)  +\n  scale_color_manual(values = c(\"darkorange\",\"darkorchid\",\"cyan4\")) +\n  theme_minimal()"
  },
  {
    "objectID": "workposts/human-ai-collab/index.html",
    "href": "workposts/human-ai-collab/index.html",
    "title": "Human-AI collaboration in industrial process control",
    "section": "",
    "text": "This project focuses on developing information content in the HMI* to support human decision-making in complex environments. The goal is to enhance the interpretability and usability of automated advice, ensuring that the information provided in the HMI aligns with human cognitive processes and operational needs.\nHMI = human machine interface."
  },
  {
    "objectID": "workposts/ux-ericsson/index.html",
    "href": "workposts/ux-ericsson/index.html",
    "title": "UX analysis of explainable machine learning tools for Ericsson’s data scientists",
    "section": "",
    "text": "During my internship at Ericsson, we developed and evaluated a glyph-based polar chart (GPC) designed to support a comprehensive interpretation of the results of ML models. The GPC enabled data scientists to compare different explanation methods within the same model and across models."
  },
  {
    "objectID": "portfolio/ux-ericsson/index.html",
    "href": "portfolio/ux-ericsson/index.html",
    "title": "Development and UX Analysis of ML Model Interpretability Tool",
    "section": "",
    "text": "This project developed a glyph-based polar chart (GPC) to enhance the interpretability of machine learning models for data scientists. The tool enables comparisons of explanations across different models and computational methods. User experience evaluations with Ericsson data scientists showed that the GPC helped identify key model variables, compare various explanation techniques, and perform logical reviews of model outputs. This project was conducted during my internship at Ericsson’s Global AI Accelerator. The development of the prototype and its evaluation with Ericsson’s data scientists was published in the Journal of Ergonomics in Design and is available here."
  },
  {
    "objectID": "portfolio/human-ai-collab/index.html",
    "href": "portfolio/human-ai-collab/index.html",
    "title": "Impact of Machine Learning Explanations on Decision-Making",
    "section": "",
    "text": "This project investigated the impact of model-agnostic explanations on human performance in industrial process control, focusing on improving the detection of system failures in condition-based maintenance. Two controlled experiments tested the effects of different explanation types—normative, contrastive, and counterfactual—on decision-making, workload, and reliance on automated decision aids. Results showed that combining normative and contrastive explanations improved decision time and reduced workload, while adding counterfactuals further enhanced accuracy and reduced false alarms. The findings can inform the design of more effective and efficient explainable AI systems to support human operators in safety-critical work environments.\nThe first experiment was published in the Journal of Artificial Intelligence in 2023 and is available here. The second experiment was published in the Journal of Human-Computer Studies in 2025 and is available here."
  },
  {
    "objectID": "portfolio/hf-nuclear/index.html",
    "href": "portfolio/hf-nuclear/index.html",
    "title": "Human Performance in Operation of Small Modular Reactors",
    "section": "",
    "text": "Background\nThe increasing automation of small modular reactors (SMRs) introduces new challenges for human operators in nuclear control rooms. Effective monitoring and control require maintaining situation awareness and workload balance, but traditional assessment methods lack validity and reliability in these high-stakes environments. Additionally, the diversity of SMR designs complicates the development of standardized human factors guidelines to ensure safe and efficient operation.\nStarting September 2024, I am leading experimental and analytical projects in a new research program aimed at addressing these gaps. The research program focuses on two key objectives: improving methodologies for assessing situation awareness (SA) and workload in nuclear control rooms, and developing a taxonomy to categorize SMR designs and their impact on human performance. The first experiment tests multiple (SA) and workload measures across different automation levels. A parallel project is creating a taxonomy to guide human factors guidelines for varying SMR designs.\nThe project aims to establish better performance metrics and standardized operational guidelines, supporting safety and efficiency in the nuclear sector. This research is funded by the Natural Sciences and Engineering Council of Canada and the Canadian Nuclear Safety Commission.\n\n\nMethods\nThis research program addresses these challenges through two parallel projects:\n\nProject 1: Experiment on Operator Performance & Automation\n\nI designed an experiment using the RANCOR microworld platform to simulate the operation of small modular reactors under routine and abnormal scenarios.\nTested 24 participants and collected multiple metrics of situation awareness and workload across three levels of automation in computerized procedures. The three levels of automation in the computerized procedures are defined according to the Institute of Electrical and Electronics Engineers (IEEE) Standard 1786 (IEEE, 2022): Type I procedure displays the instructions on a screen, resembling a traditional paper-based procedure; Type II can additionally display process data and step logic, visualize results, and provide access links to displays and soft controls; Type III has the additional capability to automatically carry out sequences in the procedure and has embedded soft control features.\nEvaluated situation awareness, cognitive workload, decision-making, and reaction time using a within-subjects experimental design with three counterbalanced conditions corresponding to the level of automation in the computerized procedures (Table I).\n\n\n\n\nTable I. Experimental design. A = Type I procedure; B = Type II; C = Type III.\n\n\n\n\nProject 2: Development of an SMR Taxonomy\n\nMy team is leading the development of a taxonomy that categorizes key design variations in SMRs, including levels of automation, control systems, and operational phases. This work identifies implications for task performance, cognitive workload, and situational awareness, providing a structured framework to inform human factors guidelines and improve safety in nuclear operations.\n\n\n\n\nKey Findings\nFindings will be presented at the Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT) meeting in Chicago in June 2025.\n\n\nImplications\nThis research supports regulatory agencies and nuclear operators in defining best practices for safe SMR operations by providing validated methodologies for assessing operator performance. It also helps engineers and system designers optimize automation levels and control interfaces to enhance human performance in nuclear control rooms.\n\n\n\nSMR simulator setup in the Halden Future Lab, Norway.\n\n\n\nFurther Reading\n\nIEEE. (2022). IEEE Guide for Human Factors Applications of Computerized Operating Procedure Systems (COPS) at Nuclear Power Generating Stations and Other Nuclear Facilities, IEEE- 1786-2022. New York: IEEE."
  },
  {
    "objectID": "portfolio/ubi/index.html",
    "href": "portfolio/ubi/index.html",
    "title": "Evaluation of ML Models for Driving Insurance",
    "section": "",
    "text": "This project leveraged fleet telematics data to inform usage-based insurance models for corporate vehicle fleets. We compared machine learning algorithms to predict collision risk in real-time driving behavior data from 3,854 corporate vehicle drivers. The analysis identified key factors that influenced collision involvement, such as driving time, trip frequency, and rapid speed changes. Fleet rental companies can use these insights to adjust insurance rates based on risky driver behaviors. This project contributes to the development of more accurate risk models and improved operational strategies for commercial fleet services.\nI presented this work at the 2020 Joint Statistical Meetings held by the American Statistical Association, and at the 2020 University of Toronto Engineering Research Conference, where it was awarded the 1st prize in the cluster “Artificial Intelligence and Data Analytics”."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "&lt; Back\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nRisk Assessment in Commercial Deployment of LLMs\n\n\nClient: Armilla AI Industry: AI Insurance Challenge: Users struggled to trust and interpret AI-generated recommendations, leading to low adoption rates. Approach: Evaluated the accuracy, safety, and bias of AI models, including red-teaming customer service language models used by a telecom company with 16M+ users. Solution: Implemented new explanation features and user training sessions. Results: - 40% reduction in user error - 2x increase in system adoption - Positive feedback from end-users. \n\n\n\n\nEvaluation of ML Models for Driving Insurance\n\n\nClient: Ericsson Inc. Industry: Telecommunications Challenge: Users struggled to trust and interpret AI-generated recommendations, leading to low adoption rates. Approach: Conducted a human factors audit, user interviews, and interface redesign focused on explainability. Solution: Implemented new explanation features and user training sessions. Results: - 40% reduction in user error - 2x increase in system adoption - Positive feedback from end-users.\n\n\n\n\nDevelopment and UX Analysis of ML Model Interpretability Tool\n\n\nDuring my internship at Ericsson, I contributed to the development of a glyph-based polar chart to enhance the interpretability of machine learning models. \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/trust-ml/index.html",
    "href": "portfolio/trust-ml/index.html",
    "title": "Investigating Trust in Human-Machine Learning Interaction",
    "section": "",
    "text": "In collaboration with a group comprising doctoral and postdoctoral researchers from the Schwartz Reisman Institute for Technology and Society, we adopted a multidisciplinary perspective to understand how machine learning systems can earn and maintain human trust. We are preparing a paper on this research inclusive of findings and suggestions for further inquiry. More information on this project is available here."
  },
  {
    "objectID": "blogposts/morality-ai/index.html",
    "href": "blogposts/morality-ai/index.html",
    "title": "Incorporating human morality into AI design",
    "section": "",
    "text": "Scholars and practitioners have long grappled with the challenge of embedding human morality into artificial agents, a central issue in AI ethics known as the alignment problem. Julia Haas, a senior research scientist at DeepMind, argues that part of the difficulty stems from traditional assumptions about the human mind. Typically, the mind is seen as having two core functions: epistemic (reasoning and computation) and phenomenological (emotion and affect). However, recent insights from reinforcement learning and cognitive science suggest a third, often overlooked aspect—the mind's inherently evaluative nature. Recognizing this could be key to designing AI systems that better align with human values.\nRead the full blog post here."
  },
  {
    "objectID": "courselist/case-studies-HF/index.html",
    "href": "courselist/case-studies-HF/index.html",
    "title": "From R Markdown to Quarto",
    "section": "",
    "text": "9:30 am - 5:00 pm\nFriday, October 20, 2023\nVanderbilt University\nQuarto is an open-source scientific and technical publishing system that offers multilingual programming language support to create dynamic and static documents, books, presentations, blogs, and other online resources. In this workshop, you will learn how to apply your reproducible authoring skills to the Quarto format and learn about new tools and workflows for authoring with Quarto in RStudio. You will learn to create static documents as well as slide presentations. The workshop will also introduce you to Quarto projects which you can use to build websites and write blogs and books. Finally, you will learn various ways to deploy and publish your Quarto projects on the web."
  },
  {
    "objectID": "courselist/statistics-R/index.html",
    "href": "courselist/statistics-R/index.html",
    "title": "Introduction to Causal Inference",
    "section": "",
    "text": "Quarto is an open-source scientific and technical publishing system that offers multilingual programming language support to create dynamic and static documents, books, presentations, blogs, and other online resources. In this workshop, you will learn how to apply your reproducible authoring skills to the Quarto format and learn about new tools and workflows for authoring with Quarto in RStudio. You will learn to create static documents as well as slide presentations. The workshop will also introduce you to Quarto projects which you can use to build websites and write blogs and books. Finally, you will learn various ways to deploy and publish your Quarto projects on the web."
  },
  {
    "objectID": "courselist/human-centered-design/index.html",
    "href": "courselist/human-centered-design/index.html",
    "title": "Human-centered System Design",
    "section": "",
    "text": "This blog post is currently being prepared."
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "Places the logo on top of the sidebar and a small version in the browser tab.\nwebsite:\n  sidebar:\n    logo: \"images/logo.png\"\n  favicon: \"images/logo.png\"\n\n\n\nwebsite:\n  sidebar:\n    logo: \"images/logo.png\"\n    tools:\n      - icon: github\n        href: https://github.com/quart-cli\n        text: \"GitHub organization\"\n      - icon: code-square\n        href: https://posit.cloud\n        text: \"Posit Cloud\"\n\n\n\nSome examples include:\n\nTwitter Cards provide an enhanced appearance when someone links to your site on Twitter.\nThe Open Graph protocol enables richer sharing of links to articles on the web, e.g., with preview images.\n\nwebsite:\n  twitter-card: true\n  open-graph: true\n\n\n\n\nquarto.org/docs/websites/website-tools.html\n\n\n\n\n\n\nPick up where we left off and\n\nAdd a link to a GitHub repository with a bootstrap icon.\nReview https://quarto.org/docs/websites/website-tools.html and implement one new tool we haven’t introduced.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#logos",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#logos",
    "title": "Miscellaneous",
    "section": "",
    "text": "Places the logo on top of the sidebar and a small version in the browser tab.\nwebsite:\n  sidebar:\n    logo: \"images/logo.png\"\n  favicon: \"images/logo.png\""
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#icons",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#icons",
    "title": "Miscellaneous",
    "section": "",
    "text": "website:\n  sidebar:\n    logo: \"images/logo.png\"\n    tools:\n      - icon: github\n        href: https://github.com/quart-cli\n        text: \"GitHub organization\"\n      - icon: code-square\n        href: https://posit.cloud\n        text: \"Posit Cloud\""
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#socials",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#socials",
    "title": "Miscellaneous",
    "section": "",
    "text": "Some examples include:\n\nTwitter Cards provide an enhanced appearance when someone links to your site on Twitter.\nThe Open Graph protocol enables richer sharing of links to articles on the web, e.g., with preview images.\n\nwebsite:\n  twitter-card: true\n  open-graph: true"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#learn-more",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#learn-more",
    "title": "Miscellaneous",
    "section": "",
    "text": "quarto.org/docs/websites/website-tools.html"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn",
    "title": "Miscellaneous",
    "section": "",
    "text": "Pick up where we left off and\n\nAdd a link to a GitHub repository with a bootstrap icon.\nReview https://quarto.org/docs/websites/website-tools.html and implement one new tool we haven’t introduced.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#theme-options",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#theme-options",
    "title": "Miscellaneous",
    "section": "Theme options",
    "text": "Theme options\n\nOne of 25 Bootswatch themes\nCustom themes\nA combination of the two"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#setting-the-theme",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#setting-the-theme",
    "title": "Miscellaneous",
    "section": "Setting the theme",
    "text": "Setting the theme\nIn _quarto.yml:\nformat:\n  html:\n    theme: default"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#dark-mode",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#dark-mode",
    "title": "Miscellaneous",
    "section": "Dark mode",
    "text": "Dark mode\nSetting a light and dark theme makes both available with a toggle automatically added to your website:\nformat:\n  html:\n    theme:\n      light: flatly\n      dark: darkly"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#customizing-themes",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#customizing-themes",
    "title": "Miscellaneous",
    "section": "Customizing themes",
    "text": "Customizing themes\nTo customize a theme, add a custom .scss file that is then called in _quarto.yml, e.g.:\nformat:\n  html:\n    theme:\n      light: [flatly, custom.scss]\n      dark: darkly"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#scss-files",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#scss-files",
    "title": "Miscellaneous",
    "section": "SCSS files",
    "text": "SCSS files\nSCSS files have the following form:\n/*-- scss:defaults --*/\n$h2-font-size:          1.6rem !default;\n$headings-font-weight:  500 !default;\n$body-color:            $gray-700 !default;\n\n/*-- scss:rules --*/\nh1, h2, h3, h4, h5, h6 {\n  text-shadow: -1px -1px 0 rgba(0, 0, 0, .3);\n}\n\nThe defaults section is where you list variables\nThe rules section is where you list (CSS) rules"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#sass-variables",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#sass-variables",
    "title": "Miscellaneous",
    "section": "SASS variables",
    "text": "SASS variables\n\nSome examples include:\n\n$body-bg: The page background color.\n$link-color: The link color.\n$font-family-monospace: The monospace font family for the page.\n$callout-color-&lt;type&gt;: The colors for the various types of callouts.\n\nSee the full list at https://quarto.org/docs/output-formats/html-themes.html#sass-variables."
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#learn-more-1",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#learn-more-1",
    "title": "Miscellaneous",
    "section": "Learn more",
    "text": "Learn more\n\nquarto.org/docs/output-formats/html-themes.html"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#tip",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#tip",
    "title": "Miscellaneous",
    "section": "Tip",
    "text": "Tip\n\n\n\n\n\n\nFiguring out what to style\n\n\n\n\nUse your browser’s developer tools.\nRefer to the default values for SASS variables and set to something absurd (red and bold or giant size) while testing. Once you have the correct variable or rule identified, set the style values to what you want them to be."
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn-1",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn-1",
    "title": "Miscellaneous",
    "section": "Your turn",
    "text": "Your turn\n\nPick up where we left off and\n\nChange the theme of your project to one of the Bootswatch themes.\nAdd light / dark mode toggle, experimenting with different light and dark themes.\nStretch goal: Customize 1-2 elements of your theme.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn-2",
    "href": "courselist/case-studies-HF/x-miscellaneous/6-miscellaneous.html#your-turn-2",
    "title": "Miscellaneous",
    "section": "Your turn",
    "text": "Your turn\nto request!\n\nWhat other aspects / features of a Quarto website or book would you like to learn about?"
  },
  {
    "objectID": "courselist/case-studies-HF/LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "courselist/case-studies-HF/LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. __Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.t stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/tables-figures.html",
    "href": "courselist/case-studies-HF/exercises/tables-figures.html",
    "title": "Tables and figures",
    "section": "",
    "text": "Create a 3 row x 2 col markdown table, populate with a column for restaurant + column for cuisine, and then add 3 examples. Then, cross reference it from text.\nInclude and image from the images/ folder and set its width.\nAdd a figure generated from code and cross reference it."
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins.html",
    "href": "courselist/case-studies-HF/exercises/hello-penguins.html",
    "title": "Hello, Penguins!",
    "section": "",
    "text": "For this analysis we’ll use the penguins dataset from the palmerpenguins package.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.2.3\n\nlibrary(gt)"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins.html#data",
    "href": "courselist/case-studies-HF/exercises/hello-penguins.html#data",
    "title": "Hello, Penguins!",
    "section": "",
    "text": "For this analysis we’ll use the penguins dataset from the palmerpenguins package.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.2.3\n\nlibrary(gt)"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins.html#species",
    "href": "courselist/case-studies-HF/exercises/hello-penguins.html#species",
    "title": "Hello, Penguins!",
    "section": "Species",
    "text": "Species\nThe figure below is a bar plot of species of penguins.\n\nggplot(\n  penguins,\n  aes(\n    x = bill_length_mm, y = bill_depth_mm,\n    color = species, shape = species\n  )\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(x = \"Bill length (mm)\", y = \"Bill depth (mm)\") +\n  theme_minimal()"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins.html#penguins",
    "href": "courselist/case-studies-HF/exercises/hello-penguins.html#penguins",
    "title": "Hello, Penguins!",
    "section": "Penguins",
    "text": "Penguins\nThe table below shows the first 10 penguins from the dataset.\n\npenguins |&gt;\n  slice_head(n = 10) |&gt;\n  select(species, island, bill_length_mm, bill_depth_mm) |&gt;\n  gt()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n\n\nAdelie\nTorgersen\n39.5\n17.4\n\n\nAdelie\nTorgersen\n40.3\n18.0\n\n\nAdelie\nTorgersen\nNA\nNA\n\n\nAdelie\nTorgersen\n36.7\n19.3\n\n\nAdelie\nTorgersen\n39.3\n20.6\n\n\nAdelie\nTorgersen\n38.9\n17.8\n\n\nAdelie\nTorgersen\n39.2\n19.6\n\n\nAdelie\nTorgersen\n34.1\n18.1\n\n\nAdelie\nTorgersen\n42.0\n20.2"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/code-cells.html",
    "href": "courselist/case-studies-HF/exercises/code-cells.html",
    "title": "Code Cells",
    "section": "",
    "text": "library(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.2.3\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     col = island)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/index.html",
    "href": "courselist/case-studies-HF/7-wrap-up/index.html",
    "title": "Wrap-up",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/index.html#slides",
    "href": "courselist/case-studies-HF/7-wrap-up/index.html#slides",
    "title": "Wrap-up",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/index.html#exercises",
    "href": "courselist/case-studies-HF/7-wrap-up/index.html#exercises",
    "title": "Wrap-up",
    "section": "Exercises",
    "text": "Exercises\nThere are no exercises in this module."
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/index.html",
    "href": "courselist/case-studies-HF/6-articles/index.html",
    "title": "Articles",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/index.html#slides",
    "href": "courselist/case-studies-HF/6-articles/index.html#slides",
    "title": "Articles",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/index.html#exercises",
    "href": "courselist/case-studies-HF/6-articles/index.html#exercises",
    "title": "Articles",
    "section": "Exercises",
    "text": "Exercises\nThere are no starter files for the exercises in this module. You’ll create the files as part of the exercises."
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/index.html",
    "href": "courselist/case-studies-HF/5-books/index.html",
    "title": "Books",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/index.html#slides",
    "href": "courselist/case-studies-HF/5-books/index.html#slides",
    "title": "Books",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/index.html#exercises",
    "href": "courselist/case-studies-HF/5-books/index.html#exercises",
    "title": "Books",
    "section": "Exercises",
    "text": "Exercises\nFor exercises in this module we’ll use all the documents we’ve created so far."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/index.html",
    "href": "courselist/case-studies-HF/4-websites/index.html",
    "title": "Websites",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/index.html#slides",
    "href": "courselist/case-studies-HF/4-websites/index.html#slides",
    "title": "Websites",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/index.html#exercises",
    "href": "courselist/case-studies-HF/4-websites/index.html#exercises",
    "title": "Websites",
    "section": "Exercises",
    "text": "Exercises\nFor exercises in this module we’ll use all the documents we’ve created so far."
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/index.html",
    "href": "courselist/case-studies-HF/3-presentations/index.html",
    "title": "Presentations",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/index.html#slides",
    "href": "courselist/case-studies-HF/3-presentations/index.html#slides",
    "title": "Presentations",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/index.html#livecoding-artifacts",
    "href": "courselist/case-studies-HF/3-presentations/index.html#livecoding-artifacts",
    "title": "Presentations",
    "section": "Livecoding artifacts",
    "text": "Livecoding artifacts\nhello-penguins-slides.qmd"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/index.html",
    "href": "courselist/case-studies-HF/2-documents/index.html",
    "title": "Documents",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/index.html#slides",
    "href": "courselist/case-studies-HF/2-documents/index.html#slides",
    "title": "Documents",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/index.html",
    "href": "courselist/case-studies-HF/1-hello-quarto/index.html",
    "title": "Hello Quarto",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/index.html#slides",
    "href": "courselist/case-studies-HF/1-hello-quarto/index.html#slides",
    "title": "Hello Quarto",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html",
    "title": "Hello Quarto",
    "section": "",
    "text": "The American Statistical Association (ASA) is committed to providing an atmosphere in which personal respect and intellectual growth are valued and the free expression and exchange of ideas are encouraged. Consistent with this commitment, it is the policy of the ASA that all participants in ASA activities enjoy a welcoming environment free from unlawful discrimination, harassment, and retaliation. We strive to be a community that welcomes and supports people of all backgrounds and identities. This includes, but is not limited to, members of any race, ethnicity, culture, national origin, color, immigration status, social and economic class, educational level, sex, sexual orientation, gender identity and expression, age, size, family status, political belief, religion, and mental and physical ability.\n\n\n\nASA Code of Conduct"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#code-of-conduct",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#code-of-conduct",
    "title": "Hello Quarto",
    "section": "",
    "text": "The American Statistical Association (ASA) is committed to providing an atmosphere in which personal respect and intellectual growth are valued and the free expression and exchange of ideas are encouraged. Consistent with this commitment, it is the policy of the ASA that all participants in ASA activities enjoy a welcoming environment free from unlawful discrimination, harassment, and retaliation. We strive to be a community that welcomes and supports people of all backgrounds and identities. This includes, but is not limited to, members of any race, ethnicity, culture, national origin, color, immigration status, social and economic class, educational level, sex, sexual orientation, gender identity and expression, age, size, family status, political belief, religion, and mental and physical ability.\n\n\n\nASA Code of Conduct"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#expected-behavior",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#expected-behavior",
    "title": "Hello Quarto",
    "section": "Expected Behavior",
    "text": "Expected Behavior\n\nModel and support the norms of respect necessary to promote the conditions for healthy exchange of scientific ideas.\nIn speech or conduct, do not insult or disparage other participants.\nBe conscious of hierarchical structures, specifically the existence of stark power differentials between students, early career statisticians and established career statisticians—noting that fear of retaliation from more established statisticians can make it difficult for students and early career statisticians to express discomfort, rebuff unwelcome advances, and report violations of the conduct policy.\nBe sensitive to indications that may suggest that individuals are feeling unwelcome.\n\n\n\nASA Code of Conduct"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#about-me",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#about-me",
    "title": "Hello Quarto",
    "section": "About me",
    "text": "About me\n\n\nMine Çetinkaya-Rundel\n\nProfessor of the Practice\nDepartment of Statistical Science\nDuke University\nDeveloper Educator, Posit\n\nR Markdown user for 10+ years\n\nQuarto user for 2+ years\n\n\nAndrew Bray\n\nAssociate Teaching Professor\nDepartment of Statistics\nUC Berkeley\nR Markdown user for 10+ years\n\nQuarto user for 1+ years"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#about-you",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#about-you",
    "title": "Hello Quarto",
    "section": "About you",
    "text": "About you\n\nPlease share:\n\nName\nProfessional affiliaton\nWhat do you use R and R Markdown for?\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#meeting-you-where-you-are",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#meeting-you-where-you-are",
    "title": "Hello Quarto",
    "section": "Meeting you where you are",
    "text": "Meeting you where you are\n\n\n\nThese materials are pitched at someone who:\n\nknows some R + Markdown\nhas worked in RStudio\nwants to learn about Quarto\n\n\n\n\nI’ll teach you\n\nMore Markdown\nNew Quarto formats\nNew Quarto projects"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#workshop-structure",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#workshop-structure",
    "title": "Hello Quarto",
    "section": "Workshop structure",
    "text": "Workshop structure\n\nMy turn:\n\nLecture segments + live coding\nFeel free to just watch, take notes, browse docs, or tinker around in RStudio\n\nOur Turn:\n\nLive coding + follow along\nIf problems crop up for you, ask away, but I might ask you to hold on\n\nYour Turn: Practice exercises for you"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#checking-in-one-more-time",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#checking-in-one-more-time",
    "title": "Hello Quarto",
    "section": "Checking in one more time",
    "text": "Checking in one more time\n\n1. Software: Download and install the latest versions of R, RStudio, and Quarto:\n\nR 4.2.3 or above: https://cran.r-project.org\nRStudio 2023.09.0+448 or above: https://posit.co/download/rstudio-desktop\nQuarto 1.3.450: https://quarto.org/docs/get-started\n\n2. R Packages: Install the following packages:\n\npkg_list &lt;- c(\"tidyverse\", \"gt\", \"ggthemes\", \"palmerpenguins\", \n              \"quarto\", \"here\", \"usethis\")\ninstall.packages(pkg_list)\n\n3. Exercises: Download and open the exercises for this session. The easiest way is to run this line of R code at the console in RStudio.\n\nusethis::use_course(\"https://tinyurl.com/nashville-exercises\")\n\n\n. . .\n\nLet’s get started!"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto",
    "title": "Hello Quarto",
    "section": "Quarto …",
    "text": "Quarto …\n\nis a new, open-source, scientific, and technical publishing system.\n\n\n\n\nArtwork from “Hello, Quarto” keynote by Julia Lowndes and Mine Çetinkaya-Rundel, presented at RStudio Conference 2022. Illustrated by Allison Horst."
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto-1",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto-1",
    "title": "Hello Quarto",
    "section": "Quarto",
    "text": "Quarto\nWith Quarto you can weave together narrative text and code to produce elegantly formatted output as documents, web pages, blog posts, books and more.\n. . .\n\njust like R Markdown…\n. . .\n\nbut not just like it, there’s more to it…"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto-unifies-extends-r-markdown",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#quarto-unifies-extends-r-markdown",
    "title": "Hello Quarto",
    "section": "Quarto unifies + extends R Markdown",
    "text": "Quarto unifies + extends R Markdown\n\n\nConsistent implementation of attractive and handy features across outputs: tabsets, code-folding, syntax highlighting, etc.\nMore accessible defaults as well as better support for accessibility\nSupport for other languages like Python, Julia, Observable, and more via Jupyter engine for executable code chunks."
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#a-tour-of-quarto",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#a-tour-of-quarto",
    "title": "Hello Quarto",
    "section": "A tour of Quarto",
    "text": "A tour of Quarto\n\n\nSit back and enjoy!"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn",
    "title": "Hello Quarto",
    "section": "Your turn",
    "text": "Your turn\n\nOpen hello-penguins.qmd in RStudio and with the visual editor . . .\n\nRender the document.\nUpdate your name and re-render.\nInspect components of the document and make one more update and re-render.\nCompare notes with neighbors about updates you’ve made and note any aspects of the document that are not clear after the tour and your first interaction with it.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#revisit-what-is-quarto",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#revisit-what-is-quarto",
    "title": "Hello Quarto",
    "section": "Revisit: What is Quarto?",
    "text": "Revisit: What is Quarto?\nQuarto is a command line interface (CLI) that renders plain text formats (.qmd, .rmd, .md) OR mixed formats (.ipynb/Jupyter notebook) into static PDF/Word/HTML reports, books, websites, presentations and more.\n. . .\n\nandrewbray$ quarto --help\n\n  Usage:   quarto \n  Version: 1.3.450\n\n  Description:\n\n    Quarto CLI\n\n  Options:\n\n    -h, --help     - Show this help.                            \n    -V, --version  - Show the version number for this program.  \n\n  Commands:\n\n    render          [input] [args...]     - Render files or projects to various document types.        \n    preview         [file] [args...]      - Render and preview a document or website project.          \n    serve           [input]               - Serve a Shiny interactive document.                        \n    create          [type] [commands...]  - Create a Quarto project or extension                       \n    create-project  [dir]                 - Create a project for rendering multiple documents          \n    convert         &lt;input&gt;               - Convert documents to alternate representations.            \n    pandoc          [args...]             - Run the version of Pandoc embedded within Quarto.          \n    run             [script] [args...]    - Run a TypeScript, R, Python, or Lua script.                \n    add             &lt;extension&gt;           - Add an extension to this folder or project                 \n    install         [target...]           - Installs an extension or global dependency.                \n    publish         [provider] [path]     - Publish a document or project. Available providers include:\n    check           [target]              - Verify correct functioning of Quarto installation.         \n    help            [command]             - Show this help or the help of a sub-command."
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#under-the-hood",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#under-the-hood",
    "title": "Hello Quarto",
    "section": "Under the hood",
    "text": "Under the hood\n\n\nknitr or jupyter evaluates R/Python/Julia code and returns a .md file along with the evaluated code\nQuarto applies Lua filters + CSS/LaTeX which is then evaluated alongside the .md file by Pandoc and converted to a final output format"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#aside-lua-filters",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#aside-lua-filters",
    "title": "Hello Quarto",
    "section": "Aside: Lua filters",
    "text": "Aside: Lua filters\n\nHere is an example of a Lua filter that converts strong emphasis to small caps, from https://pandoc.org/lua-filters.html:\n\nreturn {\n  {\n    Strong = function (elem)\n      return pandoc.SmallCaps(elem.c)\n    end,\n  }\n}\n. . .\n\nLua filters written by R/Python/Julia developers should be interchangeable between formats - not language specific!\n\n. . .\n\nWe won’t go into the details of writing Lua filters in this workshop, and you don’t need to worry about learning about Lua filters unless you’re working on extending Quarto."
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#from-the-comfort-of-your-own-homeworkspace",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#from-the-comfort-of-your-own-homeworkspace",
    "title": "Hello Quarto",
    "section": "From the comfort of your own homeworkspace",
    "text": "From the comfort of your own homeworkspace"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#rendering",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#rendering",
    "title": "Hello Quarto",
    "section": "Rendering",
    "text": "Rendering\n\nOption 1: In RStudio with  as a background job, and preview the output.\n\n. . .\n\nOption 2: In the Terminal via quarto render:\n\n\nquarto render document.qmd # defaults to html\nquarto render document.qmd --to pdf\nquarto render document.qmd --to docx\n\n. . .\n\nOption 3: In the R console, via the quarto R package:\n\n\nlibrary(quarto)\n\nquarto_render(\"document.qmd\") # defaults to html\nquarto_render(\"document.qmd\", output_format = \"pdf\")"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn-1",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn-1",
    "title": "Hello Quarto",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen the last .qmd file you were working on in RStudio.\nCompare behavior of rendering with\n\nRStudio &gt; Render,\nusing the CLI with quarto render, and\nin the R console via quarto_render().\n\nIf you’re an RStudio user, brainstorm why you might still want to know about the other two ways of rendering Quarto documents.\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#one-install-batteries-included",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#one-install-batteries-included",
    "title": "Hello Quarto",
    "section": "One install, “Batteries included”",
    "text": "One install, “Batteries included”\n\nRMarkdown grew into a large ecosystem, with varying syntax.\n\n. . .\n\nQuarto comes “batteries included” straight out of the box\n\nHTML reports and websites\nPDF reports\nMS Office (Word, Powerpoint)\nPresentations (Powerpoint, Beamer, revealjs)\nBooks\n\n\n. . .\n\nAny language, exact same approach and syntax"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#many-quarto-formats",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#many-quarto-formats",
    "title": "Hello Quarto",
    "section": "Many Quarto formats",
    "text": "Many Quarto formats\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nBasic Formats\nhtml_document\npdf_document\nword_document\nhtml\npdf\ndocx\n\n\nBeamer\nbeamer_presentation\nbeamer\n\n\nPowerPoint\npowerpoint_presentation\npptx\n\n\nHTML Slides\nxaringan\nioslides\nrevealjs\nrevealjs\n\n\nAdvanced Layout\ntufte\ndistill\nQuarto Article Layout"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#many-quarto-formats-1",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#many-quarto-formats-1",
    "title": "Hello Quarto",
    "section": "Many Quarto formats",
    "text": "Many Quarto formats\n\n\n\nFeature\nR Markdown\nQuarto\n\n\n\n\nCross References\nhtml_document2\npdf_document2\nword_document2\nQuarto Crossrefs\n\n\nWebsites & Blogs\nblogdown\ndistill\nQuarto Websites\nQuarto Blogs\n\n\nBooks\nbookdown\nQuarto Books\n\n\nInteractivity\nShiny Documents\nQuarto Interactive Documents\n\n\nJournal Articles\nrticles\nJournal Articles\n\n\nDashboards\nflexdashboard\nComing soon!"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#what-about-r-markdown",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#what-about-r-markdown",
    "title": "Hello Quarto",
    "section": "What about R Markdown?",
    "text": "What about R Markdown?\n\n\nYou can render existing R Markdown documents with Quarto and you can rename them to .qmd files to turn them into Quarto documents.\nYou don’t have to do this – R Markdown continues to be maintained.\nHowever, Quarto\n\nOffers “batteries included” shared syntax across formats\nAllows you to choose your own editor and your preferred data science language\nComes with richer features out of the box\nIs actively developed"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#questions",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#questions",
    "title": "Hello Quarto",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review before we wrap up this module?"
  },
  {
    "objectID": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn-2",
    "href": "courselist/case-studies-HF/1-hello-quarto/1-hello-quarto.html#your-turn-2",
    "title": "Hello Quarto",
    "section": "Your turn",
    "text": "Your turn\n\nIn RStudio, go to File &gt; New File &gt; Quarto document to create a Quarto document with HTML output. Render the document, which will ask you to give it a name – you can use my-first-document.qmd.\nUse the visual editor for the next steps.\n\nAdd a title and your name as the author.\nCreate two sections, one with things you would like to use Quarto for and a second with your favorite thing about R.\nAdd a table of contents.\nStretch goal: Change the html theme to sketchy.\n\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html",
    "title": "Documents",
    "section": "",
    "text": "Where does the name “Quarto” come from?\n\n. . .\n\n\n\nSource: https://en.wikipedia.org/wiki/Quarto"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#section",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#section",
    "title": "Documents",
    "section": "",
    "text": "Where does the name “Quarto” come from?\n\n. . .\n\n\n\nSource: https://en.wikipedia.org/wiki/Quarto"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#components",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#components",
    "title": "Documents",
    "section": "Components",
    "text": "Components\n\nMetadata: YAML\nText: Markdown\nCode: Executed via knitr or jupyter\n\n. . .\nWeave it all together, and you have beautiful, powerful, and useful outputs!"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#literate-programming",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#literate-programming",
    "title": "Documents",
    "section": "Literate programming",
    "text": "Literate programming\nLiterate programming is writing out the program logic in a human language with included code snippets (separated by a primitive markup) and macros.\n---\ntitle: \"ggplot2 demo\"\ndate: \"5/19/2023\"\nformat: html\n---\n\n## MPG\n\nThere is a relationship between city and highway mileage.\n\n```{r}\n#| label: fig-mpg\n\nlibrary(ggplot2)\n\nggplot(mpg, aes(x = cty, y = hwy)) + \n  geom_point() + \n  geom_smooth(method = \"loess\")\n```\n\n\nSource: https://en.wikipedia.org/wiki/Literate_programming"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#yaml",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#yaml",
    "title": "Documents",
    "section": "YAML",
    "text": "YAML\n“Yet Another Markup Language” or “YAML Ain’t Markup Language” is used to provide document level metadata …\n. . .\n… in key-value pairs,\n. . .\n… that can nest,\n. . .\n… are fussy about indentation,\n. . .\n… and are kept between ---.\n---\nkey: value\n---"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-output-options",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-output-options",
    "title": "Documents",
    "section": "Example: Output options",
    "text": "Example: Output options\n---\nformat: something\n---\n. . .\n\n---\nformat: html\n---\n---\nformat: pdf\n---\n---\nformat: revealjs\n---"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-indented-nesting",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-indented-nesting",
    "title": "Documents",
    "section": "Example: Indented nesting",
    "text": "Example: Indented nesting\nIndentation matters!\n---\nformat: \n  html:\n    toc: true\n    code-fold: true\n---"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#fussing-with-yaml-invalid",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#fussing-with-yaml-invalid",
    "title": "Documents",
    "section": "Fussing with YAML (invalid)",
    "text": "Fussing with YAML (invalid)\n\nInvalid: No space after :\n\n---\nformat:html\n---\n\nInvalid: Read as missing\n\n---\nformat:\nhtml\n---\n\nValid, but needs next object\n\n---\nformat: \n  html:\n---"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#fussing-with-yaml-valid",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#fussing-with-yaml-valid",
    "title": "Documents",
    "section": "Fussing with YAML (valid)",
    "text": "Fussing with YAML (valid)\nThere are multiple ways of formatting valid YAML:\n\nValid: There’s a space after :\n\nformat: html\n\nValid: There are 2 spaces a new line and no trailing :\n\nformat:\n  html\n\nValid: format: html with additional options made with proper indentation\n\nformat: \n  html:\n    toc: true"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#why-yaml",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#why-yaml",
    "title": "Documents",
    "section": "Why YAML?",
    "text": "Why YAML?\nTo avoid manually typing out all the options, every time when rendering via the CLI:\n. . .\nquarto render document.qmd --to html\n\n. . .\nquarto render document.qmd --to html -M code-fold:true\n\n. . .\nquarto render document.qmd --to html -M code-fold:true -P alpha:0.2 -P ratio:0.3"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#quarto-linting",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#quarto-linting",
    "title": "Documents",
    "section": "Quarto linting",
    "text": "Quarto linting\nLint, or a linter, is a static code analysis tool used to flag programming errors, bugs, stylistic errors and suspicious constructs.\n\n\n\n\n\n\n\n\n\n\nSource: https://en.wikipedia.org/wiki/Lint_(software)"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#quarto-yaml-intelligence",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#quarto-yaml-intelligence",
    "title": "Documents",
    "section": "Quarto YAML Intelligence",
    "text": "Quarto YAML Intelligence\nRStudio + VSCode provide rich tab-completion - start a word and tab to complete, or Ctrl + space to see all available options."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn",
    "title": "Documents",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen hello-penguins.qmd in RStudio.\nTry Ctrl + space to see the available YAML options.\nTry out the tab-completion of any options that sound interesting.\nYou can use the HTML reference as needed.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#list-of-valid-yaml-fields",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#list-of-valid-yaml-fields",
    "title": "Documents",
    "section": "List of valid YAML fields",
    "text": "List of valid YAML fields\n\nMany YAML fields are common across various outputs\nBut also each output type has its own set of valid YAML fields and options\nDefinitive list: quarto.org/docs/reference/formats/html"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#text-formatting",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#text-formatting",
    "title": "Documents",
    "section": "Text Formatting",
    "text": "Text Formatting\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n*italics* and **bold**\nitalics and bold\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#headings",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#headings",
    "title": "Documents",
    "section": "Headings",
    "text": "Headings\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n\n# Header 1\nHeader 1\n\n\n## Header 2\nHeader 2\n\n\n### Header 3\nHeader 3\n\n\n#### Header 4\nHeader 4\n\n\n##### Header 5\nHeader 5\n\n\n###### Header 6\nHeader 6"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#links",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#links",
    "title": "Documents",
    "section": "Links",
    "text": "Links\nThere are several types of “links” or hyperlinks.\n\n\nMarkdown\nYou can embed [named hyperlinks](https://quarto.org/),\ndirect urls like &lt;https://quarto.org/&gt;, and links to \n[other places](#quarto-anatomy) in \nthe document. The syntax is similar for embedding an\ninline image: ![Penguins playing with ball](images/penguins-quarto-ball.png).\n\nOutput\nYou can embed named hyperlinks, direct urls like https://quarto.org/, and links to other places in the document. The syntax is similar for embedding an inline image: ."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-figures",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-figures",
    "title": "Documents",
    "section": "Markdown figures",
    "text": "Markdown figures\n![Penguins playing with a Quarto ball](images/penguins-quarto-ball.png)\n\n\n\nPenguins playing with a Quarto ball"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-figures-with-options",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-figures-with-options",
    "title": "Documents",
    "section": "Markdown figures with options",
    "text": "Markdown figures with options\n\n\n![](images/penguins-quarto-ball.png){fig-align=\"left\" width=250}\n\n\n\n\n\n\n![](images/penguins-quarto-ball.png){fig-align=\"right\" width=250 fig-alt=\"Illustration of two penguins playing with a Quarto ball.\"}"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#lists",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#lists",
    "title": "Documents",
    "section": "Lists",
    "text": "Lists\nUnordered list:\n\n\nMarkdown:\n-   unordered list         \n    -   sub-item 1         \n    -   sub-item 1         \n        -   sub-sub-item 1 \n\nOutput\n\nunordered list\n\nsub-item 1\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\nOrdered list:\n\n\nMarkdown:\n1. ordered list            \n2. item 2                  \n   i. sub-item 1          \n      A.  sub-sub-item 1\n\nOutput\n\nordered list\n\nitem 2\n\nsub-item 1\n\nsub-sub-item 1"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#quotes",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#quotes",
    "title": "Documents",
    "section": "Quotes",
    "text": "Quotes\nMarkdown:\n&gt; Let us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do. \n&gt; - Donald Knuth, Literate Programming\n. . .\nOutput:\n\nLet us change our traditional attitude to the construction of programs: Instead of imagining that our main task is to instruct a computer what to do, let us concentrate rather on explaining to human beings what we want a computer to do. - Donald Knuth, Literate Programming\n\n\n\n“Literate Programming”, The Computer Journal 27 (1984), p. 97. (Reprinted in Literate Programming, 1992, p. 99.) Literate Programming (1984)"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-1",
    "title": "Documents",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen markdown-syntax.qmd in RStudio.\nFollow the instructions in the document for how to modify it.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-tables",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#markdown-tables",
    "title": "Documents",
    "section": "Markdown tables",
    "text": "Markdown tables\nMarkdown:\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n. . .\nOutput:\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables",
    "title": "Documents",
    "section": "Grid tables",
    "text": "Grid tables\nMarkdown:\n+---------------+---------------+--------------------+\n| Fruit         | Price         | Advantages         |\n+===============+===============+====================+\n| Bananas       | $1.34         | - built-in wrapper |\n|               |               | - bright color     |\n+---------------+---------------+--------------------+\n| Oranges       | $2.10         | - cures scurvy     |\n|               |               | - tasty            |\n+---------------+---------------+--------------------+\n\n: Sample grid table."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-1",
    "title": "Documents",
    "section": "Grid tables",
    "text": "Grid tables\nOutput:\n\nSample grid table.\n\n\n\n\n\n\n\nFruit\nPrice\nAdvantages\n\n\n\n\nBananas\n$1.34\n\nbuilt-in wrapper\nbright color\n\n\n\nOranges\n$2.10\n\ncures scurvy\ntasty"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-alignment",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-alignment",
    "title": "Documents",
    "section": "Grid tables: Alignment",
    "text": "Grid tables: Alignment\n\nAlignments can be specified as with pipe tables, by putting colons at the boundaries of the separator line after the header:\n\n+---------------+---------------+--------------------+\n| Right         | Left          | Centered           |\n+==============:+:==============+:==================:+\n| Bananas       | $1.34         | built-in wrapper   |\n+---------------+---------------+--------------------+\n. . .\n\nFor headerless tables, the colons go on the top line instead:\n\n+--------------:+:--------------+:------------------:+\n| Right         | Left          | Centered           |\n+---------------+---------------+--------------------+"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-authoring",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#grid-tables-authoring",
    "title": "Documents",
    "section": "Grid tables: Authoring",
    "text": "Grid tables: Authoring\n\nNote that grid tables are quite awkward to write with a plain text editor because unlike pipe tables, the column indicators must align.\nThe Visual Editor can assist in making these tables!"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#tables-from-code",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#tables-from-code",
    "title": "Documents",
    "section": "Tables from code",
    "text": "Tables from code\nThe knitr package can turn data frames into tables with knitr::kable():\n\nlibrary(knitr)\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version\n4.2.3\n\nhead(penguins) |&gt; \n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#tables-from-code-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#tables-from-code-1",
    "title": "Documents",
    "section": "Tables from code",
    "text": "Tables from code\nIf you want fancier tables, try the gt package and all that it offers!\n\nlibrary(gt)\n\nhead(penguins) |&gt; \n  gt() |&gt;\n  tab_style(\n    style = list(\n      cell_fill(color = \"pink\"),\n      cell_text(style = \"italic\")\n      ),\n    locations = cells_body(\n      columns = bill_length_mm,\n      rows = bill_length_mm &gt; 40\n    )\n  )\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#cross-references-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#cross-references-1",
    "title": "Documents",
    "section": "Cross references",
    "text": "Cross references\n\nHelp readers to navigate your document with numbered references and hyperlinks to entities like figures and tables.\nCross referencing steps:\n\nAdd a caption to your figure or table.\nGive an id to your figure or table, starting with fig- or tbl-.\nRefer to it with @fig-... or @tbl-...."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#figure-cross-references",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#figure-cross-references",
    "title": "Documents",
    "section": "Figure cross references",
    "text": "Figure cross references\nThe presence of the caption (Blue penguin) and label (#fig-blue-penguin) make this figure referenceable:\n\n\nMarkdown:\nSee @fig-blue-penguin for a cute blue penguin.\n![Blue penguin](images/blue-penguin.png){#fig-blue-penguin}\n\nOutput:\nSee Figure 1 for a cute blue penguin.\n\n\n\n\n\n\nFigure 1: Blue Penguin"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#table-cross-references-from-code",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#table-cross-references-from-code",
    "title": "Documents",
    "section": "Table cross references (from code)",
    "text": "Table cross references (from code)\nThe presence of the caption (A few penguins) and label (#tbl-penguins) make this table referenceable:\n\n\nMarkdown:\nSee @tbl-penguins for data on a few penguins.\n\n```{r}\n#| label: tbl-penguins\n#| tbl-cap: A few penguins\n\nhead(penguins) |&gt; \n  gt()\n```\n\nOutput:\nSee Table 1 for data on a few penguins.\n\nhead(penguins) |&gt; \n  gt()\n\n\n\nTable 1: A few penguins\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#table-cross-references-from-markdown",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#table-cross-references-from-markdown",
    "title": "Documents",
    "section": "Table cross references (from markdown)",
    "text": "Table cross references (from markdown)\nThe presence of the caption (A few penguins) and label (#tbl-penguins) make this table referenceable:\n\n\nMarkdown:\nSee @tbl-numbers for data on a few penguins.\n\n| Right | Left |\n|------:|:-----|\n|   12  |  12  |\n|  123  |  123 |\n\n: An array of numbers {#tbl-numbers}\n\nOutput:\nSee Table 2 for data on a few penguins.\n\n\n\nTable 2: An array of numbers\n\n\n\n\n\nRight\nLeft\n\n\n\n\n12\n12\n\n\n123\n123"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-2",
    "title": "Documents",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen tables-figures.qmd.\nFollow the instructions in the document.\nExchange one new thing you’ve learned with your neighbor.\n\n\n\n\n\n−+\n08:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#section-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#section-1",
    "title": "Documents",
    "section": "",
    "text": "What you’re about to see . . .\n\nExtends the type of elements you can add to a doc\nWill work across the main output formats (html, pdf, docx, pptx)\n\n\n\n\nIngredients\nFenced Div and Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-1",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-2",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-3",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-3",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-4",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-4",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-5",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-bracketed-span-5",
    "title": "Documents",
    "section": "The Bracketed Span",
    "text": "The Bracketed Span"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-fenced-div",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-fenced-div",
    "title": "Documents",
    "section": "The Fenced Div",
    "text": "The Fenced Div"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-callout-blocks",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-callout-blocks",
    "title": "Documents",
    "section": "Example: Callout Blocks",
    "text": "Example: Callout Blocks\nUse case: highlight content for the reader in multiple formats.\n\n\n\nMarkdown\n:::{.callout-note}\nLook - a squirrel!\n:::\n\n:::{.callout-important}\nLook - a squirrel!\n:::\n\n:::{.callout-tip}\nLook - a squirrel!\n:::\n\n\n\nHTML output\n\n\n\n\n\n\nNote\n\n\n\nLook - a squirrel!\n\n\n\n\n\n\n\n\nImportant\n\n\n\nLook - a squirrel!\n\n\n\n\n\n\n\n\nTip\n\n\n\nLook - a squirrel!"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#callout-blocks",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#callout-blocks",
    "title": "Documents",
    "section": "Callout Blocks",
    "text": "Callout Blocks\nHighlight content for the reader in multiple formats.\n\n\n\nMarkdown\n:::{.callout-note}\nLook - a squirrel!\n:::\n\n:::{.callout-important}\nLook - a squirrel!\n:::\n\n:::{.callout-tip}\nLook - a squirrel!\n:::\n\n\n\npdf output"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#callout-blocks-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#callout-blocks-1",
    "title": "Documents",
    "section": "Callout Blocks",
    "text": "Callout Blocks\nHighlight content for the reader in multiple formats.\n\n\n\nMarkdown\n:::{.callout-note}\nLook - a squirrel!\n:::\n\n:::{.callout-important}\nLook - a squirrel!\n:::\n\n:::{.callout-tip}\nLook - a squirrel!\n:::\n\n\n\ndocx output"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-3",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-3",
    "title": "Documents",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen callout-boxes.qmd and render the document.\nChange the type of the first callout box and then re-render. Also try adding attributes inside { } to learn what they do.\n\nicon=true or icon=false.\nappearance=\"simple\" (can also try \"minimal\" and \"default\").\n\nMake the second callout box collapsible.\nChange the format to PDF and re-render.\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#r-markdowns-code-chunk",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#r-markdowns-code-chunk",
    "title": "Documents",
    "section": "R Markdown’s Code Chunk",
    "text": "R Markdown’s Code Chunk\n\n\n\n\n```{r, echo=FALSE}\nrnorm(3)\n```\n\n\n\n\n. . .\n\nWhat syntax is being used in echo=FALSE?\n\nHTML\nPandoc attribute syntax\nYAML\nCSS\nR"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk",
    "title": "Documents",
    "section": "Generalizing the Code Chunk",
    "text": "Generalizing the Code Chunk\nHow can this be generalized to other languages?\n\n\n```{r, echo=FALSE}\nrnorm(3)\n```"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk-1",
    "title": "Documents",
    "section": "Generalizing the Code Chunk",
    "text": "Generalizing the Code Chunk\nHow can this be generalized to other languages?\n\n\n```{language, echo=FALSE}\ncode\n```\n\n\nExecutable code flagged by {}\nSupport R, Python, Julia\nAlso support mermaid and dot diagram languages."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#generalizing-the-code-chunk-2",
    "title": "Documents",
    "section": "Generalizing the Code Chunk",
    "text": "Generalizing the Code Chunk\nHow can this be generalized to other languages?\n\n\n```{language}\n#| echo: false\n\ncode\n```\n\n\nExecutable code flagged by {}\nSupport R, Python, Julia\nAlso support mermaid and dot diagram languages1\nCell options live inside the cell after #| (the hash pipe!)2\n\n\nThis is a Quarto Code Cell."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#the-perks-of-the-hashpipe",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#the-perks-of-the-hashpipe",
    "title": "Documents",
    "section": "The Perks of the Hashpipe #|",
    "text": "The Perks of the Hashpipe #|\n\n\nLine breaks prevent chunk options that go on {r, and=on, and=on, and=on, and=on, and=on, and=on}\n\n\n\n\nChunk options are now pan-language with &lt;commentchar&gt;|.\n\n\n\n```{python}\n#| echo: false\n```\n\n```{mermaid}\n%%| echo: false\n```\n\n\n\n\n\nNo more yelling! (eval=FALSE)"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#execution-options",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#execution-options",
    "title": "Documents",
    "section": "Execution Options",
    "text": "Execution Options\nControl how the code is executed with options.\n\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output.\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block)."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#section-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#section-2",
    "title": "Documents",
    "section": "",
    "text": "Don’t forget to use cmd-space to see the available options!"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml",
    "title": "Documents",
    "section": "From Cell Option to YAML",
    "text": "From Cell Option to YAML\n\n\n---\ntitle: My Doc\nformat: html\n---\n\n```{r}\n#| echo: true\n\npi + 1\n```"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-1",
    "title": "Documents",
    "section": "From Cell Option to YAML",
    "text": "From Cell Option to YAML\n\n\n---\ntitle: My Doc\nformat: html\nexecute:\n  echo: true\n---\n\n```{r}\npi + 1\n```\n\n\nOptions can be moved into YAML under the execute key to apply to all chunks. Exceptions to that option can be set cell-by-cell."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-2",
    "title": "Documents",
    "section": "From Cell Option to YAML",
    "text": "From Cell Option to YAML\n\n\n---\ntitle: My Doc\nformat: html\nexecute:\n  echo: true\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n```{r}\npi + 1\n```\n\n\nOptions can be moved into YAML under the execute key to apply to all chunks. Exceptions to that option can be set cell-by-cell.\nYou can also pass options via YAML to knitr through the knitr key3."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-3",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#from-cell-option-to-yaml-3",
    "title": "Documents",
    "section": "From Cell Option to YAML",
    "text": "From Cell Option to YAML\n\n\n---\ntitle: My Doc\nformat: html\nexecute:\n  echo: true\nknitr:\n  opts_chunk: \n    collapse: true\n    R.options:\n      digits: 2\n---\n\n```{r}\npi + 1\n```\n\n\nOptions can be moved into YAML under the execute key to apply to all chunks. Exceptions to that option can be set cell-by-cell.\nYou can also pass options via YAML to knitr through the knitr key4.\nYou can use knitr to pass options that control your R session."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code",
    "title": "Documents",
    "section": "Example: Figures from Code",
    "text": "Example: Figures from Code\n\n\n```{r}\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     col = island)) +\n  geom_point()\n```\n\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: Removed 2 rows containing missing values or values outside the\nscale range (`geom_point()`)."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code-1",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code-1",
    "title": "Documents",
    "section": "Example: Figures from Code",
    "text": "Example: Figures from Code\n\n\n```{r}\n#| fig-width: 5\n#| fig-height: 3\n\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     col = island)) +\n  geom_point()\n```\n\n\n\nWarning: Removed 2 rows containing missing values or values outside the\nscale range (`geom_point()`)."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code-2",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#example-figures-from-code-2",
    "title": "Documents",
    "section": "Example: Figures from Code",
    "text": "Example: Figures from Code\n\n\n```{r}\n#| fig-width: 5\n#| fig-height: 3\n#| fig-cap: Size of penguins on three islands in the Palmer Archipelago.\n#| fig-alt: Scatterplot showing the bill sizes of penguins across three islands.\n\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\nggplot(penguins, aes(x = bill_length_mm,\n                     y = bill_depth_mm,\n                     col = island)) +\n  geom_point()\n```\n\n\n\nWarning: Removed 2 rows containing missing values or values outside the\nscale range (`geom_point()`).\n\n\n\n\n\nSize of penguins on three islands in the Palmer Archipelago.\n\n\n\n\n\n\n. . .\n\nSave time/code by moving figure sizing defaults up to the YAML."
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-4",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#your-turn-4",
    "title": "Documents",
    "section": "Your turn",
    "text": "Your turn\n\n\nOpen code-cells.qmd and render the document.\nAdd echo: false to the code cell and re-render.\nAdd more cell options by using Ctrl + Space after the #| or consult the Quarto Reference.\nAdd a second code cell (you can copy + paste the first), move your cell options to the YAML, and re-render.\n\n\n\n\n\n−+\n07:00"
  },
  {
    "objectID": "courselist/case-studies-HF/2-documents/2-documents.html#footnotes",
    "href": "courselist/case-studies-HF/2-documents/2-documents.html#footnotes",
    "title": "Documents",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee https://quarto.org/docs/authoring/diagrams.html.↩︎\nThe hash pipe is available in the R Markdown too.↩︎\nNo more ```{r setup}!↩︎\nNo more ```{r setup} :tada:↩︎"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html",
    "title": "Presentations",
    "section": "",
    "text": "Metadata: YAML\nText: Markdown\nCode: Executed via knitr or jupyter\n\n. . .\nWeave it all together, and you have a beautiful, functional slide deck!\n\n\n\n\nLet’s build a presentation together from hello-penguins-slides.qmd and showcase the following features of Quarto presentations:\n\nHierarchy, headers, and document outline\nIncremental lists\nColumns and tabsets\nCode, output location, code highlighting\nLogo and footer\nMaking things fit on a slide\nChalkboard\nPublishing your presentation to Quarto Pub\nPrinting to PDF\n\n\n\n\n\n\nPick up where we left off and\n\nChange the transition style between slides\nChange the slide size\nAdd slide numbers\n\n\n\n\n\n−+\n15:00\n\n\n\n\n\n\n\nLet’s continue building our a presentation together from hello-penguins-slides.qmd and showcase the following features of Quarto presentations:\n\nFragments\nAnimations\nTitle slide attributes\nSpeaker notes"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#components",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#components",
    "title": "Presentations",
    "section": "",
    "text": "Metadata: YAML\nText: Markdown\nCode: Executed via knitr or jupyter\n\n. . .\nWeave it all together, and you have a beautiful, functional slide deck!"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#our-turn",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#our-turn",
    "title": "Presentations",
    "section": "",
    "text": "Let’s build a presentation together from hello-penguins-slides.qmd and showcase the following features of Quarto presentations:\n\nHierarchy, headers, and document outline\nIncremental lists\nColumns and tabsets\nCode, output location, code highlighting\nLogo and footer\nMaking things fit on a slide\nChalkboard\nPublishing your presentation to Quarto Pub\nPrinting to PDF"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#your-turn",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#your-turn",
    "title": "Presentations",
    "section": "",
    "text": "Pick up where we left off and\n\nChange the transition style between slides\nChange the slide size\nAdd slide numbers\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#our-turn-1",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#our-turn-1",
    "title": "Presentations",
    "section": "",
    "text": "Let’s continue building our a presentation together from hello-penguins-slides.qmd and showcase the following features of Quarto presentations:\n\nFragments\nAnimations\nTitle slide attributes\nSpeaker notes"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#quarto-presentation-formats",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#quarto-presentation-formats",
    "title": "Presentations",
    "section": "Quarto presentation formats",
    "text": "Quarto presentation formats\n\nrevealjs for HTML slides\n\nEssentially the replacement for xaringan, but with Pandoc-native syntax\n\nbeamer for LaTeX slides\nPowerPoint for when you have to collaborate via MS Office"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#learn-more",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#learn-more",
    "title": "Presentations",
    "section": "Learn more",
    "text": "Learn more\n\nquarto.org/docs/presentations"
  },
  {
    "objectID": "courselist/case-studies-HF/3-presentations/3-presentations.html#questions",
    "href": "courselist/case-studies-HF/3-presentations/3-presentations.html#questions",
    "title": "Presentations",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review before we wrap up this module?"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html",
    "title": "Websites",
    "section": "",
    "text": "A Quarto Project is a directory that contains a file called _quarto.yml.\n\n\n\n\n\n\nThis is a Quarto Project.\n\n\nThis is not.\n\n\n\n\n\n\nA YAML file with particular keys and values that Quarto recognizes. Unrecognized keys are ignored.\n\n\n_quarto.yml\n\nproject:\n  title: \"A Barebones Project\"\n\n\n\n\nA YAML file with particular keys and values that Quarto recognizes. Unrecognized keys are ignored.\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: _site\n  resources:\n    - \"/docs/download/_download.json\"\n    - \"/docs/download/_prerelease.json\"\n    - \"/_redirects\"\n\nwebsite:\n  title: \"Quarto\"\n  image: \"quarto-dark-bg.jpeg\"\n  favicon: \"favicon.png\"\n  google-analytics: \"G-FV9Z7SDZ0M\"\n  open-graph: true\n  twitter-card: true\n  site-url: https://quarto.org\n  repo-url: https://github.com/quarto-dev/quarto-web\n  issue-url: https://github.com/quarto-dev/quarto-cli/issues/new/choose\n  repo-actions: [edit, issue]\n  page-navigation: true\n  bread-crumbs: true\n  search:\n    show-item-context: true\n    type: overlay\n    algolia:\n      index-name: prod_QUARTO\n      application-id: ZPJB5I1QN7\n      search-only-api-key: 41be6c1e0a7fea4a51b107810facf577\n      analytics-events: true\n      show-logo: true\n  page-footer:\n    left: |\n      Proudly supported by\n      [![](https://www.rstudio.com/assets/img/posit-logo-fullcolor-TM.svg){fig-alt=\"Posit\" width=65px}](https://posit.co)\n    center:\n      - text: \"About\"\n        href: about.qmd\n      - text: \"FAQ\"\n        href: docs/faq/index.qmd\n      - text: \"License\"\n        href: license.qmd\n      - text: \"Trademark\"\n        href: trademark.qmd\n    right:\n      - icon: twitter\n        href: https://twitter.com/quarto_pub\n        aria-label: Quarto Twitter\n      - icon: github\n        href: https://github.com/quarto-dev/quarto-cli\n        aria-label: Quarto GitHub\n      - icon: rss\n        href: https://quarto.org/docs/blog/index.xml\n        aria-label: Quarto Blog RSS        \n  navbar:\n    background: light\n    logo: quarto.png\n    logo-alt: \"Quarto logo.\"\n    title: false\n    collapse-below: lg\n    left:\n      - text: \"Overview\"\n        href: index.qmd\n      - text: \"Get Started\"\n        href: docs/get-started/index.qmd\n      - text: \"Guide\"\n        href: docs/guide/index.qmd\n      - text: Extensions\n        href: docs/extensions/index.qmd\n      - text: \"Reference\"\n        href: docs/reference/index.qmd\n      - text: \"Gallery\"\n        href: docs/gallery/index.qmd\n      - text: \"Blog\"\n        href: docs/blog/index.qmd\n      - text: \"Help\"\n        menu:\n          - text: \"Report a Bug\"\n            icon: \"bug\"\n            href: \"https://github.com/quarto-dev/quarto-cli/issues\"\n          - text: \"Ask a Question\"\n            icon: \"chat-right-text\"\n            href: \"https://github.com/quarto-dev/quarto-cli/discussions\"\n          - text: \"FAQ\"\n            icon: \"question-circle\"\n            href: docs/faq/index.qmd\n    tools:\n      - icon: twitter\n        href: https://twitter.com/quarto_pub\n        text: Quarto Twitter\n      - icon: github\n        href: https://github.com/quarto-dev/quarto-cli\n        text: Quarto GitHub\n      - icon: rss\n        href: https://quarto.org/docs/blog/index.xml\n        text: Quarto Blog RSS        \n\n  sidebar:\n    - id: get-started\n      title: \"Get Started\"\n      style: \"floating\"\n      collapse-level: 2\n      align: left\n      contents:\n        - docs/get-started/index.qmd\n        - text: \"Tutorial: Hello, Quarto\"\n          href: docs/get-started/hello/\n        - text: \"Tutorial: Computations\"\n          href: docs/get-started/computations/\n        - text: \"Tutorial: Authoring\"\n          href: docs/get-started/authoring/\n\n    - id: guide\n      collapse-level: 1\n      contents:\n        - section: \"Guide\"\n          href: docs/guide/index.qmd\n          contents:\n          - section: \"Authoring\"\n            contents:\n              - docs/authoring/markdown-basics.qmd\n              - docs/authoring/figures.qmd\n              - docs/authoring/tables.qmd\n              - docs/authoring/diagrams.qmd\n              - docs/authoring/videos.qmd\n              - text: \"Jupyter Notebooks\"\n                href: docs/authoring/notebook-embed.qmd\n              - docs/authoring/callouts.qmd\n              - docs/authoring/code-annotation.qmd\n              - docs/authoring/article-layout.qmd\n              - section: \"Scholarly Writing\"\n                contents:\n                  - docs/authoring/front-matter.qmd\n                  - docs/authoring/title-blocks.qmd\n                  - docs/authoring/footnotes-and-citations.qmd\n                  - docs/authoring/cross-references.qmd\n                  - docs/authoring/create-citeable-articles.qmd\n                  - docs/authoring/appendices.qmd\n          - section: \"Computations\"\n            contents:\n              - docs/computations/python.qmd\n              - docs/computations/r.qmd\n              - docs/computations/julia.qmd\n              - docs/computations/ojs.qmd\n              - docs/computations/execution-options.qmd\n              - docs/computations/parameters.qmd\n          - section: \"Tools\"\n            contents:\n              - section: \"JupyterLab\"\n                contents:\n                  - text: \"JupyterLab Basics\"\n                    href: docs/tools/jupyter-lab.qmd\n                  - text: \"JupyterLab Extension\"\n                    href: docs/tools/jupyter-lab-extension.qmd\n              - section: \"RStudio IDE\"\n                contents: \n                  - text: \"RStudio Basics\"\n                    href: docs/tools/rstudio.qmd\n                  - section: \"Visual Editor\"\n                    href: docs/visual-editor/index.qmd\n                    contents:\n                      - text: Editor Basics\n                        href: docs/visual-editor/index.qmd\n                      - docs/visual-editor/technical.qmd\n                      - docs/visual-editor/content.qmd\n                      - docs/visual-editor/options.qmd\n                      - docs/visual-editor/markdown.qmd\n              - section: \"VS Code\"\n                href: docs/tools/vscode.qmd\n                contents:\n                  - text: \"VS Code Basics\"\n                    href: docs/tools/vscode.qmd\n                  - text: \"Visual Editor\"\n                    href: docs/visual-editor/vscode/index.qmd\n                  - text: \"Notebook Editor\"\n                    href: docs/tools/vscode-notebook.qmd\n                \n              - docs/tools/neovim.qmd\n              - docs/tools/text-editors.qmd\n          - section: \"Documents\"\n            contents:\n              - section: \"HTML\"\n                contents:\n                  - docs/output-formats/html-basics.qmd\n                  - docs/output-formats/html-code.qmd\n                  - docs/output-formats/html-themes.qmd\n                  - docs/output-formats/html-multi-format.qmd\n                  - docs/output-formats/html-publishing.qmd\n              - section: \"PDF\"\n                contents:\n                  - docs/output-formats/pdf-basics.qmd\n                  - docs/output-formats/pdf-engine.qmd\n              - section: \"MS Word\"\n                contents:\n                  - docs/output-formats/ms-word.qmd\n                  - docs/output-formats/ms-word-templates.qmd\n              - section: \"Markdown\"\n                contents:\n                  - docs/output-formats/gfm.qmd\n                  - docs/output-formats/hugo.qmd\n                  - docs/output-formats/docusaurus.qmd\n              - docs/output-formats/all-formats.qmd\n          - section: \"Presentations\"\n            contents:\n              - text: \"Overview\"\n                href: docs/presentations/index.qmd\n              - section: docs/presentations/revealjs/index.qmd\n                contents:\n                  - text: \"Reveal Basics\"\n                    href: docs/presentations/revealjs/index.qmd\n                  - docs/presentations/revealjs/presenting.qmd\n                  - docs/presentations/revealjs/advanced.qmd\n                  - docs/presentations/revealjs/themes.qmd\n              - docs/presentations/powerpoint.qmd\n              - docs/presentations/beamer.qmd\n          - section: \"Websites\"\n            href: docs/websites/website-basics.qmd\n            contents:\n              - docs/websites/website-basics.qmd\n              - docs/websites/website-navigation.qmd\n              - docs/websites/website-blog.qmd\n              - docs/websites/website-search.qmd\n              - docs/websites/website-tools.qmd\n              - docs/websites/website-about.qmd\n              - section: \"Listing Pages\"\n                href: docs/websites/website-listings.qmd\n                contents:\n                  - docs/websites/website-listings.qmd\n                  - docs/websites/website-listings-custom.qmd\n          - section: \"Books\"\n            href: docs/books/book-basics.qmd\n            contents:\n              - docs/books/book-basics.qmd\n              - docs/books/book-structure.qmd\n              - docs/books/book-crossrefs.qmd\n              - text: \"Customizing Output\"\n                href: docs/books/book-output.qmd\n          - section: \"Interactivity\"\n            contents:\n              - text: \"Overview\"\n                href: docs/interactive/index.qmd\n              - section: docs/interactive/ojs/index.qmd\n                contents:\n                  - text: \"Introduction\"\n                    href: docs/interactive/ojs/index.qmd\n                  - docs/interactive/ojs/libraries.qmd\n                  - docs/interactive/ojs/data-sources.qmd\n                  - docs/interactive/ojs/ojs-cells.qmd\n                  - docs/interactive/ojs/shiny.qmd\n                  - docs/interactive/ojs/code-reuse.qmd\n                  - section: \"Examples\"\n                    contents:\n                      - docs/interactive/ojs/examples/penguins.qmd\n                      - docs/interactive/ojs/examples/sunburst.qmd\n                      - docs/interactive/ojs/examples/arquero.qmd\n                      - docs/interactive/ojs/examples/population.qmd\n                      - docs/interactive/ojs/examples/noaa-co2.qmd\n                      - docs/interactive/ojs/examples/github.qmd\n                      - docs/interactive/ojs/examples/layout.qmd\n                      - section: \"Shiny\"\n                        contents:\n                          - text: \"K-Means\"\n                            href: https://jjallaire.shinyapps.io/kmeans-shiny-ojs/\n                          - text: \"Binning\"\n                            href: https://jjallaire.shinyapps.io/binning-shiny-ojs/\n                          - text: \"Data Binding\"\n                            href: https://jjallaire.shinyapps.io/data-shiny-ojs/\n                          - text: \"Covid Map\"\n                            href: https://jjallaire.shinyapps.io/covid19-bicartogram/\n              - section: docs/interactive/shiny/index.qmd\n                contents:\n                  - text: \"Introduction\"\n                    href: docs/interactive/shiny/index.qmd\n                  - docs/interactive/shiny/running.qmd\n                  - docs/interactive/shiny/execution.qmd\n                  - docs/interactive/shiny/resources.qmd\n                  - section: \"Examples\"\n                    contents:\n                      - text: \"Old Faithful\"\n                        href: https://jjallaire.shinyapps.io/shiny-old-faithful/\n                      - text: \"K-Means\"\n                        href: https://jjallaire.shinyapps.io/shiny-k-means/\n                      - text: \"Diamonds\"\n                        href: https://jjallaire.shinyapps.io/shiny-diamonds/\n              - section: \"Widgets\"\n                contents:\n                  - docs/interactive/widgets/jupyter.qmd\n                  - docs/interactive/widgets/htmlwidgets.qmd\n              - docs/interactive/layout.qmd\n          - section: \"Publishing\"\n            contents:\n              - docs/publishing/index.qmd\n              - docs/publishing/quarto-pub.qmd\n              - docs/publishing/github-pages.qmd\n              - docs/publishing/rstudio-connect.qmd\n              - docs/publishing/netlify.qmd\n              - docs/publishing/confluence.qmd\n              - docs/publishing/other.qmd\n              - text: \"Publishing with CI\"\n                href: docs/publishing/ci.qmd\n          - section: \"Projects\"\n            contents:\n              - docs/projects/quarto-projects.qmd\n              - docs/projects/code-execution.qmd\n              - docs/projects/profiles.qmd\n              - docs/projects/environment.qmd\n              - docs/projects/scripts.qmd\n              - docs/projects/virtual-environments.qmd\n          - section: \"Advanced\"\n            contents:\n              - docs/authoring/includes.qmd\n              - docs/authoring/variables.qmd\n              - docs/output-formats/page-layout.qmd\n              - docs/authoring/language.qmd\n              - docs/authoring/conditional.qmd\n              - docs/extensions/nbfilter.qmd\n    - id: extensions\n      title: \"Extensions\"\n      contents:\n        - \"---\"\n        - section: docs/extensions/index.qmd\n          contents: \n            - text: \"Shortcodes & Filters\"\n              href: docs/extensions/listing-filters.qmd\n            - text: \"Journal Articles\"\n              href: docs/extensions/listing-journals.qmd\n            - text: \"Custom Formats\"\n              href: docs/extensions/listing-formats.qmd\n            - text: \"Revealjs Extensions\"\n              href: docs/extensions/listing-revealjs.qmd\n            - docs/extensions/managing.qmd\n        - \"---\"\n        - section: docs/extensions/creating.qmd\n          contents:\n            - text: \"Overview\"\n              href: docs/extensions/creating.qmd\n            - docs/extensions/lua.qmd\n            - docs/extensions/lua-api.qmd\n            - text: \"Distribution\"\n              href: docs/extensions/distributing.qmd\n            - \"---\"\n            - text: \"Shortcodes\"\n              href: docs/extensions/shortcodes.qmd\n            - text: \"Filters\"\n              href: docs/extensions/filters.qmd\n            - section: \"Journal Articles\"\n              href: docs/journals/formats.qmd\n              contents:\n                - docs/journals/formats.qmd\n                - docs/journals/templates.qmd\n                - docs/journals/authors.qmd\n            - docs/extensions/formats.qmd\n            - docs/extensions/revealjs.qmd\n            - docs/extensions/project-types.qmd\n            - docs/extensions/starter-templates.qmd\n    - id: manuscripts\n      title: \"Manuscripts\"\n      style: \"floating\"\n      collapse-level: 2\n      align: left\n      contents:\n        - text: Manuscripts Overview\n          href: docs/manuscripts/index.qmd\n        - text: \"Authoring Manuscripts\"\n          contents: \n            - text: Jupyter Lab\n              href: docs/manuscripts/authoring/jupyterlab.qmd\n            - text: VS Code\n              href: docs/manuscripts/authoring/vscode.qmd\n            - text: RStudio\n              href: docs/manuscripts/authoring/rstudio.qmd\n        - text: \"Publishing Manuscripts\"\n          href: docs/manuscripts/publishing.qmd\n        - text: \"Next Steps\"\n          href: docs/manuscripts/next-steps.qmd\n        - text: \"---\"\n        - text: \"Manuscript Components\"\n          href: docs/manuscripts/components.qmd\n          \n        \n    - id: reference\n      title: \"Reference\"\n      collapse-level: 3\n      contents:\n        - section: \"Reference\"\n          href: docs/reference/index.qmd\n          contents:\n          - section: \"Formats\"\n            contents:\n              - text: \"HTML\"\n                href: docs/reference/formats/html.qmd\n              - text: \"PDF\"\n                href: docs/reference/formats/pdf.qmd\n              - text: \"MS Word\"\n                href: docs/reference/formats/docx.qmd\n              - text: \"OpenOffice\"\n                href: docs/reference/formats/odt.qmd\n              - text: \"ePub\"\n                href: docs/reference/formats/epub.qmd\n              - section: \"Presentations\"\n                contents:\n                  - text: \"Revealjs\"\n                    href: docs/reference/formats/presentations/revealjs.qmd\n                  - text: \"PowerPoint\"\n                    href: docs/reference/formats/presentations/pptx.qmd\n                  - text: \"Beamer\"\n                    href: docs/reference/formats/presentations/beamer.qmd\n              - section: \"Markdown\"\n                contents:\n                  - text: \"GitHub\"\n                    href: docs/reference/formats/markdown/gfm.qmd\n                  - text: \"CommonMark\"\n                    href: docs/reference/formats/markdown/commonmark.qmd\n                  - text: \"Markua\"\n                    href: docs/reference/formats/markdown/markua.qmd\n              - section: \"Wikis\"\n                contents:\n                  - text: \"MediaWiki\"\n                    href: docs/reference/formats/wiki/mediawiki.qmd\n                  - text: \"DokuWiki\"\n                    href: docs/reference/formats/wiki/dokuwiki.qmd\n                  - text: \"ZimWiki\"\n                    href: docs/reference/formats/wiki/zimwiki.qmd\n                  - text: \"Jira Wiki\"\n                    href: docs/reference/formats/wiki/jira.qmd\n                  - text: \"XWiki\"\n                    href: docs/reference/formats/wiki/xwiki.qmd\n              - section: \"More Formats\"\n                contents:\n                  - text: \"JATS\"\n                    href: docs/reference/formats/jats.qmd\n                  - text: \"Jupyter\"\n                    href: docs/reference/formats/ipynb.qmd\n                  - text: \"ConTeXt\"\n                    href: docs/reference/formats/context.qmd\n                  - text: \"RTF\"\n                    href: docs/reference/formats/rtf.qmd\n                  - text: \"reST\"\n                    href: docs/reference/formats/rst.qmd\n                  - text: \"AsciiDoc\"\n                    href: docs/reference/formats/asciidoc.qmd\n                  - text: \"Org-Mode\"\n                    href: docs/reference/formats/org.qmd\n                  - text: \"Muse\"\n                    href: docs/reference/formats/muse.qmd\n                  - text: \"GNU TexInfo\"\n                    href: docs/reference/formats/texinfo.qmd\n                  - text: \"Groff Man Page\"\n                    href: docs/reference/formats/man.qmd\n                  - text: \"Groff Manuscript\"\n                    href: docs/reference/formats/ms.qmd\n                  - text: \"Haddock markup\"\n                    href: docs/reference/formats/haddock.qmd\n                  - text: \"OPML\"\n                    href: docs/reference/formats/opml.qmd\n                  - text: \"Textile\"\n                    href: docs/reference/formats/textile.qmd\n                  - text: \"DocBook\"\n                    href: docs/reference/formats/docbook.qmd\n                  - text: \"InDesign\"\n                    href: docs/reference/formats/icml.qmd\n                  - text: \"TEI Simple\"\n                    href: docs/reference/formats/tei.qmd\n                  - text: \"FictionBook\"\n                    href: docs/reference/formats/fb2.qmd\n          - section: \"Code Cells\"\n            href: docs/reference/cells/index.qmd\n            contents:\n              - text: \"Jupyter\"\n                href: docs/reference/cells/cells-jupyter.qmd\n              - text: \"Knitr\"\n                href: docs/reference/cells/cells-knitr.qmd\n              - text: \"Observable\"\n                href: docs/reference/cells/cells-ojs.qmd\n          - section: \"Projects\"\n            contents:\n              - text: \"Options\"\n                href: docs/reference/projects/options.qmd\n              - text: \"Websites\"\n                href: docs/reference/projects/websites.qmd\n              - text: \"Books\"\n                href: docs/reference/projects/books.qmd\n          - section: \"More\"\n            contents:\n              - text: \"Dates\"\n                href: docs/reference/dates.qmd\n              - text: \"Globs\"\n                href: docs/reference/globs.qmd\n              - text: \"Citations\"\n                href: docs/reference/metadata/citation.qmd\n    - id: prerelease\n      title: \"Quarto 1.3\"\n      contents:\n        - section: \"Highlights\"\n          href: docs/prerelease/1.3/index.qmd\n          contents:\n            - text: \"Confluence Publishing\"\n              href: docs/publishing/confluence.qmd\n            - text: \"Multi-Format\"\n              href: docs/output-formats/html-multi-format.qmd\n            - text: \"Cell Embedding\"\n              href: docs/authoring/notebook-embed.qmd\n            - text: \"Grid Customization\"\n              href: docs/output-formats/page-layout.qmd#grid-customization\n            - text: \"Code Annotation\"\n              href: docs/authoring/code-annotation.qmd\n            - section: \"Quarto AST\"\n              href: docs/prerelease/1.3/ast.qmd\n              contents:\n                - text: Callouts\n                  href: docs/prerelease/1.3/custom-ast-nodes/callout.qmd\n                - text: Tabsets\n                  href: docs/prerelease/1.3/custom-ast-nodes/tabset.qmd\n                - text: Conditional Blocks\n                  href: docs/prerelease/1.3/custom-ast-nodes/conditional-block.qmd\n            - text: \"Mermaid Theming\"\n              href: docs/authoring/diagrams.qmd#mermaid-theming\n            - text: \"PDF Images\"\n              href: docs/prerelease/1.3/pdf.qmd\n            - text: \"`kbd` Shortcode\"\n              href: docs/authoring/markdown-basics.qmd#keyboard-shortcuts\n\nbibliography: references.bib\n\nformat:\n  html:\n    toc: true\n    theme:\n      light: [cosmo, theme.scss]\n    code-copy: true\n    code-overflow: wrap\n    css: styles.css\n    include-after-body: js.html\n    grid:\n      sidebar-width: 250px\n      body-width: 900px\n      margin-width: 300px\n\nfilters:\n  - filters/tools-tabset.lua\n\nfreeze: true\n\neditor: visual\n\nprofile:\n  group: \n    - [prerelease,rc]\n\n\n\n\n\n\n\nQuarto Projects determine how quarto render, quarto preview and quarto publish work when run inside the directory.\nRStudio Projects store configuration info for the IDE when working from the directory.\nA directory can have one or both!\n\n\n\n\n\n\n\n\n\n\n\nQuarto projects have a _quarto.yml file\nThe type field in this file indicates the type of project:\n\ndefault: Collection of documents\nwebsite: Websites (and blogs)\nbook: Books\nmanuscript: Manuscripts (Quarto 1.4+)\n\n\n\n\n\n\nWebsites are essentially format: html + a Quarto Project file\nBut a website is different than format: html in that it has multiple pages\nWebsites are our first exploration into Quarto Projects\nWebsites and books are very similar in that they associate multiple pages/resources into a connected resource\n\n\n\n\n\nLet’s build a website together from all of the documents we’ve created so far and highlight the following features of Quarto websites:\n\n_quarto.yml\nindex.qmd / landing page / change landing page\nNavigation\nFreeze\nThemes and dark theme toggle\nPublishing to QuartoPub\nAn aspect of the workshop webpage that you fancy?\n\n\n\n\n\n\nPick up where we left off and\n\nAdd an about page to the navigation and customize it.\nChange your theme.\nAdd a cross-reference to a figure on the same page as the reference.\nAdd a cross-reference to a figure on a different page as the reference.\n\n\n\n\n\n−+\n15:00\n\n\n\n\n\n\n\nLet’s now add a blog component to our website.\n\nAdd a folder called posts and create a few minimal blog post entries and collect these from a blog page using the listings feature.\nChange the style of listings."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#what-defines-a-quarto-project",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#what-defines-a-quarto-project",
    "title": "Websites",
    "section": "What defines a Quarto Project?",
    "text": "What defines a Quarto Project?\n\n\nA Quarto Project is a directory that contains a file called _quarto.yml.\n\n\n\n\n\n\nThis is a Quarto Project.\n\n\nThis is not."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quarto.yml",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quarto.yml",
    "title": "Websites",
    "section": "_quarto.yml",
    "text": "_quarto.yml\nA YAML file with particular keys and values that Quarto recognizes. Unrecognized keys are ignored.\n\n\n_quarto.yml\n\nproject:\n  title: \"A Barebones Project\""
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quarto.yml-1",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quarto.yml-1",
    "title": "Websites",
    "section": "_quarto.yml",
    "text": "_quarto.yml\nA YAML file with particular keys and values that Quarto recognizes. Unrecognized keys are ignored.\n\n\n_quarto.yml\n\nproject:\n  type: website\n  output-dir: _site\n  resources:\n    - \"/docs/download/_download.json\"\n    - \"/docs/download/_prerelease.json\"\n    - \"/_redirects\"\n\nwebsite:\n  title: \"Quarto\"\n  image: \"quarto-dark-bg.jpeg\"\n  favicon: \"favicon.png\"\n  google-analytics: \"G-FV9Z7SDZ0M\"\n  open-graph: true\n  twitter-card: true\n  site-url: https://quarto.org\n  repo-url: https://github.com/quarto-dev/quarto-web\n  issue-url: https://github.com/quarto-dev/quarto-cli/issues/new/choose\n  repo-actions: [edit, issue]\n  page-navigation: true\n  bread-crumbs: true\n  search:\n    show-item-context: true\n    type: overlay\n    algolia:\n      index-name: prod_QUARTO\n      application-id: ZPJB5I1QN7\n      search-only-api-key: 41be6c1e0a7fea4a51b107810facf577\n      analytics-events: true\n      show-logo: true\n  page-footer:\n    left: |\n      Proudly supported by\n      [![](https://www.rstudio.com/assets/img/posit-logo-fullcolor-TM.svg){fig-alt=\"Posit\" width=65px}](https://posit.co)\n    center:\n      - text: \"About\"\n        href: about.qmd\n      - text: \"FAQ\"\n        href: docs/faq/index.qmd\n      - text: \"License\"\n        href: license.qmd\n      - text: \"Trademark\"\n        href: trademark.qmd\n    right:\n      - icon: twitter\n        href: https://twitter.com/quarto_pub\n        aria-label: Quarto Twitter\n      - icon: github\n        href: https://github.com/quarto-dev/quarto-cli\n        aria-label: Quarto GitHub\n      - icon: rss\n        href: https://quarto.org/docs/blog/index.xml\n        aria-label: Quarto Blog RSS        \n  navbar:\n    background: light\n    logo: quarto.png\n    logo-alt: \"Quarto logo.\"\n    title: false\n    collapse-below: lg\n    left:\n      - text: \"Overview\"\n        href: index.qmd\n      - text: \"Get Started\"\n        href: docs/get-started/index.qmd\n      - text: \"Guide\"\n        href: docs/guide/index.qmd\n      - text: Extensions\n        href: docs/extensions/index.qmd\n      - text: \"Reference\"\n        href: docs/reference/index.qmd\n      - text: \"Gallery\"\n        href: docs/gallery/index.qmd\n      - text: \"Blog\"\n        href: docs/blog/index.qmd\n      - text: \"Help\"\n        menu:\n          - text: \"Report a Bug\"\n            icon: \"bug\"\n            href: \"https://github.com/quarto-dev/quarto-cli/issues\"\n          - text: \"Ask a Question\"\n            icon: \"chat-right-text\"\n            href: \"https://github.com/quarto-dev/quarto-cli/discussions\"\n          - text: \"FAQ\"\n            icon: \"question-circle\"\n            href: docs/faq/index.qmd\n    tools:\n      - icon: twitter\n        href: https://twitter.com/quarto_pub\n        text: Quarto Twitter\n      - icon: github\n        href: https://github.com/quarto-dev/quarto-cli\n        text: Quarto GitHub\n      - icon: rss\n        href: https://quarto.org/docs/blog/index.xml\n        text: Quarto Blog RSS        \n\n  sidebar:\n    - id: get-started\n      title: \"Get Started\"\n      style: \"floating\"\n      collapse-level: 2\n      align: left\n      contents:\n        - docs/get-started/index.qmd\n        - text: \"Tutorial: Hello, Quarto\"\n          href: docs/get-started/hello/\n        - text: \"Tutorial: Computations\"\n          href: docs/get-started/computations/\n        - text: \"Tutorial: Authoring\"\n          href: docs/get-started/authoring/\n\n    - id: guide\n      collapse-level: 1\n      contents:\n        - section: \"Guide\"\n          href: docs/guide/index.qmd\n          contents:\n          - section: \"Authoring\"\n            contents:\n              - docs/authoring/markdown-basics.qmd\n              - docs/authoring/figures.qmd\n              - docs/authoring/tables.qmd\n              - docs/authoring/diagrams.qmd\n              - docs/authoring/videos.qmd\n              - text: \"Jupyter Notebooks\"\n                href: docs/authoring/notebook-embed.qmd\n              - docs/authoring/callouts.qmd\n              - docs/authoring/code-annotation.qmd\n              - docs/authoring/article-layout.qmd\n              - section: \"Scholarly Writing\"\n                contents:\n                  - docs/authoring/front-matter.qmd\n                  - docs/authoring/title-blocks.qmd\n                  - docs/authoring/footnotes-and-citations.qmd\n                  - docs/authoring/cross-references.qmd\n                  - docs/authoring/create-citeable-articles.qmd\n                  - docs/authoring/appendices.qmd\n          - section: \"Computations\"\n            contents:\n              - docs/computations/python.qmd\n              - docs/computations/r.qmd\n              - docs/computations/julia.qmd\n              - docs/computations/ojs.qmd\n              - docs/computations/execution-options.qmd\n              - docs/computations/parameters.qmd\n          - section: \"Tools\"\n            contents:\n              - section: \"JupyterLab\"\n                contents:\n                  - text: \"JupyterLab Basics\"\n                    href: docs/tools/jupyter-lab.qmd\n                  - text: \"JupyterLab Extension\"\n                    href: docs/tools/jupyter-lab-extension.qmd\n              - section: \"RStudio IDE\"\n                contents: \n                  - text: \"RStudio Basics\"\n                    href: docs/tools/rstudio.qmd\n                  - section: \"Visual Editor\"\n                    href: docs/visual-editor/index.qmd\n                    contents:\n                      - text: Editor Basics\n                        href: docs/visual-editor/index.qmd\n                      - docs/visual-editor/technical.qmd\n                      - docs/visual-editor/content.qmd\n                      - docs/visual-editor/options.qmd\n                      - docs/visual-editor/markdown.qmd\n              - section: \"VS Code\"\n                href: docs/tools/vscode.qmd\n                contents:\n                  - text: \"VS Code Basics\"\n                    href: docs/tools/vscode.qmd\n                  - text: \"Visual Editor\"\n                    href: docs/visual-editor/vscode/index.qmd\n                  - text: \"Notebook Editor\"\n                    href: docs/tools/vscode-notebook.qmd\n                \n              - docs/tools/neovim.qmd\n              - docs/tools/text-editors.qmd\n          - section: \"Documents\"\n            contents:\n              - section: \"HTML\"\n                contents:\n                  - docs/output-formats/html-basics.qmd\n                  - docs/output-formats/html-code.qmd\n                  - docs/output-formats/html-themes.qmd\n                  - docs/output-formats/html-multi-format.qmd\n                  - docs/output-formats/html-publishing.qmd\n              - section: \"PDF\"\n                contents:\n                  - docs/output-formats/pdf-basics.qmd\n                  - docs/output-formats/pdf-engine.qmd\n              - section: \"MS Word\"\n                contents:\n                  - docs/output-formats/ms-word.qmd\n                  - docs/output-formats/ms-word-templates.qmd\n              - section: \"Markdown\"\n                contents:\n                  - docs/output-formats/gfm.qmd\n                  - docs/output-formats/hugo.qmd\n                  - docs/output-formats/docusaurus.qmd\n              - docs/output-formats/all-formats.qmd\n          - section: \"Presentations\"\n            contents:\n              - text: \"Overview\"\n                href: docs/presentations/index.qmd\n              - section: docs/presentations/revealjs/index.qmd\n                contents:\n                  - text: \"Reveal Basics\"\n                    href: docs/presentations/revealjs/index.qmd\n                  - docs/presentations/revealjs/presenting.qmd\n                  - docs/presentations/revealjs/advanced.qmd\n                  - docs/presentations/revealjs/themes.qmd\n              - docs/presentations/powerpoint.qmd\n              - docs/presentations/beamer.qmd\n          - section: \"Websites\"\n            href: docs/websites/website-basics.qmd\n            contents:\n              - docs/websites/website-basics.qmd\n              - docs/websites/website-navigation.qmd\n              - docs/websites/website-blog.qmd\n              - docs/websites/website-search.qmd\n              - docs/websites/website-tools.qmd\n              - docs/websites/website-about.qmd\n              - section: \"Listing Pages\"\n                href: docs/websites/website-listings.qmd\n                contents:\n                  - docs/websites/website-listings.qmd\n                  - docs/websites/website-listings-custom.qmd\n          - section: \"Books\"\n            href: docs/books/book-basics.qmd\n            contents:\n              - docs/books/book-basics.qmd\n              - docs/books/book-structure.qmd\n              - docs/books/book-crossrefs.qmd\n              - text: \"Customizing Output\"\n                href: docs/books/book-output.qmd\n          - section: \"Interactivity\"\n            contents:\n              - text: \"Overview\"\n                href: docs/interactive/index.qmd\n              - section: docs/interactive/ojs/index.qmd\n                contents:\n                  - text: \"Introduction\"\n                    href: docs/interactive/ojs/index.qmd\n                  - docs/interactive/ojs/libraries.qmd\n                  - docs/interactive/ojs/data-sources.qmd\n                  - docs/interactive/ojs/ojs-cells.qmd\n                  - docs/interactive/ojs/shiny.qmd\n                  - docs/interactive/ojs/code-reuse.qmd\n                  - section: \"Examples\"\n                    contents:\n                      - docs/interactive/ojs/examples/penguins.qmd\n                      - docs/interactive/ojs/examples/sunburst.qmd\n                      - docs/interactive/ojs/examples/arquero.qmd\n                      - docs/interactive/ojs/examples/population.qmd\n                      - docs/interactive/ojs/examples/noaa-co2.qmd\n                      - docs/interactive/ojs/examples/github.qmd\n                      - docs/interactive/ojs/examples/layout.qmd\n                      - section: \"Shiny\"\n                        contents:\n                          - text: \"K-Means\"\n                            href: https://jjallaire.shinyapps.io/kmeans-shiny-ojs/\n                          - text: \"Binning\"\n                            href: https://jjallaire.shinyapps.io/binning-shiny-ojs/\n                          - text: \"Data Binding\"\n                            href: https://jjallaire.shinyapps.io/data-shiny-ojs/\n                          - text: \"Covid Map\"\n                            href: https://jjallaire.shinyapps.io/covid19-bicartogram/\n              - section: docs/interactive/shiny/index.qmd\n                contents:\n                  - text: \"Introduction\"\n                    href: docs/interactive/shiny/index.qmd\n                  - docs/interactive/shiny/running.qmd\n                  - docs/interactive/shiny/execution.qmd\n                  - docs/interactive/shiny/resources.qmd\n                  - section: \"Examples\"\n                    contents:\n                      - text: \"Old Faithful\"\n                        href: https://jjallaire.shinyapps.io/shiny-old-faithful/\n                      - text: \"K-Means\"\n                        href: https://jjallaire.shinyapps.io/shiny-k-means/\n                      - text: \"Diamonds\"\n                        href: https://jjallaire.shinyapps.io/shiny-diamonds/\n              - section: \"Widgets\"\n                contents:\n                  - docs/interactive/widgets/jupyter.qmd\n                  - docs/interactive/widgets/htmlwidgets.qmd\n              - docs/interactive/layout.qmd\n          - section: \"Publishing\"\n            contents:\n              - docs/publishing/index.qmd\n              - docs/publishing/quarto-pub.qmd\n              - docs/publishing/github-pages.qmd\n              - docs/publishing/rstudio-connect.qmd\n              - docs/publishing/netlify.qmd\n              - docs/publishing/confluence.qmd\n              - docs/publishing/other.qmd\n              - text: \"Publishing with CI\"\n                href: docs/publishing/ci.qmd\n          - section: \"Projects\"\n            contents:\n              - docs/projects/quarto-projects.qmd\n              - docs/projects/code-execution.qmd\n              - docs/projects/profiles.qmd\n              - docs/projects/environment.qmd\n              - docs/projects/scripts.qmd\n              - docs/projects/virtual-environments.qmd\n          - section: \"Advanced\"\n            contents:\n              - docs/authoring/includes.qmd\n              - docs/authoring/variables.qmd\n              - docs/output-formats/page-layout.qmd\n              - docs/authoring/language.qmd\n              - docs/authoring/conditional.qmd\n              - docs/extensions/nbfilter.qmd\n    - id: extensions\n      title: \"Extensions\"\n      contents:\n        - \"---\"\n        - section: docs/extensions/index.qmd\n          contents: \n            - text: \"Shortcodes & Filters\"\n              href: docs/extensions/listing-filters.qmd\n            - text: \"Journal Articles\"\n              href: docs/extensions/listing-journals.qmd\n            - text: \"Custom Formats\"\n              href: docs/extensions/listing-formats.qmd\n            - text: \"Revealjs Extensions\"\n              href: docs/extensions/listing-revealjs.qmd\n            - docs/extensions/managing.qmd\n        - \"---\"\n        - section: docs/extensions/creating.qmd\n          contents:\n            - text: \"Overview\"\n              href: docs/extensions/creating.qmd\n            - docs/extensions/lua.qmd\n            - docs/extensions/lua-api.qmd\n            - text: \"Distribution\"\n              href: docs/extensions/distributing.qmd\n            - \"---\"\n            - text: \"Shortcodes\"\n              href: docs/extensions/shortcodes.qmd\n            - text: \"Filters\"\n              href: docs/extensions/filters.qmd\n            - section: \"Journal Articles\"\n              href: docs/journals/formats.qmd\n              contents:\n                - docs/journals/formats.qmd\n                - docs/journals/templates.qmd\n                - docs/journals/authors.qmd\n            - docs/extensions/formats.qmd\n            - docs/extensions/revealjs.qmd\n            - docs/extensions/project-types.qmd\n            - docs/extensions/starter-templates.qmd\n    - id: manuscripts\n      title: \"Manuscripts\"\n      style: \"floating\"\n      collapse-level: 2\n      align: left\n      contents:\n        - text: Manuscripts Overview\n          href: docs/manuscripts/index.qmd\n        - text: \"Authoring Manuscripts\"\n          contents: \n            - text: Jupyter Lab\n              href: docs/manuscripts/authoring/jupyterlab.qmd\n            - text: VS Code\n              href: docs/manuscripts/authoring/vscode.qmd\n            - text: RStudio\n              href: docs/manuscripts/authoring/rstudio.qmd\n        - text: \"Publishing Manuscripts\"\n          href: docs/manuscripts/publishing.qmd\n        - text: \"Next Steps\"\n          href: docs/manuscripts/next-steps.qmd\n        - text: \"---\"\n        - text: \"Manuscript Components\"\n          href: docs/manuscripts/components.qmd\n          \n        \n    - id: reference\n      title: \"Reference\"\n      collapse-level: 3\n      contents:\n        - section: \"Reference\"\n          href: docs/reference/index.qmd\n          contents:\n          - section: \"Formats\"\n            contents:\n              - text: \"HTML\"\n                href: docs/reference/formats/html.qmd\n              - text: \"PDF\"\n                href: docs/reference/formats/pdf.qmd\n              - text: \"MS Word\"\n                href: docs/reference/formats/docx.qmd\n              - text: \"OpenOffice\"\n                href: docs/reference/formats/odt.qmd\n              - text: \"ePub\"\n                href: docs/reference/formats/epub.qmd\n              - section: \"Presentations\"\n                contents:\n                  - text: \"Revealjs\"\n                    href: docs/reference/formats/presentations/revealjs.qmd\n                  - text: \"PowerPoint\"\n                    href: docs/reference/formats/presentations/pptx.qmd\n                  - text: \"Beamer\"\n                    href: docs/reference/formats/presentations/beamer.qmd\n              - section: \"Markdown\"\n                contents:\n                  - text: \"GitHub\"\n                    href: docs/reference/formats/markdown/gfm.qmd\n                  - text: \"CommonMark\"\n                    href: docs/reference/formats/markdown/commonmark.qmd\n                  - text: \"Markua\"\n                    href: docs/reference/formats/markdown/markua.qmd\n              - section: \"Wikis\"\n                contents:\n                  - text: \"MediaWiki\"\n                    href: docs/reference/formats/wiki/mediawiki.qmd\n                  - text: \"DokuWiki\"\n                    href: docs/reference/formats/wiki/dokuwiki.qmd\n                  - text: \"ZimWiki\"\n                    href: docs/reference/formats/wiki/zimwiki.qmd\n                  - text: \"Jira Wiki\"\n                    href: docs/reference/formats/wiki/jira.qmd\n                  - text: \"XWiki\"\n                    href: docs/reference/formats/wiki/xwiki.qmd\n              - section: \"More Formats\"\n                contents:\n                  - text: \"JATS\"\n                    href: docs/reference/formats/jats.qmd\n                  - text: \"Jupyter\"\n                    href: docs/reference/formats/ipynb.qmd\n                  - text: \"ConTeXt\"\n                    href: docs/reference/formats/context.qmd\n                  - text: \"RTF\"\n                    href: docs/reference/formats/rtf.qmd\n                  - text: \"reST\"\n                    href: docs/reference/formats/rst.qmd\n                  - text: \"AsciiDoc\"\n                    href: docs/reference/formats/asciidoc.qmd\n                  - text: \"Org-Mode\"\n                    href: docs/reference/formats/org.qmd\n                  - text: \"Muse\"\n                    href: docs/reference/formats/muse.qmd\n                  - text: \"GNU TexInfo\"\n                    href: docs/reference/formats/texinfo.qmd\n                  - text: \"Groff Man Page\"\n                    href: docs/reference/formats/man.qmd\n                  - text: \"Groff Manuscript\"\n                    href: docs/reference/formats/ms.qmd\n                  - text: \"Haddock markup\"\n                    href: docs/reference/formats/haddock.qmd\n                  - text: \"OPML\"\n                    href: docs/reference/formats/opml.qmd\n                  - text: \"Textile\"\n                    href: docs/reference/formats/textile.qmd\n                  - text: \"DocBook\"\n                    href: docs/reference/formats/docbook.qmd\n                  - text: \"InDesign\"\n                    href: docs/reference/formats/icml.qmd\n                  - text: \"TEI Simple\"\n                    href: docs/reference/formats/tei.qmd\n                  - text: \"FictionBook\"\n                    href: docs/reference/formats/fb2.qmd\n          - section: \"Code Cells\"\n            href: docs/reference/cells/index.qmd\n            contents:\n              - text: \"Jupyter\"\n                href: docs/reference/cells/cells-jupyter.qmd\n              - text: \"Knitr\"\n                href: docs/reference/cells/cells-knitr.qmd\n              - text: \"Observable\"\n                href: docs/reference/cells/cells-ojs.qmd\n          - section: \"Projects\"\n            contents:\n              - text: \"Options\"\n                href: docs/reference/projects/options.qmd\n              - text: \"Websites\"\n                href: docs/reference/projects/websites.qmd\n              - text: \"Books\"\n                href: docs/reference/projects/books.qmd\n          - section: \"More\"\n            contents:\n              - text: \"Dates\"\n                href: docs/reference/dates.qmd\n              - text: \"Globs\"\n                href: docs/reference/globs.qmd\n              - text: \"Citations\"\n                href: docs/reference/metadata/citation.qmd\n    - id: prerelease\n      title: \"Quarto 1.3\"\n      contents:\n        - section: \"Highlights\"\n          href: docs/prerelease/1.3/index.qmd\n          contents:\n            - text: \"Confluence Publishing\"\n              href: docs/publishing/confluence.qmd\n            - text: \"Multi-Format\"\n              href: docs/output-formats/html-multi-format.qmd\n            - text: \"Cell Embedding\"\n              href: docs/authoring/notebook-embed.qmd\n            - text: \"Grid Customization\"\n              href: docs/output-formats/page-layout.qmd#grid-customization\n            - text: \"Code Annotation\"\n              href: docs/authoring/code-annotation.qmd\n            - section: \"Quarto AST\"\n              href: docs/prerelease/1.3/ast.qmd\n              contents:\n                - text: Callouts\n                  href: docs/prerelease/1.3/custom-ast-nodes/callout.qmd\n                - text: Tabsets\n                  href: docs/prerelease/1.3/custom-ast-nodes/tabset.qmd\n                - text: Conditional Blocks\n                  href: docs/prerelease/1.3/custom-ast-nodes/conditional-block.qmd\n            - text: \"Mermaid Theming\"\n              href: docs/authoring/diagrams.qmd#mermaid-theming\n            - text: \"PDF Images\"\n              href: docs/prerelease/1.3/pdf.qmd\n            - text: \"`kbd` Shortcode\"\n              href: docs/authoring/markdown-basics.qmd#keyboard-shortcuts\n\nbibliography: references.bib\n\nformat:\n  html:\n    toc: true\n    theme:\n      light: [cosmo, theme.scss]\n    code-copy: true\n    code-overflow: wrap\n    css: styles.css\n    include-after-body: js.html\n    grid:\n      sidebar-width: 250px\n      body-width: 900px\n      margin-width: 300px\n\nfilters:\n  - filters/tools-tabset.lua\n\nfreeze: true\n\neditor: visual\n\nprofile:\n  group: \n    - [prerelease,rc]"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-project-vs-rstudio-project",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-project-vs-rstudio-project",
    "title": "Websites",
    "section": "Quarto Project vs RStudio Project",
    "text": "Quarto Project vs RStudio Project\n\n\n\nQuarto Projects determine how quarto render, quarto preview and quarto publish work when run inside the directory.\nRStudio Projects store configuration info for the IDE when working from the directory.\nA directory can have one or both!"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-projects",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-projects",
    "title": "Websites",
    "section": "Quarto projects",
    "text": "Quarto projects\n\nQuarto projects have a _quarto.yml file\nThe type field in this file indicates the type of project:\n\ndefault: Collection of documents\nwebsite: Websites (and blogs)\nbook: Books\nmanuscript: Manuscripts (Quarto 1.4+)"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-websites",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quarto-websites",
    "title": "Websites",
    "section": "Quarto websites",
    "text": "Quarto websites\n\nWebsites are essentially format: html + a Quarto Project file\nBut a website is different than format: html in that it has multiple pages\nWebsites are our first exploration into Quarto Projects\nWebsites and books are very similar in that they associate multiple pages/resources into a connected resource"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#our-turn",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#our-turn",
    "title": "Websites",
    "section": "Our turn",
    "text": "Our turn\n\nLet’s build a website together from all of the documents we’ve created so far and highlight the following features of Quarto websites:\n\n_quarto.yml\nindex.qmd / landing page / change landing page\nNavigation\nFreeze\nThemes and dark theme toggle\nPublishing to QuartoPub\nAn aspect of the workshop webpage that you fancy?"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#your-turn",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#your-turn",
    "title": "Websites",
    "section": "Your turn",
    "text": "Your turn\n\nPick up where we left off and\n\nAdd an about page to the navigation and customize it.\nChange your theme.\nAdd a cross-reference to a figure on the same page as the reference.\nAdd a cross-reference to a figure on a different page as the reference.\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#our-turn-1",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#our-turn-1",
    "title": "Websites",
    "section": "Our turn",
    "text": "Our turn\n\nLet’s now add a blog component to our website.\n\nAdd a folder called posts and create a few minimal blog post entries and collect these from a blog page using the listings feature.\nChange the style of listings."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#when-should-code-be-re-run",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#when-should-code-be-re-run",
    "title": "Websites",
    "section": "When should code be re-run?",
    "text": "When should code be re-run?\n\n\nYou might have a reason to re-run all code in a Quarto website (every single chunk in every single document) every time you render the website.\nBut, chances are, that’s not what you want.\n\nJust playing around styling – you probably don’t want to run the code again\nChanged some code in a document – you probably want to re-run the code in that document, but not necessarily others\nMade a big change affecting computations on many or all pages – you probably want to re-run all code\n\nfreeze and cache options give you fine control over these decisions"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#freeze",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#freeze",
    "title": "Websites",
    "section": "Freeze",
    "text": "Freeze\n\nThe freeze option controls when/if computational documents be re-rendered during a global project render:\n\nexecute:\n  freeze: true  # never re-render during project render\nexecute:\n  freeze: auto  # re-render only when source changes\nexecute:\n  freeze: false  # always re-render\n\nThe freeze option is typically added to a _metadata.yml file within a specific directory, affecting all files in that directory.\nFor blogs, set feeze in _metadata.yml at the root of the posts directory.\nYou can have it only within specific subdirectories for more complex sites."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#cache",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#cache",
    "title": "Websites",
    "section": "Cache",
    "text": "Cache\n\nCache stores the results of computations for a specific file.\nCache invalidation is triggered by changes in chunk source code (or other cache attributes you’ve defined).\ncache can also be set at the chunk level. Consider using the cache for computationally expensive chunks."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#freeze-vs.-cache",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#freeze-vs.-cache",
    "title": "Websites",
    "section": "Freeze vs. cache",
    "text": "Freeze vs. cache\n\nFreeze option is typically set\n\nfor the whole website in _quarto.yml, or\nfor files within a directory in _metadata.yml in that directory\n\n\nexecute: \n  freeze: auto\n\nCache option is typically set for a given file or for individual chunk(s) in a file.\n\nexecute:\n  cache: true\nor\n\n```{r}\n#| cache: true\n\n1 + 1\n```\n\n[1] 2"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#quartopub",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#quartopub",
    "title": "Websites",
    "section": "QuartoPub",
    "text": "QuartoPub\n\nQuarto Pub is a free publishing service for content created with Quarto. It is ideal for blogs, course or project websites, books, presentations, and personal hobby sites.\nPublish with quarto publish:\n\n\n\nTerminal\n\nquarto publish quarto-pub\n\n\nGain a _publish.yml that is safe to check into version control."
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#other-venues",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#other-venues",
    "title": "Websites",
    "section": "Other venues",
    "text": "Other venues\n\nGitHub Pages\nPosit Connect\nNetlify\nConfluence\nMore venues"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#learn-more",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#learn-more",
    "title": "Websites",
    "section": "Learn more",
    "text": "Learn more\n\nquarto.org/docs/websites"
  },
  {
    "objectID": "courselist/case-studies-HF/4-websites/4-websites.html#questions",
    "href": "courselist/case-studies-HF/4-websites/4-websites.html#questions",
    "title": "Websites",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review before we wrap up this module?\n\n\n\n\n\nmine.quarto.pub/quarto-asa-nashville"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html",
    "href": "courselist/case-studies-HF/5-books/5-books.html",
    "title": "Books",
    "section": "",
    "text": "Books are also essentially format: html + a Quarto Project\nBut a book is different than format: html in that it has multiple pages\nBooks and websites are very similar in that they associate multiple pages/resources into a connected resource\nBooks and websites are different in how they treat components: pages vs. cross-referencable chapters for website and books, respectively\n\n\n\n\n\nLet’s build a book together from all of the documents we’ve created so far and highlight the following features of Quarto websites:\n\n_quarto.yml\nindex.qmd / landing page / change landing page\nCross references\nSections\nAppendices\n\n\n\n\n\n\nPick up where we left off and\n\nGive a title to your book.\nAdd a numbered figure and cross-reference it.\nAdd a numbered figure to another chapter, cross-reference it, and observe the numbering scheme\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#quarto-books",
    "href": "courselist/case-studies-HF/5-books/5-books.html#quarto-books",
    "title": "Books",
    "section": "",
    "text": "Books are also essentially format: html + a Quarto Project\nBut a book is different than format: html in that it has multiple pages\nBooks and websites are very similar in that they associate multiple pages/resources into a connected resource\nBooks and websites are different in how they treat components: pages vs. cross-referencable chapters for website and books, respectively"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#our-turn",
    "href": "courselist/case-studies-HF/5-books/5-books.html#our-turn",
    "title": "Books",
    "section": "",
    "text": "Let’s build a book together from all of the documents we’ve created so far and highlight the following features of Quarto websites:\n\n_quarto.yml\nindex.qmd / landing page / change landing page\nCross references\nSections\nAppendices"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#your-turn",
    "href": "courselist/case-studies-HF/5-books/5-books.html#your-turn",
    "title": "Books",
    "section": "",
    "text": "Pick up where we left off and\n\nGive a title to your book.\nAdd a numbered figure and cross-reference it.\nAdd a numbered figure to another chapter, cross-reference it, and observe the numbering scheme\n\n\n\n\n\n−+\n15:00"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#quartopub",
    "href": "courselist/case-studies-HF/5-books/5-books.html#quartopub",
    "title": "Books",
    "section": "QuartoPub",
    "text": "QuartoPub\n\nQuarto Pub is a free publishing service for content created with Quarto. It is ideal for blogs, course or project websites, books, presentations, and personal hobby sites.\nPublish with quarto publish:\n\n\n\nTerminal\n\nquarto publish\n\n\nGain a _publish.yml that is safe to check into version control."
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#other-venues",
    "href": "courselist/case-studies-HF/5-books/5-books.html#other-venues",
    "title": "Books",
    "section": "Other venues",
    "text": "Other venues\n\nGitHub Pages\nPosit Connect\nNetlify\nConfluence\nMore venues"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#computations",
    "href": "courselist/case-studies-HF/5-books/5-books.html#computations",
    "title": "Books",
    "section": "Computations",
    "text": "Computations\nSame freeze and cache ideas for websites apply to books."
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#publishing-1",
    "href": "courselist/case-studies-HF/5-books/5-books.html#publishing-1",
    "title": "Books",
    "section": "Publishing",
    "text": "Publishing\nSame publishing options for websites apply to books as well."
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#learn-more",
    "href": "courselist/case-studies-HF/5-books/5-books.html#learn-more",
    "title": "Books",
    "section": "Learn more",
    "text": "Learn more\n\nquarto.org/docs/books"
  },
  {
    "objectID": "courselist/case-studies-HF/5-books/5-books.html#questions",
    "href": "courselist/case-studies-HF/5-books/5-books.html#questions",
    "title": "Books",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review before we wrap up this module?"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html",
    "title": "Articles",
    "section": "",
    "text": "Metadata: YAML\nText: Markdown\nCode: Executed via knitr or jupyter\n\n. . .\nWeave it all together, and you have a beautiful, reproducible journal article!\n\n\n\nQuarto supports\n\n\na standardized schema for authors and affiliations that can be expressed once int the source document,\nthe use of Citation Style Language (CSL) to automate the formatting of citations and bibliographies, and\noutputting to pdf, html, and docx with custom formatting,\n\n\n. . .\naccording to the styles required for various journals,\n. . .\nand creating the LaTeX required for submission to multiple journals.\n\n\n\n\ngithub.com/quarto-journals\n\n\n\n\nJournal / Publisher\nName\n\n\n\n\nAssociation of Computing Machinery\nacm\n\n\nAmerican Chemical Society\nacs\n\n\nAmerican Geophysical Union\nagu\n\n\nBiophysical journal\nbiophysical-journal\n\n\nElsevier Journals\nelsevier\n\n\nAmerican Statistical Association Journals\njasa\n\n\nJournal of Statistical Software\njss\n\n\nPublic Library of Science\nplos\n\n\n\n\n\n\nThe quarto use template command can be used to create an article from one these formats, e.g. for JASA:\n\n\nTerminal\n\nquarto use template quarto-journals/jasa\n\n\n\n\n\nLet’s write an article together for JASA and showcase the following features of Quarto journal articles:\n\nPDF output\nExtended YAML fields\nCitations"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#components",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#components",
    "title": "Articles",
    "section": "",
    "text": "Metadata: YAML\nText: Markdown\nCode: Executed via knitr or jupyter\n\n. . .\nWeave it all together, and you have a beautiful, reproducible journal article!"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#journal-articles",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#journal-articles",
    "title": "Articles",
    "section": "",
    "text": "Quarto supports\n\n\na standardized schema for authors and affiliations that can be expressed once int the source document,\nthe use of Citation Style Language (CSL) to automate the formatting of citations and bibliographies, and\noutputting to pdf, html, and docx with custom formatting,\n\n\n. . .\naccording to the styles required for various journals,\n. . .\nand creating the LaTeX required for submission to multiple journals."
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#journal-formats",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#journal-formats",
    "title": "Articles",
    "section": "",
    "text": "github.com/quarto-journals\n\n\n\n\nJournal / Publisher\nName\n\n\n\n\nAssociation of Computing Machinery\nacm\n\n\nAmerican Chemical Society\nacs\n\n\nAmerican Geophysical Union\nagu\n\n\nBiophysical journal\nbiophysical-journal\n\n\nElsevier Journals\nelsevier\n\n\nAmerican Statistical Association Journals\njasa\n\n\nJournal of Statistical Software\njss\n\n\nPublic Library of Science\nplos"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#getting-started-with-a-journal-article",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#getting-started-with-a-journal-article",
    "title": "Articles",
    "section": "",
    "text": "The quarto use template command can be used to create an article from one these formats, e.g. for JASA:\n\n\nTerminal\n\nquarto use template quarto-journals/jasa"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#our-turn",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#our-turn",
    "title": "Articles",
    "section": "",
    "text": "Let’s write an article together for JASA and showcase the following features of Quarto journal articles:\n\nPDF output\nExtended YAML fields\nCitations"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#learn-more",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#learn-more",
    "title": "Articles",
    "section": "Learn more",
    "text": "Learn more\n\nquarto.org/docs/journals/index.html"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#coming-up-quarto-manuscripts-1.4",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#coming-up-quarto-manuscripts-1.4",
    "title": "Articles",
    "section": "Coming up: Quarto manuscripts! (1.4+)",
    "text": "Coming up: Quarto manuscripts! (1.4+)\n\nquarto.org/docs/manuscripts"
  },
  {
    "objectID": "courselist/case-studies-HF/6-articles/6-articles.html#questions",
    "href": "courselist/case-studies-HF/6-articles/6-articles.html#questions",
    "title": "Articles",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review or learn before we wrap up the workshop?"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html",
    "title": "Wrap-up",
    "section": "",
    "text": "orchestrates each step of rendering\n\n\n\nArtwork from “Hello, Quarto” keynote by Julia Lowndes and Mine Çetinkaya-Rundel, presented at RStudio Conference 2022. Illustrated by Allison Horst.\n\n\n\n\n\n\nhttps://quarto.org\n\n\n\n\n\n\nquarto.org/docs/blog"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#quarto-cli",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#quarto-cli",
    "title": "Wrap-up",
    "section": "",
    "text": "orchestrates each step of rendering\n\n\n\nArtwork from “Hello, Quarto” keynote by Julia Lowndes and Mine Çetinkaya-Rundel, presented at RStudio Conference 2022. Illustrated by Allison Horst."
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#learn-more",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#learn-more",
    "title": "Wrap-up",
    "section": "",
    "text": "https://quarto.org"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#follow-up-with",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#follow-up-with",
    "title": "Wrap-up",
    "section": "",
    "text": "quarto.org/docs/blog"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#creating-a-minimum-reproducible-example",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#creating-a-minimum-reproducible-example",
    "title": "Wrap-up",
    "section": "Creating a minimum reproducible example",
    "text": "Creating a minimum reproducible example\n\nFor any coding question, start by creating a minimum reproducible example (reprex)\nYou’ll find that this task is less than trivial for a complex Quarto project\nBut there’s a good chance you’ll solve your problem while creating the reprex"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#getting-help",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#getting-help",
    "title": "Wrap-up",
    "section": "Getting help",
    "text": "Getting help\n\nReview the FAQ: https://quarto.org/docs/faq\nHave a question, post on GitHub Discussion: https://github.com/quarto-dev/quarto-cli/discussions\nFound (or think you found) a bug or have a feature request, open an issue: https://github.com/quarto-dev/quarto-cli/issues"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#thank-you",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#thank-you",
    "title": "Wrap-up",
    "section": "Thank you!",
    "text": "Thank you!\n🐘 https://fosstodon.org/@minecr\n🐦 @minebocek"
  },
  {
    "objectID": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#questions",
    "href": "courselist/case-studies-HF/7-wrap-up/7-wrap-up.html#questions",
    "title": "Wrap-up",
    "section": "Questions",
    "text": "Questions\n\nAny questions / anything you’d like to review or learn before we wrap up the workshop?"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/callout-boxes.html",
    "href": "courselist/case-studies-HF/exercises/callout-boxes.html",
    "title": "Callout boxes",
    "section": "",
    "text": "Note that there are five types of callouts, including: note, warning, important, tip, and caution."
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/callout-boxes.html#expand-to-learn-about-collapse",
    "href": "courselist/case-studies-HF/exercises/callout-boxes.html#expand-to-learn-about-collapse",
    "title": "Callout boxes",
    "section": "Expand To Learn About Collapse",
    "text": "Expand To Learn About Collapse\nThis should be an example of a “folded” caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default. Try adding these to attributes."
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins-slides.html",
    "href": "courselist/case-studies-HF/exercises/hello-penguins-slides.html",
    "title": "Hello, Penguins!",
    "section": "",
    "text": "For this analysis we’ll use the penguins dataset from the palmerpenguins package.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.2.3\n\nlibrary(gt)"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#data",
    "href": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#data",
    "title": "Hello, Penguins!",
    "section": "",
    "text": "For this analysis we’ll use the penguins dataset from the palmerpenguins package.\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.2.3\n\n\nWarning: package 'tibble' was built under R version 4.2.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.2.3\n\n\nWarning: package 'dplyr' was built under R version 4.2.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\nlibrary(ggthemes)\n\nWarning: package 'ggthemes' was built under R version 4.2.3\n\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.2.3\n\nlibrary(gt)"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#species",
    "href": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#species",
    "title": "Hello, Penguins!",
    "section": "Species",
    "text": "Species\nThe figure below is a bar plot of species of penguins.\n\nggplot(\n  penguins,\n  aes(\n    x = bill_length_mm, y = bill_depth_mm,\n    color = species, shape = species\n  )\n) +\n  geom_point() +\n  scale_color_colorblind() +\n  labs(x = \"Bill length (mm)\", y = \"Bill depth (mm)\") +\n  theme_minimal()"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#penguins",
    "href": "courselist/case-studies-HF/exercises/hello-penguins-slides.html#penguins",
    "title": "Hello, Penguins!",
    "section": "Penguins",
    "text": "Penguins\nThe table below shows the first 10 penguins from the dataset.\n\npenguins |&gt;\n  slice_head(n = 10) |&gt;\n  select(species, island, bill_length_mm, bill_depth_mm) |&gt;\n  gt()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n\n\nAdelie\nTorgersen\n39.5\n17.4\n\n\nAdelie\nTorgersen\n40.3\n18.0\n\n\nAdelie\nTorgersen\nNA\nNA\n\n\nAdelie\nTorgersen\n36.7\n19.3\n\n\nAdelie\nTorgersen\n39.3\n20.6\n\n\nAdelie\nTorgersen\n38.9\n17.8\n\n\nAdelie\nTorgersen\n39.2\n19.6\n\n\nAdelie\nTorgersen\n34.1\n18.1\n\n\nAdelie\nTorgersen\n42.0\n20.2"
  },
  {
    "objectID": "courselist/case-studies-HF/exercises/markdown-syntax.html",
    "href": "courselist/case-studies-HF/exercises/markdown-syntax.html",
    "title": "Markdown syntax",
    "section": "",
    "text": "Add a title and author to the YAML header. Add a table of contents as well.\nAdd two major sections with level two headers. Add a subsection to one of your major sections.\nAdd an image link to a web image you have chosen and a local image.\nUse any markdown syntax that you can recall from the slides or refresh your memory from https://quarto.org/docs/authoring/markdown-basics.html."
  },
  {
    "objectID": "courselist/case-studies-HF/index.html#instructor",
    "href": "courselist/case-studies-HF/index.html#instructor",
    "title": "From R Markdown to Quarto",
    "section": "Instructor",
    "text": "Instructor\nMine Çetinkaya-Rundel is Professor of the Practice at Duke University and Developer Educator at RStudio. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for For Excellence in Teaching Introductory Statistics.\nAndrew Bray is an Associate Teaching Professor in the Department of Statistics at UC Berkeley, where he develops and teaches courses in statistics and data science. His research interests include statistical computing, data privacy, and applications of statistical models to environmental science. He is one of the authors of the infer R package for resampling based inference and an enthusiastic user of all things R Markdown / Quarto.\nThe materials for this workshop were authored by Mine Çetinkaya-Rundel and Andrew Bray supported by the ASA Traveling Course program. This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "courselist/case-studies-HF/pre-work.html",
    "href": "courselist/case-studies-HF/pre-work.html",
    "title": "Pre-workshop instructions",
    "section": "",
    "text": "Prior to the workshop, please complete the following steps:\n\n1. Software\nDownload and install the latest versions of R, RStudio, and Quarto:\n\nR 4.2.3 or above: https://cran.r-project.org\nRStudio 2023.09.0+448 or above: https://posit.co/download/rstudio-desktop\nQuarto 1.3.450: https://quarto.org/docs/get-started\n\n\n\n2. R Packages\nInstall the following packages:\n\npkg_list &lt;- c(\"tidyverse\", \"gt\", \"ggthemes\", \"palmerpenguins\", \n              \"quarto\", \"here\", \"usethis\")\ninstall.packages(pkg_list)\n\n\n\n3. Exercises\nDownload and open the exercises for this session. The easiest way is to run this line of R code at the console in RStudio.\n\nusethis::use_course(\"https://tinyurl.com/nashville-exercises\")\n\nIf that doesn’t work, you can download a zip file of the exercises here, then open the directory. The qmd files can be opened in RStudio."
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/index.html",
    "href": "courselist/case-studies-HF/x-miscellaneous/index.html",
    "title": "Miscellaneous",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/index.html#slides",
    "href": "courselist/case-studies-HF/x-miscellaneous/index.html#slides",
    "title": "Miscellaneous",
    "section": "",
    "text": "View slides in full screen"
  },
  {
    "objectID": "courselist/case-studies-HF/x-miscellaneous/index.html#exercises",
    "href": "courselist/case-studies-HF/x-miscellaneous/index.html#exercises",
    "title": "Miscellaneous",
    "section": "Exercises",
    "text": "Exercises\nFor exercises in this module we’ll use all the documents we’ve created so far."
  },
  {
    "objectID": "courselist/statistics-R - Copy/index.html",
    "href": "courselist/statistics-R - Copy/index.html",
    "title": "Causality in Machine Learning",
    "section": "",
    "text": "This blog post is currently being prepared."
  },
  {
    "objectID": "courselist/statistics-R/about.html",
    "href": "courselist/statistics-R/about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "courselist/statistics-R/index.html#instructor",
    "href": "courselist/statistics-R/index.html#instructor",
    "title": "Introduction to Causal Inference",
    "section": "Instructor",
    "text": "Instructor\nMine Çetinkaya-Rundel is Professor of the Practice at Duke University and Developer Educator at RStudio. Mine’s work focuses on innovation in statistics and data science pedagogy, with an emphasis on computing, reproducible research, student-centered learning, and open-source education as well as pedagogical approaches for enhancing retention of women and under-represented minorities in STEM. Mine is a Fellow of the ASA and Elected Member of the ISI as well as the winner of the 2021 Robert V. Hogg Award for For Excellence in Teaching Introductory Statistics.\nAndrew Bray is an Associate Teaching Professor in the Department of Statistics at UC Berkeley, where he develops and teaches courses in statistics and data science. His research interests include statistical computing, data privacy, and applications of statistical models to environmental science. He is one of the authors of the infer R package for resampling based inference and an enthusiastic user of all things R Markdown / Quarto.\nThe materials for this workshop were authored by Mine Çetinkaya-Rundel and Andrew Bray supported by the ASA Traveling Course program. This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "portfolio/armilla/index.html",
    "href": "portfolio/armilla/index.html",
    "title": "AI Risk Assessment in Insurtech",
    "section": "",
    "text": "This project leveraged fleet telematics data to inform usage-based insurance models for corporate vehicle fleets. We compared machine learning algorithms to predict collision risk in real-time driving behavior data from 3,854 corporate vehicle drivers. The analysis identified key factors that influenced collision involvement, such as driving time, trip frequency, and rapid speed changes. Fleet rental companies can use these insights to adjust insurance rates based on risky driver behaviors. This project contributes to the development of more accurate risk models and improved operational strategies for commercial fleet services.\nI presented this work at the 2020 Joint Statistical Meetings held by the American Statistical Association, and at the 2020 University of Toronto Engineering Research Conference, where it was awarded the 1st prize in the cluster “Artificial Intelligence and Data Analytics”."
  },
  {
    "objectID": "thinking.html",
    "href": "thinking.html",
    "title": "",
    "section": "",
    "text": "Why AI in Nuclear Will Fail Without Human Factors\nMost AI tools ignore how humans actually operate in high-risk environments. That's a design failure, not a tech one.\nApr 2025\nOperational Trust Is a Design Problem, Not a Communication One\nYou can't train people to trust systems that don't behave predictably. Trust has to be earned at the interface level.\nMar 2025\nIf I Were a CNO Tomorrow, I’d Start With This\nSummary of content\nFeb 2025"
  },
  {
    "objectID": "prova1.html",
    "href": "prova1.html",
    "title": "prova1",
    "section": "",
    "text": "Apr 2025\nA well-defined problem I've been focusing on is how operators in safety-critical industries, like nuclear power, interact with machine learning-driven recommendations. In these environments, decision-making is often time-sensitive and can have severe consequences. Operators are not only required to make quick judgments but also need to trust and interpret the information provided by automation systems. As automation is increasingly used to augment human decision-making, it's essential to understand how operators respond to different types of machine learning explanations in these high-stakes scenarios.\nMachine learning models, especially in complex systems like nuclear power plants, are often seen as black boxes by operators. While these systems may be highly effective at detecting patterns and providing recommendations, the lack of transparency about how they arrive at their conclusions can lead to distrust. If operators don't understand or can't explain why a recommendation was made, they may hesitate to follow it, even if the model is more accurate than their own judgment. This can result in slower decision-making or, in the worst case, mistakes due to misinterpretation of the system's outputs.\nThe key challenge is finding ways to make these machine learning systems interpretable without overwhelming the user. If we provide too much detail, we risk adding cognitive load, potentially distracting the operator from the task at hand. If we provide too little, we may leave them feeling insecure about the system's reliability. The goal is to strike a balance where operators can trust the system’s recommendations and understand them well enough to use them in real-time decision-making.\nIn my PhD, I specifically focused on understanding how different types of explanations—normative, contrastive, and counterfactual—affect human performance and trust when interacting with machine learning systems. Normative explanations provide a standard or rule for why a recommendation was made. Contrastive explanations, on the other hand, show what didn't happen, helping users understand why one outcome was chosen over another. Finally, counterfactual explanations illustrate what would have happened had a different decision been made, offering operators a glimpse into potential alternative outcomes.\nThese three types of explanations—each with its own strengths and weaknesses—can have different impacts on operator reliance and trust. For example, contrastive explanations can help clarify the reasoning behind machine learning decisions by drawing attention to the most relevant differences in outcomes. On the other hand, counterfactual explanations can offer operators a clearer sense of control by showing them the effects of different choices. Normative explanations can be valuable in providing a baseline or framework for understanding how the system functions. However, the challenge is that no single explanation type works universally across all tasks or operators. Some people may prefer one type of explanation over another, depending on their cognitive style or their prior experience with automation.\nBy studying how these explanations impact operator trust, reliance, and task performance, we can better design machine learning systems that enhance human decision-making. This is especially important in environments like nuclear power plants, where operators are expected to integrate machine learning recommendations into their decision-making processes while maintaining high safety standards. Providing clear, transparent, and relevant explanations can help operators use these systems more effectively, leading to more efficient operations and, ultimately, safer outcomes."
  },
  {
    "objectID": "thinking/ai-memo.html",
    "href": "thinking/ai-memo.html",
    "title": "sto cazzus",
    "section": "",
    "text": "Apr 2025\nA well-defined problem I’ve been focusing on is how operators in safety-critical industries, like nuclear power, interact with machine learning-driven recommendations. In these environments, decision-making is often time-sensitive and can have severe consequences. Operators are not only required to make quick judgments but also need to trust and interpret the information provided by automation systems. As automation is increasingly used to augment human decision-making, it’s essential to understand how operators respond to different types of machine learning explanations in these high-stakes scenarios.\nMachine learning models, especially in complex systems like nuclear power plants, are often seen as black boxes by operators. While these systems may be highly effective at detecting patterns and providing recommendations, the lack of transparency about how they arrive at their conclusions can lead to distrust. If operators don’t understand or can’t explain why a recommendation was made, they may hesitate to follow it, even if the model is more accurate than their own judgment. This can result in slower decision-making or, in the worst case, mistakes due to misinterpretation of the system’s outputs.\nThe key challenge is finding ways to make these machine learning systems interpretable without overwhelming the user. If we provide too much detail, we risk adding cognitive load, potentially distracting the operator from the task at hand. If we provide too little, we may leave them feeling insecure about the system’s reliability. The goal is to strike a balance where operators can trust the system’s recommendations and understand them well enough to use them in real-time decision-making.\nIn my PhD, I specifically focused on understanding how different types of explanations—normative, contrastive, and counterfactual—affect human performance and trust when interacting with machine learning systems. Normative explanations provide a standard or rule for why a recommendation was made. Contrastive explanations, on the other hand, show what didn’t happen, helping users understand why one outcome was chosen over another. Finally, counterfactual explanations illustrate what would have happened had a different decision been made, offering operators a glimpse into potential alternative outcomes.\nThese three types of explanations—each with its own strengths and weaknesses—can have different impacts on operator reliance and trust. For example, contrastive explanations can help clarify the reasoning behind machine learning decisions by drawing attention to the most relevant differences in outcomes. On the other hand, counterfactual explanations can offer operators a clearer sense of control by showing them the effects of different choices. Normative explanations can be valuable in providing a baseline or framework for understanding how the system functions. However, the challenge is that no single explanation type works universally across all tasks or operators. Some people may prefer one type of explanation over another, depending on their cognitive style or their prior experience with automation.\nBy studying how these explanations impact operator trust, reliance, and task performance, we can better design machine learning systems that enhance human decision-making. This is especially important in environments like nuclear power plants, where operators are expected to integrate machine learning recommendations into their decision-making processes while maintaining high safety standards. Providing clear, transparent, and relevant explanations can help operators use these systems more effectively, leading to more efficient operations and, ultimately, safer outcomes."
  },
  {
    "objectID": "thinking/my-memo2.html",
    "href": "thinking/my-memo2.html",
    "title": "my-memo2",
    "section": "",
    "text": "Mar 2025"
  },
  {
    "objectID": "docs/my-memo2.html",
    "href": "docs/my-memo2.html",
    "title": "my-memo2",
    "section": "",
    "text": "Mar 2025"
  },
  {
    "objectID": "memos/ai-memo.html",
    "href": "memos/ai-memo.html",
    "title": "sto cazzus",
    "section": "",
    "text": "Apr 2025\nA well-defined problem I’ve been focusing on is how operators in safety-critical industries, like nuclear power, interact with machine learning-driven recommendations. In these environments, decision-making is often time-sensitive and can have severe consequences. Operators are not only required to make quick judgments but also need to trust and interpret the information provided by automation systems. As automation is increasingly used to augment human decision-making, it’s essential to understand how operators respond to different types of machine learning explanations in these high-stakes scenarios.\nMachine learning models, especially in complex systems like nuclear power plants, are often seen as black boxes by operators. While these systems may be highly effective at detecting patterns and providing recommendations, the lack of transparency about how they arrive at their conclusions can lead to distrust. If operators don’t understand or can’t explain why a recommendation was made, they may hesitate to follow it, even if the model is more accurate than their own judgment. This can result in slower decision-making or, in the worst case, mistakes due to misinterpretation of the system’s outputs.\nThe key challenge is finding ways to make these machine learning systems interpretable without overwhelming the user. If we provide too much detail, we risk adding cognitive load, potentially distracting the operator from the task at hand. If we provide too little, we may leave them feeling insecure about the system’s reliability. The goal is to strike a balance where operators can trust the system’s recommendations and understand them well enough to use them in real-time decision-making.\nIn my PhD, I specifically focused on understanding how different types of explanations—normative, contrastive, and counterfactual—affect human performance and trust when interacting with machine learning systems. Normative explanations provide a standard or rule for why a recommendation was made. Contrastive explanations, on the other hand, show what didn’t happen, helping users understand why one outcome was chosen over another. Finally, counterfactual explanations illustrate what would have happened had a different decision been made, offering operators a glimpse into potential alternative outcomes.\nThese three types of explanations—each with its own strengths and weaknesses—can have different impacts on operator reliance and trust. For example, contrastive explanations can help clarify the reasoning behind machine learning decisions by drawing attention to the most relevant differences in outcomes. On the other hand, counterfactual explanations can offer operators a clearer sense of control by showing them the effects of different choices. Normative explanations can be valuable in providing a baseline or framework for understanding how the system functions. However, the challenge is that no single explanation type works universally across all tasks or operators. Some people may prefer one type of explanation over another, depending on their cognitive style or their prior experience with automation.\nBy studying how these explanations impact operator trust, reliance, and task performance, we can better design machine learning systems that enhance human decision-making. This is especially important in environments like nuclear power plants, where operators are expected to integrate machine learning recommendations into their decision-making processes while maintaining high safety standards. Providing clear, transparent, and relevant explanations can help operators use these systems more effectively, leading to more efficient operations and, ultimately, safer outcomes."
  },
  {
    "objectID": "memos/my-memo2.html",
    "href": "memos/my-memo2.html",
    "title": "my-memo2",
    "section": "",
    "text": "Mar 2025"
  },
  {
    "objectID": "index.html#expert-guidance-at-critical-intersections",
    "href": "index.html#expert-guidance-at-critical-intersections",
    "title": "Human-Centered AI for Critical Infrastructure",
    "section": "Expert Guidance at Critical Intersections",
    "text": "Expert Guidance at Critical Intersections\n\n\n\n\n🎓\n\n\nAcademic Expertise\nPhD research in XAI and human factors with specialized knowledge in condition-based maintenance systems.\n\n\n\n\n\n\n🛡️\n\n\nOperational Safety\nExperience from nuclear industry human factors, applying the highest safety standards to AI implementation.\n\n\n\n\n\n\n🧭\n\n\nImplementation Guidance\nPractical roadmaps for integrating AI systems that enhance rather than complicate human decision-making."
  },
  {
    "objectID": "index.html#the-critical-human-element-in-ai-implementation",
    "href": "index.html#the-critical-human-element-in-ai-implementation",
    "title": "Human-Centered AI for Critical Infrastructure",
    "section": "The Critical Human Element in AI Implementation",
    "text": "The Critical Human Element in AI Implementation\nToo often, organizations deploy powerful AI tools without sufficient consideration for how operators will interact with, understand, and appropriately trust these systems in real-time, high-pressure situations.\nThis disconnect creates operational risks, reduces efficiency gains, and can lead to costly implementation failures or safety incidents."
  },
  {
    "objectID": "index.html#specialized-services",
    "href": "index.html#specialized-services",
    "title": "Human-Centered AI for Critical Infrastructure",
    "section": "Specialized Services",
    "text": "Specialized Services\n\n\n\n\n🔍\n\n\nAI Use Case Identification\nIdentify where AI can provide genuine operational benefits while minimizing implementation risks.\nLearn more\n\n\n\n\n\n\n🖥️\n\n\nHuman-Machine Interface Design\nCreate interfaces that enhance situation awareness and effective human oversight.\nLearn more\n\n\n\n\n\n\n💡\n\n\nXAI Implementation Guidance\nDetermine what types of explanations are necessary for different operational contexts.\nLearn more\n\n\n\n\n\n\n⚠️\n\n\nRisk Assessment\nEvaluate how AI implementations might affect human performance and operational safety.\nLearn more"
  },
  {
    "objectID": "index.html#research-backed-expertise",
    "href": "index.html#research-backed-expertise",
    "title": "Human-Centered AI for Critical Infrastructure",
    "section": "Research-Backed Expertise",
    "text": "Research-Backed Expertise\n“My work focuses on ensuring critical infrastructure organizations can safely harness AI capabilities while optimizing the crucial role of human operators. With a PhD in explainable AI for condition-based maintenance and postdoctoral research in nuclear human factors, I bring specialized knowledge to your AI implementation challenges.”"
  },
  {
    "objectID": "index.html#ready-to-enhance-your-ai-implementation",
    "href": "index.html#ready-to-enhance-your-ai-implementation",
    "title": "Human-Centered AI for Critical Infrastructure",
    "section": "Ready to Enhance Your AI Implementation?",
    "text": "Ready to Enhance Your AI Implementation?\nI provide tailored guidance for organizations implementing AI in critical infrastructure environments, with a focus on optimizing human-machine interaction for safety and operational excellence.\nStart the Conversation"
  },
  {
    "objectID": "posts/ai-memo.html",
    "href": "posts/ai-memo.html",
    "title": "sto cazzus",
    "section": "",
    "text": "Apr 2025\nA well-defined problem I’ve been focusing on is how operators in safety-critical industries, like nuclear power, interact with machine learning-driven recommendations. In these environments, decision-making is often time-sensitive and can have severe consequences. Operators are not only required to make quick judgments but also need to trust and interpret the information provided by automation systems. As automation is increasingly used to augment human decision-making, it’s essential to understand how operators respond to different types of machine learning explanations in these high-stakes scenarios.\nMachine learning models, especially in complex systems like nuclear power plants, are often seen as black boxes by operators. While these systems may be highly effective at detecting patterns and providing recommendations, the lack of transparency about how they arrive at their conclusions can lead to distrust. If operators don’t understand or can’t explain why a recommendation was made, they may hesitate to follow it, even if the model is more accurate than their own judgment. This can result in slower decision-making or, in the worst case, mistakes due to misinterpretation of the system’s outputs.\nThe key challenge is finding ways to make these machine learning systems interpretable without overwhelming the user. If we provide too much detail, we risk adding cognitive load, potentially distracting the operator from the task at hand. If we provide too little, we may leave them feeling insecure about the system’s reliability. The goal is to strike a balance where operators can trust the system’s recommendations and understand them well enough to use them in real-time decision-making.\nIn my PhD, I specifically focused on understanding how different types of explanations—normative, contrastive, and counterfactual—affect human performance and trust when interacting with machine learning systems. Normative explanations provide a standard or rule for why a recommendation was made. Contrastive explanations, on the other hand, show what didn’t happen, helping users understand why one outcome was chosen over another. Finally, counterfactual explanations illustrate what would have happened had a different decision been made, offering operators a glimpse into potential alternative outcomes.\nThese three types of explanations—each with its own strengths and weaknesses—can have different impacts on operator reliance and trust. For example, contrastive explanations can help clarify the reasoning behind machine learning decisions by drawing attention to the most relevant differences in outcomes. On the other hand, counterfactual explanations can offer operators a clearer sense of control by showing them the effects of different choices. Normative explanations can be valuable in providing a baseline or framework for understanding how the system functions. However, the challenge is that no single explanation type works universally across all tasks or operators. Some people may prefer one type of explanation over another, depending on their cognitive style or their prior experience with automation.\nBy studying how these explanations impact operator trust, reliance, and task performance, we can better design machine learning systems that enhance human decision-making. This is especially important in environments like nuclear power plants, where operators are expected to integrate machine learning recommendations into their decision-making processes while maintaining high safety standards. Providing clear, transparent, and relevant explanations can help operators use these systems more effectively, leading to more efficient operations and, ultimately, safer outcomes."
  },
  {
    "objectID": "posts/my-memo2.html",
    "href": "posts/my-memo2.html",
    "title": "my-memo2",
    "section": "",
    "text": "Mar 2025"
  },
  {
    "objectID": "posts/exp-hf.html",
    "href": "posts/exp-hf.html",
    "title": "What is experimental human factors?",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nPhasellus vel tortor nec ipsum faucibus consequat. Aenean eu tincidunt nisi. Integer vitae nibh sed turpis luctus finibus. Maecenas eu sapien sit amet mauris convallis tincidunt.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nPhasellus vel tortor nec ipsum faucibus consequat. Aenean eu tincidunt nisi. Integer vitae nibh sed turpis luctus finibus. Maecenas eu sapien sit amet mauris convallis tincidunt.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\nDuis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\nPhasellus vel tortor nec ipsum faucibus consequat. Aenean eu tincidunt nisi. Integer vitae nibh sed turpis luctus finibus. Maecenas eu sapien sit amet mauris convallis tincidunt."
  },
  {
    "objectID": "publications.html#highlighted-work",
    "href": "publications.html#highlighted-work",
    "title": "Publications",
    "section": "Highlighted Work",
    "text": "Highlighted Work\n\nPhD Dissertation: Supporting Human Performance with Post-hoc Explanations in Automated Decision Assistance\nHuman performance effects of combining counterfactual explanations with normative and contrastive explanations… (IJHCS)\nHuman Performance Consequences of Normative and Contrastive Explanations… (Journal of Artificial Intelligence)\n\n\n Full list of publications ▼ \n\n\n\n\n[Publication 1 – full citation]\n\n\n[Publication 2 – full citation]\n\n\n[Publication 3 – full citation]"
  },
  {
    "objectID": "portfolio - Copy/ubi/index.html",
    "href": "portfolio - Copy/ubi/index.html",
    "title": "Machine Learning Evaluation for Usage-based Insurance",
    "section": "",
    "text": "This project leveraged fleet telematics data to inform usage-based insurance models for corporate vehicle fleets. We compared machine learning algorithms to predict collision risk in real-time driving behavior data from 3,854 corporate vehicle drivers. The analysis identified key factors that influenced collision involvement, such as driving time, trip frequency, and rapid speed changes. Fleet rental companies can use these insights to adjust insurance rates based on risky driver behaviors. This project contributes to the development of more accurate risk models and improved operational strategies for commercial fleet services.\nI presented this work at the 2020 Joint Statistical Meetings held by the American Statistical Association, and at the 2020 University of Toronto Engineering Research Conference, where it was awarded the 1st prize in the cluster “Artificial Intelligence and Data Analytics”."
  },
  {
    "objectID": "portfolio - Copy/human-ai-collab/index.html",
    "href": "portfolio - Copy/human-ai-collab/index.html",
    "title": "Impact of Machine Learning Explanations on Decision-Making",
    "section": "",
    "text": "This project investigated the impact of model-agnostic explanations on human performance in industrial process control, focusing on improving the detection of system failures in condition-based maintenance. Two controlled experiments tested the effects of different explanation types—normative, contrastive, and counterfactual—on decision-making, workload, and reliance on automated decision aids. Results showed that combining normative and contrastive explanations improved decision time and reduced workload, while adding counterfactuals further enhanced accuracy and reduced false alarms. The findings can inform the design of more effective and efficient explainable AI systems to support human operators in safety-critical work environments.\nThe first experiment was published in the Journal of Artificial Intelligence in 2023 and is available here. The second experiment was published in the Journal of Human-Computer Studies in 2025 and is available here."
  },
  {
    "objectID": "portfolio - Copy/hf-nuclear/index.html",
    "href": "portfolio - Copy/hf-nuclear/index.html",
    "title": "Human Performance in Operation of Small Modular Reactors",
    "section": "",
    "text": "Background\nThe increasing automation of small modular reactors (SMRs) introduces new challenges for human operators in nuclear control rooms. Effective monitoring and control require maintaining situation awareness and workload balance, but traditional assessment methods lack validity and reliability in these high-stakes environments. Additionally, the diversity of SMR designs complicates the development of standardized human factors guidelines to ensure safe and efficient operation.\nStarting September 2024, I am leading experimental and analytical projects in a new research program aimed at addressing these gaps. The research program focuses on two key objectives: improving methodologies for assessing situation awareness (SA) and workload in nuclear control rooms, and developing a taxonomy to categorize SMR designs and their impact on human performance. The first experiment tests multiple (SA) and workload measures across different automation levels. A parallel project is creating a taxonomy to guide human factors guidelines for varying SMR designs.\nThe project aims to establish better performance metrics and standardized operational guidelines, supporting safety and efficiency in the nuclear sector. This research is funded by the Natural Sciences and Engineering Council of Canada and the Canadian Nuclear Safety Commission.\n\n\nMethods\nThis research program addresses these challenges through two parallel projects:\n\nProject 1: Experiment on Operator Performance & Automation\n\nI designed an experiment using the RANCOR microworld platform to simulate the operation of small modular reactors under routine and abnormal scenarios.\nTested 24 participants and collected multiple metrics of situation awareness and workload across three levels of automation in computerized procedures. The three levels of automation in the computerized procedures are defined according to the Institute of Electrical and Electronics Engineers (IEEE) Standard 1786 (IEEE, 2022): Type I procedure displays the instructions on a screen, resembling a traditional paper-based procedure; Type II can additionally display process data and step logic, visualize results, and provide access links to displays and soft controls; Type III has the additional capability to automatically carry out sequences in the procedure and has embedded soft control features.\nEvaluated situation awareness, cognitive workload, decision-making, and reaction time using a within-subjects experimental design with three counterbalanced conditions corresponding to the level of automation in the computerized procedures (Table I).\n\n\n\n\nTable I. Experimental design. A = Type I procedure; B = Type II; C = Type III.\n\n\n\n\nProject 2: Development of an SMR Taxonomy\n\nMy team is leading the development of a taxonomy that categorizes key design variations in SMRs, including levels of automation, control systems, and operational phases. This work identifies implications for task performance, cognitive workload, and situational awareness, providing a structured framework to inform human factors guidelines and improve safety in nuclear operations.\n\n\n\n\nKey Findings\nFindings will be presented at the Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT) meeting in Chicago in June 2025.\n\n\nImplications\nThis research supports regulatory agencies and nuclear operators in defining best practices for safe SMR operations by providing validated methodologies for assessing operator performance. It also helps engineers and system designers optimize automation levels and control interfaces to enhance human performance in nuclear control rooms.\n\n\n\nSMR simulator setup in the Halden Future Lab, Norway.\n\n\n\nFurther Reading\n\nIEEE. (2022). IEEE Guide for Human Factors Applications of Computerized Operating Procedure Systems (COPS) at Nuclear Power Generating Stations and Other Nuclear Facilities, IEEE- 1786-2022. New York: IEEE."
  },
  {
    "objectID": "portfolio - Copy/trust-ml/index.html",
    "href": "portfolio - Copy/trust-ml/index.html",
    "title": "Investigating Trust in Human-Machine Learning Interaction",
    "section": "",
    "text": "In collaboration with a group comprising doctoral and postdoctoral researchers from the Schwartz Reisman Institute for Technology and Society, we adopted a multidisciplinary perspective to understand how machine learning systems can earn and maintain human trust. We are preparing a paper on this research inclusive of findings and suggestions for further inquiry. More information on this project is available here."
  },
  {
    "objectID": "portfolio - Copy/ux-ericsson/index.html",
    "href": "portfolio - Copy/ux-ericsson/index.html",
    "title": "Development of Model Interpretability Tool",
    "section": "",
    "text": "This project developed a glyph-based polar chart (GPC) to enhance the interpretability of machine learning models for data scientists. The tool enables comparisons of explanations across different models and computational methods. User experience evaluations with Ericsson data scientists showed that the GPC helped identify key model variables, compare various explanation techniques, and perform logical reviews of model outputs. This project was conducted during my internship at Ericsson’s Global AI Accelerator. The development of the prototype and its evaluation with Ericsson’s data scientists was published in the Journal of Ergonomics in Design and is available here."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Contact me if you are ready to make your AI systems effective and safe.\ngentiledv at gmail dot com"
  },
  {
    "objectID": "servicelist/ai-risk/index.html",
    "href": "servicelist/ai-risk/index.html",
    "title": "AI Risk Assessment",
    "section": "",
    "text": "This project leveraged fleet telematics data to inform usage-based insurance models for corporate vehicle fleets. We compared machine learning algorithms to predict collision risk in real-time driving behavior data from 3,854 corporate vehicle drivers. The analysis identified key factors that influenced collision involvement, such as driving time, trip frequency, and rapid speed changes. Fleet rental companies can use these insights to adjust insurance rates based on risky driver behaviors. This project contributes to the development of more accurate risk models and improved operational strategies for commercial fleet services.\nI presented this work at the 2020 Joint Statistical Meetings held by the American Statistical Association, and at the 2020 University of Toronto Engineering Research Conference, where it was awarded the 1st prize in the cluster “Artificial Intelligence and Data Analytics”."
  },
  {
    "objectID": "servicelist/training/index.html",
    "href": "servicelist/training/index.html",
    "title": "Development and UX Analysis of ML Model Interpretability Tool",
    "section": "",
    "text": "This project developed a glyph-based polar chart (GPC) to enhance the interpretability of machine learning models for data scientists. The tool enables comparisons of explanations across different models and computational methods. User experience evaluations with Ericsson data scientists showed that the GPC helped identify key model variables, compare various explanation techniques, and perform logical reviews of model outputs. This project was conducted during my internship at Ericsson’s Global AI Accelerator. The development of the prototype and its evaluation with Ericsson’s data scientists was published in the Journal of Ergonomics in Design and is available here."
  },
  {
    "objectID": "index.html#davide-gentile",
    "href": "index.html#davide-gentile",
    "title": "Davide Gentile",
    "section": "",
    "text": "Leading human factors research in nuclear operations at the university of toronto cognitive engineering lab\nPreviously consulted on ai risk at armilla ai, researched human–ml interaction at the schwartz reisman institute, and interned at ericsson’s global ai accelerator. Member of z-inspection since june 2025\nIndustries: nuclear, healthcare, transportation, industrial products, consumer products, software, web, mobile\nprojects\npublications\nwriting\nservices\ncontact"
  },
  {
    "objectID": "index.html#ai-is-not-a-person.-its-a-tool-built-to-serve-human-needs-not-mimic-them.",
    "href": "index.html#ai-is-not-a-person.-its-a-tool-built-to-serve-human-needs-not-mimic-them.",
    "title": "Davide Gentile",
    "section": "",
    "text": "I design research that keeps that truth at the center. My work focuses on how people actually experience AI — what they understand, what they trust, and what they need. I build evaluations that go beyond benchmarks, using behavioral science, statistical rigor, and real user data to guide design and development.\nI've worked on systems that generate language, adapt to context, and interact in real time. I've built longitudinal studies, in-the-wild assessments, and hybrid frameworks that blend quantitative scale with qualitative depth. I collaborate tightly with engineers and designers to make sure the research is not just insightful, but usable.\nWhat I bring:\n– Human-centered evaluation of generative AI\n– Rigorous mixed-method research, from design to analysis\n– Behavioral science expertise and strong statistical grounding\n– Clear, persuasive communication across functions\n– Strategic thinking that informs product direction\n– Independent, focused execution\nI'm interested in how people adapt to AI tools — not how tools pretend to be people. If your goal is to build systems that respect human intent, extend capability, and scale responsibly, then we're already aligned.\nDavide Gentile\nContact"
  },
  {
    "objectID": "index.html#ai-is-not-a-person.-its-a-tool-built-to-serve-people-not-mimic-them.",
    "href": "index.html#ai-is-not-a-person.-its-a-tool-built-to-serve-people-not-mimic-them.",
    "title": "Davide Gentile",
    "section": "",
    "text": "I design research that keeps that truth at the center. My work focuses on how people actually experience AI — what they understand, what they trust, and what they need. I build evaluations that go beyond benchmarks, using behavioral science, statistical rigor, and real user data to guide design and development.\nI've worked on systems that generate language, adapt to context, and interact in real time. I've built longitudinal studies, in-the-wild assessments, and hybrid frameworks that blend quantitative scale with qualitative depth. I collaborate tightly with engineers and designers to make sure the research is not just insightful, but usable.\nWhat I bring:\n– Human-centered evaluation of generative AI\n– Rigorous mixed-method research, from design to analysis\n– Behavioral science expertise and strong statistical grounding\n– Clear, persuasive communication across functions\n– Strategic thinking that informs product direction\n– Independent, focused execution\nI'm interested in how people adapt to AI tools — not how tools pretend to be people. If your goal is to build systems that respect human intent, extend capability, and scale responsibly, then we're already aligned.\nDavide Gentile\nContact"
  },
  {
    "objectID": "index.html#ai-is-a-tool-built-to-serve-people-not-mimic-them.",
    "href": "index.html#ai-is-a-tool-built-to-serve-people-not-mimic-them.",
    "title": "Davide Gentile",
    "section": "",
    "text": "I work on user research, AI evaluation, and behavioral data analysis. I specialize in designing rigorous, human-centered methods for understanding how people interact with intelligent systems. I’ve helped product teams and engineers solve complex challenges around usability, trust, and real-world impact of generative AI.\nWhat I bring:\n– Human-centered evaluation of AI\n– Mixed-method research\n– Behavioral science and statistics\n– Clear communication across functions\n– Strategic thinking that informs product direction\nContact\nHome | Case studies | Publications | Thoughts"
  },
  {
    "objectID": "slides.html#slide-1-opening",
    "href": "slides.html#slide-1-opening",
    "title": "test",
    "section": "Slide 1: Opening",
    "text": "Slide 1: Opening\nAI is not a person.\nIt’s a tool — built to serve human needs, not mimic them."
  },
  {
    "objectID": "slides.html#slide-2-what-i-do",
    "href": "slides.html#slide-2-what-i-do",
    "title": "test",
    "section": "Slide 2: What I Do",
    "text": "Slide 2: What I Do\nI work on user research, AI evaluation, and behavioral data analysis.\nI design methods that keep products aligned with how people actually think and act."
  },
  {
    "objectID": "slides.html#slide-3-methods",
    "href": "slides.html#slide-3-methods",
    "title": "test",
    "section": "Slide 3: Methods",
    "text": "Slide 3: Methods\n\nMixed-method research (quant + qual)\n\nHuman-centered evaluation\n\nBehavioral measurement\n\nReal-world usage insights"
  },
  {
    "objectID": "slides.html#slide-4-experience",
    "href": "slides.html#slide-4-experience",
    "title": "test",
    "section": "Slide 4: Experience",
    "text": "Slide 4: Experience\nWorked with product, research, and engineering teams to: - Evaluate generative models - Design feedback loops - Translate complex data into clear direction"
  },
  {
    "objectID": "slides.html#slide-5-lets-talk",
    "href": "slides.html#slide-5-lets-talk",
    "title": "test",
    "section": "Slide 5: Let’s Talk",
    "text": "Slide 5: Let’s Talk\nIf you’re building AI that empowers instead of distracts,\nEmail me.\nLet’s make it work better — for real people."
  },
  {
    "objectID": "index.html#services",
    "href": "index.html#services",
    "title": "Davide Gentile",
    "section": "Services",
    "text": "Services\n\nHuman Factors audit: usability, explainability, and system design.\nAI risk assessment: mapping of AI risks according to latest research in technical AI governance.\nTraining and workshops: train your team to see how AI can benefit their life and work."
  },
  {
    "objectID": "writing.html",
    "href": "writing.html",
    "title": "Davide Gentile",
    "section": "",
    "text": "&lt; Back\n\nMay 2025\n\nContemporary problems in science and possible paths forward."
  },
  {
    "objectID": "projects.html#projects",
    "href": "projects.html#projects",
    "title": "Davide Gentile",
    "section": "Projects",
    "text": "Projects"
  },
  {
    "objectID": "publications.html#publications",
    "href": "publications.html#publications",
    "title": "Davide Gentile",
    "section": "Publications",
    "text": "Publications\nLists of academic publications on explainable AI, human factors, and decision automation.\nHighlighted work:\n\nSupporting human performance with post-hoc explanations in automated decision assistance\nThis is my PhD dissertation. It focuses on how different ways of explaining AI results can influence human decisions to rely on AI or not.\nView dissertation →\nCombining normative and contrastive explanations can benefit user reliance on machine learning advice, workload, and trust in automation\nA human-subjects experiment (N=24) tested how normative and contrastive explanations impact user reliance on a machine learning aid for hydraulic system maintenance. Normative explanations lowered decision time and subjective workload, while the addition of contrastive explanations also improved participants’ ability to distinguish between correct and incorrect ML estimations.\nRead in Journal of Artificial Intelligence →\nCombining counterfactual, normative, and contrastive explanations leads to minor improvements in human reliance on machine learning estimations\nA follow up human-subject experiment (N=24) added counterfactual explanations to further explore their effect on human performance in the same hydraulic diagnosis task. Including counterfactual explanations reduced false alarms and showed potential to decrease decision time and workload, though these benefits warrant cautious interpretation.\nRead in International Journal of Human-Computer Studies →\n\n\n Full list of publications ▼ \n\n\n\n\nGentile D., Liang Y., & Jamieson, G. A. (2025). Assessing Measures of Human Performance in the Nuclear Control Room. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\n\n\nLawson-Jack K., Gentile D., & Jamieson, G. A. (2025). Towards a Taxonomy of Heterogeneity in the Design of Small Modular Reactors and Implications for Human Performance. In the 14th International Topical Meeting on Nuclear Plant Instrumentation and Control & Human-Machine Interface Technology (NPIC&HMIT), Chicago.\n\n\nGentile D., Donmez, B., & Jamieson, G. A. (2025). Human performance effects of combining counterfactual explanations with normative and contrastive explanations in supervised machine learning for automated decision assistance. International Journal of Human-Computer Studies, 196, 103434.\n\n\nGentile D. (2024). Supporting Human Performance with Post-hoc Explanations in Automated Decision Assistance.\n\n\nGentile D., Donmez, B., & Jamieson, G. A. (2023). Human Performance Consequences of Normative and Contrastive Explanations: An Experiment in Machine Learning for Reliability Maintenance. Artificial Intelligence, 103945.\n\n\nNguyen, T., Gentile D., Jamieson, G. A., Gosine, R., & Purmhedi, H. (2023). Designing a glyph-based polar chart to interpret the results of machine learning models. In Ergonomics in Design: The Quarterly of Human Factors Applications.\n\n\nGentile D., Jamieson G. A., Donmez B. (2021). Evaluating human understanding in Explainable AI systems. In ACM Human Factors in Computing Systems (CHI) Workshop on Operationalizing Human-Centered Perspectives in Explainable AI, CHI2021, Yokohama, Japan."
  }
]